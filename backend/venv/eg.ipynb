{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8d1457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ğŸ” SCRAPING CNN FINANCE HEADLINES\n",
      "====================================================================================================\n",
      "\n",
      "ğŸŒ Fetching: https://edition.cnn.com/search?q=finance&size=10&from=0&page=1&sort=newest&types=all&section=\n",
      "\n",
      "â³ Opening browser and loading page...\n",
      "\n",
      "âœ“ Browser started\n",
      "\n",
      "â³ Waiting for headlines to load...\n",
      "\n",
      "âœ“ Saved rendered HTML to 'debug_selenium_page.html'\n",
      "\n",
      "âœ“ Found 9 headlines:\n",
      "\n",
      "====================================================================================================\n",
      "1. The Fed just cut rates. Hereâ€™s how to make that move work for your money\n",
      "   ğŸ”— https://www.cnn.com/2025/09/17/business/your-money-federal-reserve-interest-rate-cut\n",
      "\n",
      "2. Stocks have literally never been this expensive\n",
      "   ğŸ”— https://www.cnn.com/2025/09/02/economy/us-stock-market\n",
      "\n",
      "3. Here are 4 ways lower interest rates could affect your personal finances\n",
      "   ğŸ”— https://www.cnn.com/2025/08/25/business/personal-finances-how-fed-interest-cut-affects-you\n",
      "\n",
      "4. Make your money work for you by â€˜ladderingâ€™ bonds or CDs\n",
      "   ğŸ”— https://www.cnn.com/2025/08/16/business/building-a-cd-or-bond-ladder\n",
      "\n",
      "5. Worried about money? Experts share how to prepare for hard times\n",
      "   ğŸ”— https://www.cnn.com/2025/08/04/health/financial-emotional-preparation-wellness\n",
      "\n",
      "6. Confused about the economy? Youâ€™re not alone\n",
      "   ğŸ”— https://www.cnn.com/2025/08/01/business/economy-explained\n",
      "\n",
      "7. This startup is working toward financial inclusion in Ivory Coast\n",
      "   ğŸ”— https://www.cnn.com/2025/07/31/world/video/djamo-fintech-ivory-coast-spc\n",
      "\n",
      "8. What drives financial fraud? It can come down to one emotion\n",
      "   ğŸ”— https://www.cnn.com/2025/07/13/economy/billionaire-boys-club-greed\n",
      "\n",
      "9. Making big financial decisions when the world is giving you heartburn\n",
      "   ğŸ”— https://www.cnn.com/2025/07/01/business/financial-decisions-money-anxiety\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "âœ“ Browser closed\n",
      "\n",
      "ğŸ“Š Total headlines scraped: 9\n",
      "\n",
      "ğŸ’¾ Saving to file...\n",
      "âœ“ Saved to 'cnn_headlines.txt'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN Headline Scraper with Selenium\n",
    "Handles JavaScript-rendered content\n",
    "\n",
    "Installation:\n",
    "pip install selenium webdriver-manager beautifulsoup4\n",
    "\n",
    "For Ubuntu/Linux, install Firefox:\n",
    "sudo apt-get update\n",
    "sudo apt-get install firefox\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_cnn_headlines(query=\"finance\", use_firefox=True):\n",
    "    \"\"\"Scrape headlines from CNN search using Selenium\"\"\"\n",
    "    \n",
    "    url = f\"https://edition.cnn.com/search?q={query}&size=10&from=0&page=1&sort=newest&types=all&section=\"\n",
    "    \n",
    "    print(f\"ğŸŒ Fetching: {url}\\n\")\n",
    "    print(\"â³ Opening browser and loading page...\\n\")\n",
    "    \n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        # Setup Firefox (more likely to be installed on Linux)\n",
    "        firefox_options = FirefoxOptions()\n",
    "        firefox_options.add_argument(\"--headless\")  # Run without GUI\n",
    "        firefox_options.add_argument(\"--no-sandbox\")\n",
    "        firefox_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        \n",
    "        service = FirefoxService(GeckoDriverManager().install())\n",
    "        driver = webdriver.Firefox(service=service, options=firefox_options)\n",
    "        \n",
    "        print(\"âœ“ Browser started\\n\")\n",
    "        \n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for content to load\n",
    "        print(\"â³ Waiting for headlines to load...\\n\")\n",
    "        time.sleep(5)  # Give it time to load\n",
    "        \n",
    "        # Try to wait for span elements\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"container__headline-text\"))\n",
    "            )\n",
    "        except:\n",
    "            print(\"âš ï¸  Timeout waiting for headlines, continuing anyway...\\n\")\n",
    "        \n",
    "        # Get page source after JavaScript execution\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Save for debugging\n",
    "        with open('debug_selenium_page.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(page_source)\n",
    "        print(\"âœ“ Saved rendered HTML to 'debug_selenium_page.html'\\n\")\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find all span tags with class 'container__headline-text'\n",
    "        headline_spans = soup.find_all('span', class_='container__headline-text')\n",
    "        \n",
    "        print(f\"âœ“ Found {len(headline_spans)} headlines:\\n\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        articles = []\n",
    "        \n",
    "        # Extract text and URL from each span\n",
    "        for i, span in enumerate(headline_spans, 1):\n",
    "            headline_text = span.get_text(strip=True)\n",
    "            article_url = span.get('data-zjs-href', 'N/A')\n",
    "            \n",
    "            articles.append({\n",
    "                'headline': headline_text,\n",
    "                'url': article_url\n",
    "            })\n",
    "            \n",
    "            print(f\"{i}. {headline_text}\")\n",
    "            print(f\"   ğŸ”— {article_url}\\n\")\n",
    "        \n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        return articles\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            print(\"\\nâœ“ Browser closed\")\n",
    "\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*100)\n",
    "    print(\"ğŸ” SCRAPING CNN FINANCE HEADLINES\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    articles = scrape_cnn_headlines(\"finance\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total headlines scraped: {len(articles)}\")\n",
    "    \n",
    "    if articles:\n",
    "        print(\"\\nğŸ’¾ Saving to file...\")\n",
    "        with open('cnn_headlines.txt', 'w', encoding='utf-8') as f:\n",
    "            for i, article in enumerate(articles, 1):\n",
    "                f.write(f\"{i}. {article['headline']}\\n\")\n",
    "                f.write(f\"   {article['url']}\\n\\n\")\n",
    "        print(\"âœ“ Saved to 'cnn_headlines.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b9c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ğŸ” SCRAPING CNN FINANCE HEADLINES\n",
      "====================================================================================================\n",
      "\n",
      "ğŸŒ Fetching: https://edition.cnn.com/search?q=finance&size=10&from=0&page=1&sort=newest&types=all&section=\n",
      "\n",
      "â³ Opening browser and loading page...\n",
      "\n",
      "âœ“ Browser started\n",
      "\n",
      "â³ Waiting for headlines to load...\n",
      "\n",
      "ğŸ“œ Scrolling to load all content...\n",
      "\n",
      "âœ“ Saved rendered HTML to 'debug_selenium_page.html'\n",
      "\n",
      "âœ“ Found 9 headlines:\n",
      "\n",
      "====================================================================================================\n",
      "1. The Fed just cut rates. Hereâ€™s how to make that move work for your money\n",
      "   ğŸ”— https://www.cnn.com/2025/09/17/business/your-money-federal-reserve-interest-rate-cut\n",
      "\n",
      "2. Stocks have literally never been this expensive\n",
      "   ğŸ”— https://www.cnn.com/2025/09/02/economy/us-stock-market\n",
      "\n",
      "3. Here are 4 ways lower interest rates could affect your personal finances\n",
      "   ğŸ”— https://www.cnn.com/2025/08/25/business/personal-finances-how-fed-interest-cut-affects-you\n",
      "\n",
      "4. Make your money work for you by â€˜ladderingâ€™ bonds or CDs\n",
      "   ğŸ”— https://www.cnn.com/2025/08/16/business/building-a-cd-or-bond-ladder\n",
      "\n",
      "5. Worried about money? Experts share how to prepare for hard times\n",
      "   ğŸ”— https://www.cnn.com/2025/08/04/health/financial-emotional-preparation-wellness\n",
      "\n",
      "6. Confused about the economy? Youâ€™re not alone\n",
      "   ğŸ”— https://www.cnn.com/2025/08/01/business/economy-explained\n",
      "\n",
      "7. This startup is working toward financial inclusion in Ivory Coast\n",
      "   ğŸ”— https://www.cnn.com/2025/07/31/world/video/djamo-fintech-ivory-coast-spc\n",
      "\n",
      "8. What drives financial fraud? It can come down to one emotion\n",
      "   ğŸ”— https://www.cnn.com/2025/07/13/economy/billionaire-boys-club-greed\n",
      "\n",
      "9. Making big financial decisions when the world is giving you heartburn\n",
      "   ğŸ”— https://www.cnn.com/2025/07/01/business/financial-decisions-money-anxiety\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "âœ“ Browser closed\n",
      "\n",
      "ğŸ“Š Total headlines scraped: 9\n",
      "\n",
      "ğŸ’¾ Saving to file...\n",
      "âœ“ Saved to 'cnn_headlines.txt'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN Headline Scraper with Selenium\n",
    "Handles JavaScript-rendered content\n",
    "\n",
    "Installation:\n",
    "pip install selenium webdriver-manager beautifulsoup4\n",
    "\n",
    "For Ubuntu/Linux, install Firefox:\n",
    "sudo apt-get update\n",
    "sudo apt-get install firefox\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_cnn_headlines(query=\"finance\", use_firefox=True):\n",
    "    \"\"\"Scrape headlines from CNN search using Selenium\"\"\"\n",
    "    \n",
    "    url = f\"https://edition.cnn.com/search?q={query}&size=10&from=0&page=1&sort=newest&types=all&section=\"\n",
    "    \n",
    "    print(f\"ğŸŒ Fetching: {url}\\n\")\n",
    "    print(\"â³ Opening browser and loading page...\\n\")\n",
    "    \n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        # Setup Firefox (more likely to be installed on Linux)\n",
    "        firefox_options = FirefoxOptions()\n",
    "        firefox_options.add_argument(\"--headless\")  # Run without GUI\n",
    "        firefox_options.add_argument(\"--no-sandbox\")\n",
    "        firefox_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        \n",
    "        service = FirefoxService(GeckoDriverManager().install())\n",
    "        driver = webdriver.Firefox(service=service, options=firefox_options)\n",
    "        \n",
    "        print(\"âœ“ Browser started\\n\")\n",
    "        \n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for content to load\n",
    "        print(\"â³ Waiting for headlines to load...\\n\")\n",
    "        time.sleep(5)  # Give it time to load\n",
    "        \n",
    "        # Scroll down multiple times to load all content\n",
    "        print(\"ğŸ“œ Scrolling to load all content...\\n\")\n",
    "        for i in range(5):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # Scroll back to top\n",
    "        driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Try to wait for span elements\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"container__headline-text\"))\n",
    "            )\n",
    "        except:\n",
    "            print(\"âš ï¸  Timeout waiting for headlines, continuing anyway...\\n\")\n",
    "        \n",
    "        # Get page source after JavaScript execution\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Save for debugging\n",
    "        with open('debug_selenium_page.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(page_source)\n",
    "        print(\"âœ“ Saved rendered HTML to 'debug_selenium_page.html'\\n\")\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find all span tags with class 'container__headline-text'\n",
    "        headline_spans = soup.find_all('span', class_='container__headline-text')\n",
    "        \n",
    "        print(f\"âœ“ Found {len(headline_spans)} headlines:\\n\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        articles = []\n",
    "        \n",
    "        # Extract text and URL from each span\n",
    "        for i, span in enumerate(headline_spans, 1):\n",
    "            headline_text = span.get_text(strip=True)\n",
    "            article_url = span.get('data-zjs-href', 'N/A')\n",
    "            \n",
    "            articles.append({\n",
    "                'headline': headline_text,\n",
    "                'url': article_url\n",
    "            })\n",
    "            \n",
    "            print(f\"{i}. {headline_text}\")\n",
    "            print(f\"   ğŸ”— {article_url}\\n\")\n",
    "        \n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        return articles\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            print(\"\\nâœ“ Browser closed\")\n",
    "\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*100)\n",
    "    print(\"ğŸ” SCRAPING CNN FINANCE HEADLINES\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    articles = scrape_cnn_headlines(\"finance\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total headlines scraped: {len(articles)}\")\n",
    "    \n",
    "    if articles:\n",
    "        print(\"\\nğŸ’¾ Saving to file...\")\n",
    "        with open('cnn_headlines.txt', 'w', encoding='utf-8') as f:\n",
    "            for i, article in enumerate(articles, 1):\n",
    "                f.write(f\"{i}. {article['headline']}\\n\")\n",
    "                f.write(f\"   {article['url']}\\n\\n\")\n",
    "        print(\"âœ“ Saved to 'cnn_headlines.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031d0b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ğŸ” CNN HEADLINE SCRAPER\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "ğŸ” Searching for: 'technology'\n",
      "\n",
      "ğŸŒ Fetching: https://edition.cnn.com/search?q=technology&size=10&from=0&page=1&sort=newest&types=all&section=\n",
      "\n",
      "â³ Opening browser and loading page...\n",
      "\n",
      "âœ“ Browser started\n",
      "\n",
      "â³ Waiting for headlines to load...\n",
      "\n",
      "ğŸ“œ Scrolling to load all content...\n",
      "\n",
      "âœ“ Saved rendered HTML to 'debug_selenium_page.html'\n",
      "\n",
      "âœ“ Found 8 headlines:\n",
      "\n",
      "====================================================================================================\n",
      "1. Exhausted? The reason may be how youâ€™re using technology\n",
      "   ğŸ”— https://www.cnn.com/2025/10/07/health/digital-exhaustion-solutions-book-wellness\n",
      "\n",
      "2. Fareedâ€™s take: America needs to get serious about Chinaâ€™s tech rise\n",
      "   ğŸ”— https://www.cnn.com/2025/10/05/world/video/gps-1005-take-china-tech-rise-dominance\n",
      "\n",
      "3. Google says 90% of tech workers are now using AI at work\n",
      "   ğŸ”— https://www.cnn.com/2025/09/23/tech/google-study-90-percent-tech-jobs-ai\n",
      "\n",
      "4. Angolan startup Anda is building a platform for human mobility\n",
      "   ğŸ”— https://www.cnn.com/2025/09/19/world/video/angola-business-startup-technology-fintech-digitization-motorcycles-mobility-future-anda-spc\n",
      "\n",
      "5. What happens when you put six tech bros in a room together? An artist used AI to find out\n",
      "   ğŸ”— https://www.cnn.com/2025/09/01/style/sputniko-tech-ai-artist-japan-hnk-spc\n",
      "\n",
      "6. AI companies have 'become more powerful than most nation states,' says tech journalist\n",
      "   ğŸ”— https://www.cnn.com/2025/08/26/Tv/video/amanpour-bianna-golodryga-karen-hao-empire-of-ai\n",
      "\n",
      "7. GPS Special: How technology is rewiring childhood\n",
      "   ğŸ”— https://www.cnn.com/2025/08/24/politics/video/gps-special-0824-technology-childhood-disconnected\n",
      "\n",
      "8. AI expert: â€˜Weâ€™ll be toastâ€™ without changes in AI technology\n",
      "   ğŸ”— https://www.cnn.com/2025/08/13/business/video/geoffrey-hinton-ai-threat-humanity-ac360-digvid\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "âœ“ Browser closed\n",
      "\n",
      "ğŸ“Š Total headlines scraped: 8\n",
      "\n",
      "ğŸ’¾ Saving to file...\n",
      "âœ“ Saved to 'cnn_headlines_technology.txt'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN Headline Scraper with Selenium\n",
    "Handles JavaScript-rendered content with manual query input\n",
    "\n",
    "Installation:\n",
    "pip install selenium webdriver-manager beautifulsoup4\n",
    "\n",
    "For Ubuntu/Linux, install Firefox:\n",
    "sudo apt-get update\n",
    "sudo apt-get install firefox\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_cnn_headlines(query, use_firefox=True):\n",
    "    \"\"\"Scrape headlines from CNN search using Selenium\"\"\"\n",
    "    \n",
    "    url = f\"https://edition.cnn.com/search?q={query}&size=10&from=0&page=1&sort=newest&types=all&section=\"\n",
    "    \n",
    "    print(f\"\\nğŸŒ Fetching: {url}\\n\")\n",
    "    print(\"â³ Opening browser and loading page...\\n\")\n",
    "    \n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        # Setup Firefox (more likely to be installed on Linux)\n",
    "        firefox_options = FirefoxOptions()\n",
    "        firefox_options.add_argument(\"--headless\")  # Run without GUI\n",
    "        firefox_options.add_argument(\"--no-sandbox\")\n",
    "        firefox_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        \n",
    "        service = FirefoxService(GeckoDriverManager().install())\n",
    "        driver = webdriver.Firefox(service=service, options=firefox_options)\n",
    "        \n",
    "        print(\"âœ“ Browser started\\n\")\n",
    "        \n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for content to load\n",
    "        print(\"â³ Waiting for headlines to load...\\n\")\n",
    "        time.sleep(5)  # Give it time to load\n",
    "        \n",
    "        # Scroll down multiple times to load all content\n",
    "        print(\"ğŸ“œ Scrolling to load all content...\\n\")\n",
    "        for i in range(5):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "        \n",
    "        # Scroll back to top\n",
    "        driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Try to wait for span elements\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"container__headline-text\"))\n",
    "            )\n",
    "        except:\n",
    "            print(\"âš ï¸  Timeout waiting for headlines, continuing anyway...\\n\")\n",
    "        \n",
    "        # Get page source after JavaScript execution\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Save for debugging\n",
    "        with open('debug_selenium_page.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(page_source)\n",
    "        print(\"âœ“ Saved rendered HTML to 'debug_selenium_page.html'\\n\")\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Find all span tags with class 'container__headline-text'\n",
    "        headline_spans = soup.find_all('span', class_='container__headline-text')\n",
    "        \n",
    "        print(f\"âœ“ Found {len(headline_spans)} headlines:\\n\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        articles = []\n",
    "        \n",
    "        # Extract text and URL from each span\n",
    "        for i, span in enumerate(headline_spans, 1):\n",
    "            headline_text = span.get_text(strip=True)\n",
    "            article_url = span.get('data-zjs-href', 'N/A')\n",
    "            \n",
    "            articles.append({\n",
    "                'headline': headline_text,\n",
    "                'url': article_url\n",
    "            })\n",
    "            \n",
    "            print(f\"{i}. {headline_text}\")\n",
    "            print(f\"   ğŸ”— {article_url}\\n\")\n",
    "        \n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        return articles\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            print(\"\\nâœ“ Browser closed\")\n",
    "\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*100)\n",
    "    print(\"ğŸ” CNN HEADLINE SCRAPER\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # Get search query from user\n",
    "    query = input(\"Enter your search query (e.g., finance, technology, sports): \").strip()\n",
    "    \n",
    "    if not query:\n",
    "        print(\"âŒ No query entered. Using default: 'finance'\")\n",
    "        query = \"finance\"\n",
    "    \n",
    "    print(f\"\\nğŸ” Searching for: '{query}'\")\n",
    "    \n",
    "    articles = scrape_cnn_headlines(query)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total headlines scraped: {len(articles)}\")\n",
    "    \n",
    "    if articles:\n",
    "        print(\"\\nğŸ’¾ Saving to file...\")\n",
    "        filename = f'cnn_headlines_{query.replace(\" \", \"_\")}.txt'\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"CNN Headlines for: {query}\\n\")\n",
    "            f.write(\"=\"*100 + \"\\n\\n\")\n",
    "            for i, article in enumerate(articles, 1):\n",
    "                f.write(f\"{i}. {article['headline']}\\n\")\n",
    "                f.write(f\"   {article['url']}\\n\\n\")\n",
    "        print(f\"âœ“ Saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3c9915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "ğŸ” THE NATIONAL NEWS HEADLINE SCRAPER\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Searching for: 'finance'\n",
      "\n",
      "ğŸŒ Fetching: https://www.thenationalnews.com/search/?query=finance\n",
      "\n",
      "â³ Opening browser and loading page...\n",
      "\n",
      "âœ“ Browser started\n",
      "\n",
      "â³ Waiting for search results to load...\n",
      "\n",
      "ğŸ“œ Scrolling to load all content...\n",
      "\n",
      "âœ“ Search results found\n",
      "\n",
      "âœ“ Saved rendered HTML to 'debug_thenational_page.html'\n",
      "\n",
      "ğŸ” Analyzing page structure...\n",
      "\n",
      "âœ“ Found 20 article containers\n",
      "\n",
      "====================================================================================================\n",
      "1. It's never too late to put your finances in shape\n",
      "   ğŸ”— https://www.thenationalnews.com/business/money/2025/09/24/its-never-too-late-to-put-your-finances-in-shape/\n",
      "   ğŸ“ Sep 24, 2025 -Have you looked at your financial situation and felt a knot in your stomach? Maybe you...\n",
      "\n",
      "2. New York's Met Opera in Saudi deal to boost shaky finances\n",
      "   ğŸ”— https://www.thenationalnews.com/news/us/2025/09/08/new-yorks-met-opera-in-saudi-deal-to-boost-shaky-finances/\n",
      "   ğŸ“ Sep 08, 2025 -The Metropolitan Opera, a stalwart of New York â€™s cultural life, has struck a deal wit...\n",
      "\n",
      "3. Terror financing investigations have 'significant holes' globally, report says\n",
      "   ğŸ”— https://www.thenationalnews.com/business/2025/07/07/most-countries-have-major-deficiencies-in-investigating-terrorism-finance-new-report-says/\n",
      "   ğŸ“ Jul 08, 2025 -A majority of countries have significant holes in how they investigate terrorism finan...\n",
      "\n",
      "4. Jordan arrests 11 on suspicion of Muslim Brotherhood financing\n",
      "   ğŸ”— https://www.thenationalnews.com/news/mena/2025/07/15/jordan-arrests-11-on-suspicion-of-muslim-brotherhood-financing/\n",
      "   ğŸ“ Jul 15, 2025 -Jordan has arrested 11 people on suspicion that they were involved in illegally raisin...\n",
      "\n",
      "5. Will crypto replace traditional finance in our daily lives?\n",
      "   ğŸ”— https://www.thenationalnews.com/business/money/2025/05/02/will-crypto-replace-traditional-finance-in-our-daily-lives/\n",
      "   ğŸ“ May 02, 2025 -Cryptocurrencies are rapidly gaining more popularity , but it will be a while before t...\n",
      "\n",
      "6. Pakistanâ€™s economy on right track, says Finance Minister Muhammad Aurangzeb\n",
      "   ğŸ”— https://www.thenationalnews.com/news/asia/2025/04/23/pakistans-economy-on-right-track-says-finance-minister-muhammad-aurangzeb/\n",
      "   ğŸ“ Apr 23, 2025 -The recent upgrade of Pakistanâ€™s credit rating by Fitch is â€œgood external validationâ€ ...\n",
      "\n",
      "7. Why the perception of Islamic finance as a conservative sector is outdated\n",
      "   ğŸ”— https://www.thenationalnews.com/business/money/2025/04/28/islamic-investing-shariah/\n",
      "   ğŸ“ Apr 28, 2025 -The UAE has built a reputation as a global financial hub, balancing conventional and I...\n",
      "\n",
      "8. UAE to provide $11bn in financing to industrial firms over next five years\n",
      "   ğŸ”— https://www.thenationalnews.com/business/economy/2025/05/19/uae-to-provide-11bn-in-financing-to-industrial-firms-over-next-five-years/\n",
      "   ğŸ“ May 19, 2025 -The UAE will provide industrial companies with more than Dh40 billion ($10.89 billion)...\n",
      "\n",
      "9. Eric Trump says crypto will take over traditional finance at Token2049 in Dubai\n",
      "   ğŸ”— https://www.thenationalnews.com/business/money/2025/05/01/eric-trump-cryptos/\n",
      "   ğŸ“ May 01, 2025 -Cryptocurrencies will take over the traditional finance system and leave big banks in ...\n",
      "\n",
      "10. UK Chancellor Rachel Reeves eases finance industry worries with investment push\n",
      "   ğŸ”— https://www.thenationalnews.com/news/uk/2025/03/25/rachel-reeves-eases-finance-industry-worries-with-investment-push/\n",
      "   ğŸ“ Mar 26, 2025 -Finance industry leaders are looking for an uplift from UK Chancellor Rachel Reeves as...\n",
      "\n",
      "11. US offers $10m for information on Hezbollah financing network\n",
      "   ğŸ”— https://www.thenationalnews.com/news/us/2025/03/17/us-offers-10m-for-information-on-hezbollah-financing-network/\n",
      "   ğŸ“ Mar 18, 2025 -The US State Department is offering a reward of up to $10 million for information on L...\n",
      "\n",
      "12. Syrian leadership to rub shoulders with global finance heads in Washington\n",
      "   ğŸ”— https://www.thenationalnews.com/news/mena/2025/04/15/syria-to-rub-shoulders-with-global-finance-leaders-in-washington/\n",
      "   ğŸ“ Apr 15, 2025 -Members of the Syrian government will attend major financial talks in Washington next ...\n",
      "\n",
      "13. McLaren plans more tech investment to boost operations, finance chief says\n",
      "   ğŸ”— https://www.thenationalnews.com/future/technology/2025/03/05/mclaren-plans-more-tech-investment-to-boost-operations-finance-chief-says/\n",
      "   ğŸ“ Mar 05, 2025 -British Formula One team McLaren Racing is open to investing in more technology platfo...\n",
      "\n",
      "14. How buying off-plan property is now an alternative to mortgage financing\n",
      "   ğŸ”— https://www.thenationalnews.com/business/money/2025/04/01/dubai-offplan-property/\n",
      "   ğŸ“ Apr 01, 2025 -Dubaiâ€™s real estate landscape is constantly evolving, and investors are looking for sm...\n",
      "\n",
      "15. Ray Dalio backs NYU Abu Dhabi's global index ranking top financial centres\n",
      "   ğŸ”— https://www.thenationalnews.com/business/economy/2025/10/09/ray-dalio-backs-nyu-abu-dhabis-global-index-ranking-top-financial-centres/\n",
      "   ğŸ“ Oct 09, 2025 -The NYU Stern School of Business at NYU Abu Dhabi has launched the The Institute for G...\n",
      "\n",
      "16. How to plan your finances for buying a home\n",
      "   ğŸ”— https://www.thenationalnews.com/business/money/2025/03/12/how-to-plan-your-finances-for-buying-a-home/\n",
      "   ğŸ“ Mar 12, 2025 -Buying a home is one of the most significant financial milestones in anyones life. It ...\n",
      "\n",
      "17. How UAE sovereign wealth funds are evolving to shape global finance\n",
      "   ğŸ”— https://www.thenationalnews.com/opinion/comment/2025/04/02/uae-sovereign-wealth-funds-business-economy-investing/\n",
      "   ğŸ“ Apr 02, 2025 -Sovereign wealth funds have long played a critical role in maintaining economic stabil...\n",
      "\n",
      "18. Iraqi President sues Prime Minister and Finance Minister over delayed KRG salaries\n",
      "   ğŸ”— https://www.thenationalnews.com/news/mena/2025/02/10/iraqi-president-sues-prime-minister-and-finance-minister-over-delayed-krg-salaries/\n",
      "   ğŸ“ Feb 10, 2025 -Iraqi President Abdul Latif Rashid has taken legal action against Prime Minister Moham...\n",
      "\n",
      "19. Finance Ministry at the heart of Lebanonâ€™s convoluted cabinet consultations\n",
      "   ğŸ”— https://www.thenationalnews.com/news/mena/2025/01/30/finance-ministry-at-the-heart-of-lebanons-convoluted-cabinet-consultations/\n",
      "   ğŸ“ Jan 30, 2025 -More than two weeks after Nawaf Salam was designated as Lebanons next Prime Minister, ...\n",
      "\n",
      "20. Abu Dhabi Finance Week to begin today as emirate brings influx of global asset managers\n",
      "   ğŸ”— https://www.thenationalnews.com/business/economy/2024/12/09/abu-dhabi-finance-week-to-begin-today-as-emirate-brings-influx-of-global-asset-managers/\n",
      "   ğŸ“ Dec 09, 2024 -Abu Dhabi Finance Week, ADGM s key financial event, will begin today as the UAE capita...\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "âœ“ Browser closed\n",
      "\n",
      "ğŸ“Š Total headlines scraped: 20\n",
      "\n",
      "ğŸ’¾ Saving to file...\n",
      "âœ“ Saved to 'thenational_headlines_finance.txt'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The National News Headline Scraper with Selenium\n",
    "Handles JavaScript-rendered content with manual query input\n",
    "\n",
    "Installation:\n",
    "pip install selenium webdriver-manager beautifulsoup4\n",
    "\n",
    "For Ubuntu/Linux, install Firefox:\n",
    "sudo apt-get update\n",
    "sudo apt-get install firefox\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_thenational_headlines(query, headless=True):\n",
    "    \"\"\"Scrape headlines from The National News search using Selenium\n",
    "    \n",
    "    Args:\n",
    "        query: Search term\n",
    "        headless: If False, browser window will be visible (useful for debugging)\n",
    "    \"\"\"\n",
    "    \n",
    "    # The National News search URL\n",
    "    url = f\"https://www.thenationalnews.com/search/?query={query.replace(' ', '+')}\"\n",
    "    \n",
    "    print(f\"\\nğŸŒ Fetching: {url}\\n\")\n",
    "    print(\"â³ Opening browser and loading page...\\n\")\n",
    "    \n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        # Setup Firefox\n",
    "        firefox_options = FirefoxOptions()\n",
    "        if headless:\n",
    "            firefox_options.add_argument(\"--headless\")  # Run without GUI\n",
    "        firefox_options.add_argument(\"--no-sandbox\")\n",
    "        firefox_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        firefox_options.add_argument(\"--window-size=1920,1080\")\n",
    "        \n",
    "        # Add user agent to appear as a real browser\n",
    "        firefox_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "        \n",
    "        service = FirefoxService(GeckoDriverManager().install())\n",
    "        driver = webdriver.Firefox(service=service, options=firefox_options)\n",
    "        \n",
    "        print(\"âœ“ Browser started\\n\")\n",
    "        \n",
    "        # Load the page\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for content to load\n",
    "        print(\"â³ Waiting for search results to load...\\n\")\n",
    "        time.sleep(8)  # Give it time to load\n",
    "        \n",
    "        # Scroll down multiple times to load all content\n",
    "        print(\"ğŸ“œ Scrolling to load all content...\\n\")\n",
    "        for i in range(5):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(3)\n",
    "        \n",
    "        # Scroll back to top\n",
    "        driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Try to wait for queryly items\n",
    "        try:\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"queryly_item_row\"))\n",
    "            )\n",
    "            print(\"âœ“ Search results found\\n\")\n",
    "        except:\n",
    "            print(\"âš ï¸  Timeout waiting for results, continuing anyway...\\n\")\n",
    "        \n",
    "        # Get page source after JavaScript execution\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Save for debugging\n",
    "        with open('debug_thenational_page.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(page_source)\n",
    "        print(\"âœ“ Saved rendered HTML to 'debug_thenational_page.html'\\n\")\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        print(\"ğŸ” Analyzing page structure...\\n\")\n",
    "        \n",
    "        # Find all queryly_item_row divs\n",
    "        item_rows = soup.find_all('div', class_='queryly_item_row')\n",
    "        \n",
    "        print(f\"âœ“ Found {len(item_rows)} article containers\\n\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        articles = []\n",
    "        \n",
    "        # Extract data from each item\n",
    "        for i, row in enumerate(item_rows, 1):\n",
    "            # Find the title div\n",
    "            title_div = row.find('div', class_='queryly_item_title')\n",
    "            \n",
    "            # Find the link (parent <a> tag)\n",
    "            link_tag = row.find('a')\n",
    "            \n",
    "            if title_div and link_tag:\n",
    "                headline_text = title_div.get_text(strip=True)\n",
    "                article_url = link_tag.get('href', 'N/A')\n",
    "                \n",
    "                # Make URL absolute if it's relative\n",
    "                if article_url.startswith('/'):\n",
    "                    article_url = f\"https://www.thenationalnews.com{article_url}\"\n",
    "                \n",
    "                # Extract description if available\n",
    "                desc_div = row.find('div', class_='queryly_item_description')\n",
    "                description = desc_div.get_text(strip=True) if desc_div else 'N/A'\n",
    "                \n",
    "                articles.append({\n",
    "                    'headline': headline_text,\n",
    "                    'url': article_url,\n",
    "                    'description': description\n",
    "                })\n",
    "                \n",
    "                print(f\"{i}. {headline_text}\")\n",
    "                print(f\"   ğŸ”— {article_url}\")\n",
    "                if description != 'N/A':\n",
    "                    # Truncate long descriptions\n",
    "                    short_desc = description[:100] + '...' if len(description) > 100 else description\n",
    "                    print(f\"   ğŸ“ {short_desc}\")\n",
    "                print()\n",
    "        \n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        return articles\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "    \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            print(\"\\nâœ“ Browser closed\")\n",
    "\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*100)\n",
    "    print(\"ğŸ” THE NATIONAL NEWS HEADLINE SCRAPER\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # Get search query from user\n",
    "    query = input(\"Enter your search query (e.g., finance, technology, sports): \").strip()\n",
    "    \n",
    "    if not query:\n",
    "        print(\"âŒ No query entered. Using default: 'finance'\")\n",
    "        query = \"finance\"\n",
    "    \n",
    "    print(f\"\\nğŸ” Searching for: '{query}'\")\n",
    "    \n",
    "    # Ask if user wants to see the browser (for debugging)\n",
    "    debug_mode = input(\"\\nRun in DEBUG mode (see browser window)? (y/n): \").strip().lower()\n",
    "    headless = debug_mode != 'y'\n",
    "    \n",
    "    if not headless:\n",
    "        print(\"ğŸ” DEBUG MODE: Browser window will be visible\\n\")\n",
    "    \n",
    "    articles = scrape_thenational_headlines(query, headless)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total headlines scraped: {len(articles)}\")\n",
    "    \n",
    "    if articles:\n",
    "        print(\"\\nğŸ’¾ Saving to file...\")\n",
    "        filename = f'thenational_headlines_{query.replace(\" \", \"_\")}.txt'\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"The National News Headlines for: {query}\\n\")\n",
    "            f.write(\"=\"*100 + \"\\n\\n\")\n",
    "            for i, article in enumerate(articles, 1):\n",
    "                f.write(f\"{i}. {article['headline']}\\n\")\n",
    "                f.write(f\"   URL: {article['url']}\\n\")\n",
    "                if article['description'] != 'N/A':\n",
    "                    f.write(f\"   Description: {article['description']}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        print(f\"âœ“ Saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "291a018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GST Council PDF Scraper...\n",
      "\n",
      "Fetching page 1...\n",
      "Found 3 PDFs on page 1\n",
      "Fetching page 2...\n",
      "Found 7 PDFs on page 2\n",
      "Fetching page 3...\n",
      "Found 10 PDFs on page 3\n",
      "Fetching page 4...\n",
      "Found 9 PDFs on page 4\n",
      "Fetching page 5...\n",
      "Found 10 PDFs on page 5\n",
      "Fetching page 6...\n",
      "Found 10 PDFs on page 6\n",
      "Fetching page 7...\n",
      "Found 10 PDFs on page 7\n",
      "Fetching page 8...\n",
      "Found 10 PDFs on page 8\n",
      "Fetching page 9...\n",
      "Found 6 PDFs on page 9\n",
      "\n",
      "Total PDFs found: 75\n",
      "\n",
      "Processing 1/75: Frequently Asked Questions (FAQs) on the decisions...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2025-09/faq.pdf\n",
      "Saved PDF: pdfs\\001_03-09-2025.pdf\n",
      "Saved text: pdf_texts\\001_03-09-2025.txt\n",
      "\n",
      "Processing 2/75: Recommendations of the 56th Meeting of the GST Cou...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2025-09/press_release_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\002_03-09-2025.pdf\n",
      "Saved text: pdf_texts\\002_03-09-2025.txt\n",
      "\n",
      "Processing 3/75: Recommendations during 54th meeting of the GST Cou...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-09/pib2053233.pdf\n",
      "Saved PDF: pdfs\\003_10-09-2024.pdf\n",
      "Saved text: pdf_texts\\003_10-09-2024.txt\n",
      "\n",
      "Processing 4/75: 51st Meeting of the GST Council...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/press-release-51-gstc.pdf\n",
      "Saved PDF: pdfs\\004_07-08-2023.pdf\n",
      "Saved text: pdf_texts\\004_07-08-2023.txt\n",
      "\n",
      "Processing 5/75: 50th Meeting of the GST Council...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/press_release_50.pdf\n",
      "Saved PDF: pdfs\\005_13-07-2023.pdf\n",
      "Saved text: pdf_texts\\005_13-07-2023.txt\n",
      "\n",
      "Processing 6/75: Recommendations of 49th GST Council Meeting...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/reeccomendations_of_49_meeting.pdf\n",
      "Saved PDF: pdfs\\006_18-02-2023.pdf\n",
      "Saved text: pdf_texts\\006_18-02-2023.txt\n",
      "\n",
      "Processing 7/75: Rs 1,49,507 crore GST Revenue collected for Decemb...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pib1887876.pdf\n",
      "Saved PDF: pdfs\\007_02-01-2023.pdf\n",
      "Saved text: pdf_texts\\007_02-01-2023.txt\n",
      "\n",
      "Processing 8/75: Union Finance Minister Smt. Nirmala Sitharaman cha...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pib1884399.pdf\n",
      "Saved PDF: pdfs\\008_17-12-2022.pdf\n",
      "Saved text: pdf_texts\\008_17-12-2022.txt\n",
      "\n",
      "Processing 9/75: Clarification regarding time limit for certain com...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pib1865179.pdf\n",
      "Saved PDF: pdfs\\009_07-10-2022.pdf\n",
      "Saved text: pdf_texts\\009_07-10-2022.txt\n",
      "\n",
      "Processing 10/75: â‚¹1,43,612 crore gross GST revenue collected in the...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressreleasepage_august2022.pdf\n",
      "Saved PDF: pdfs\\010_01-09-2022.pdf\n",
      "Saved text: pdf_texts\\010_01-09-2022.txt\n",
      "\n",
      "Processing 11/75: Recommendations of 47th GST Council Meeting...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pib1838020.pdf\n",
      "Saved PDF: pdfs\\011_29-06-2022.pdf\n",
      "Saved text: pdf_texts\\011_29-06-2022.txt\n",
      "\n",
      "Processing 12/75: â‚¹1,40,885 crore gross GST Revenue collection for M...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressreleasepage_1junee_2022.pdf\n",
      "Saved PDF: pdfs\\012_01-06-2022.pdf\n",
      "Saved text: pdf_texts\\012_01-06-2022.txt\n",
      "\n",
      "Processing 13/75: Centre Clears Entire GST Compensation Due Till Dat...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressreleasepage_1june2022.pdf\n",
      "Saved PDF: pdfs\\013_01-06-2022.pdf\n",
      "Saved text: pdf_texts\\013_01-06-2022.txt\n",
      "\n",
      "Processing 14/75: GST Revenue collection for April 2022 highest ever...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressreleasepage_2may2022.pdf\n",
      "Saved PDF: pdfs\\014_02-05-2022.pdf\n",
      "Saved text: pdf_texts\\014_02-05-2022.txt\n",
      "\n",
      "Processing 15/75: 2.78 lakh crore of compensation released to States...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pib1820749_28april2022.pdf\n",
      "Saved PDF: pdfs\\015_28-04-2022.pdf\n",
      "Saved text: pdf_texts\\015_28-04-2022.txt\n",
      "\n",
      "Processing 16/75: Average monthly gross GST collection for third qua...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressreleasepage_april_2022.pdf\n",
      "Saved PDF: pdfs\\016_05-04-2022.pdf\n",
      "Saved text: pdf_texts\\016_05-04-2022.txt\n",
      "\n",
      "Processing 17/75: Key Features of Union Budget 2022-23...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/key_features_of_union_budget_2022-23.pdf\n",
      "Saved PDF: pdfs\\017_03-02-2022.pdf\n",
      "Saved text: pdf_texts\\017_03-02-2022.txt\n",
      "\n",
      "Processing 18/75: Summary of Economic Survey 2021-22...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/summary_of_economic_survey.pdf\n",
      "Saved PDF: pdfs\\018_01-02-2022.pdf\n",
      "Saved text: pdf_texts\\018_01-02-2022.txt\n",
      "\n",
      "Processing 19/75: Finance Minister Smt. Nirmala Sitharaman authorise...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease21012022.pdf\n",
      "Saved PDF: pdfs\\019_21-01-2022.pdf\n",
      "Saved text: pdf_texts\\019_21-01-2022.txt\n",
      "\n",
      "Processing 20/75: 46th GST Council Meeting Press Release Dated 31.12...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/46th_gst_council_press_release_final.pdf\n",
      "Saved PDF: pdfs\\020_04-01-2022.pdf\n",
      "Saved text: pdf_texts\\020_04-01-2022.txt\n",
      "\n",
      "Processing 21/75: Gross GST Collection in FY 2021-22 shows increasin...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease29112021.pdf\n",
      "Saved PDF: pdfs\\021_29-11-2021.pdf\n",
      "Saved text: pdf_texts\\021_29-11-2021.txt\n",
      "\n",
      "Processing 22/75: CBIC Chairman inaugurates Customs & GST pavilion a...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease15112021.pdf\n",
      "Saved PDF: pdfs\\022_15-11-2021.pdf\n",
      "Saved text: pdf_texts\\022_15-11-2021.txt\n",
      "\n",
      "Processing 23/75: Centre releases Rs. 17,000 crore as GST Compensati...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease03112021.pdf\n",
      "Saved PDF: pdfs\\023_03-11-2021.pdf\n",
      "Saved text: pdf_texts\\023_03-11-2021.txt\n",
      "\n",
      "Processing 24/75: Government of India releases balance amount of â‚¹ 4...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease28102021.pdf\n",
      "Saved PDF: pdfs\\024_28-10-2021.pdf\n",
      "Saved text: pdf_texts\\024_28-10-2021.txt\n",
      "\n",
      "Processing 25/75: Government of India releases â‚¹ 40,000 crore to Sta...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease07102021.pdf\n",
      "Saved PDF: pdfs\\025_07-10-2021.pdf\n",
      "Saved text: pdf_texts\\025_07-10-2021.txt\n",
      "\n",
      "Processing 26/75: Recommendations of 45th GST Council Meeting...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/recommendations_of_45th_gst_council_meeting.pdf\n",
      "Saved PDF: pdfs\\026_20-09-2021.pdf\n",
      "Saved text: pdf_texts\\026_20-09-2021.txt\n",
      "\n",
      "Processing 27/75: Recommendations of 44th GST Council Meeting Change...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pib1726525.pdf\n",
      "Saved PDF: pdfs\\027_12-06-2021.pdf\n",
      "Saved text: pdf_texts\\027_12-06-2021.txt\n",
      "\n",
      "Processing 28/75: Recommendations of 43rd GST Council meeting...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/press-release-pib-43rd-gstcm-n-1.pdf\n",
      "Saved PDF: pdfs\\028_28-05-2021.pdf\n",
      "Saved text: pdf_texts\\028_28-05-2021.txt\n",
      "\n",
      "Processing 29/75: Press release on the mandatory use of HSN/SAC on G...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/press_release_hs_code_sac_issue.pdf\n",
      "Saved PDF: pdfs\\029_31-03-2021.pdf\n",
      "Saved text: pdf_texts\\029_31-03-2021.txt\n",
      "\n",
      "Processing 30/75: Press Release issued on extending the date of furn...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease-30dec.pdf\n",
      "Saved PDF: pdfs\\030_30-12-2020.pdf\n",
      "Saved text: pdf_texts\\030_30-12-2020.txt\n",
      "\n",
      "Processing 31/75: Press Release on Annual Return (GSTR-9) and Reconc...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/annualreturnpressrelease_09102020.pdf\n",
      "Saved PDF: pdfs\\031_09-10-2020.pdf\n",
      "Saved text: pdf_texts\\031_09-10-2020.txt\n",
      "\n",
      "Processing 32/75: Finance Minister Strive to make GST Tax Administra...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/press-release-gst-day-20.pdf\n",
      "Saved PDF: pdfs\\032_01-07-2020.pdf\n",
      "Saved text: pdf_texts\\032_01-07-2020.txt\n",
      "\n",
      "Processing 33/75: Press Release of message from Hon'ble Finance Mini...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/mos-gst-day.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0xb4d0a for key /Info\n",
      "Multiple definitions in dictionary at byte 0xb4d17 for key /Info\n",
      "Multiple definitions in dictionary at byte 0xb4d24 for key /Info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PDF: pdfs\\033_01-07-2020.pdf\n",
      "\n",
      "Processing 34/75: CBIC introduces machine release of goods...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-02/pressrelease_0602.pdf\n",
      "Saved PDF: pdfs\\034_06-02-2020.pdf\n",
      "Saved text: pdf_texts\\034_06-02-2020.txt\n",
      "\n",
      "Processing 35/75: GST rate on all Electric Vehicles reduced from 12%...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/36_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\035_27-07-2019.pdf\n",
      "Saved text: pdf_texts\\035_27-07-2019.txt\n",
      "\n",
      "Processing 36/75: FM chairs the 35th GST Council Meeting held today ...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/35_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\036_21-06-2019.pdf\n",
      "Saved text: pdf_texts\\036_21-06-2019.txt\n",
      "\n",
      "Processing 37/75: FM chairs 35th GST Council meeting in Delhi; decis...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/8.35th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\037_21-06-2019.pdf\n",
      "Saved text: pdf_texts\\037_21-06-2019.txt\n",
      "\n",
      "Processing 38/75: GST Council decisions on rate changes on supply of...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/17.35th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\038_21-06-2019.pdf\n",
      "Saved text: pdf_texts\\038_21-06-2019.txt\n",
      "\n",
      "Processing 39/75: GST Council decision relating to changes in law an...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/21.35th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\039_21-06-2019.pdf\n",
      "Saved text: pdf_texts\\039_21-06-2019.txt\n",
      "\n",
      "Processing 40/75: Decisions taken by the GST Council in the 34thmeet...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/34th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\040_19-03-2019.pdf\n",
      "Saved text: pdf_texts\\040_19-03-2019.txt\n",
      "\n",
      "Processing 41/75: Recommendations of the 33rd GST Council meeting...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/33rd_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\041_24-02-2019.pdf\n",
      "Saved text: pdf_texts\\041_24-02-2019.txt\n",
      "\n",
      "Processing 42/75: Major Decisions taken by the GST Council in its 32...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/32nd_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\042_10-01-2019.pdf\n",
      "Saved text: pdf_texts\\042_10-01-2019.txt\n",
      "\n",
      "Processing 43/75: Recommendations made by the GST Council in its 32 ...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/7.32nd_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\043_10-01-2019.pdf\n",
      "Saved text: pdf_texts\\043_10-01-2019.txt\n",
      "\n",
      "Processing 44/75: Recommendations made during 31st Meeting of the GS...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/31st_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\044_22-12-2018.pdf\n",
      "Saved text: pdf_texts\\044_22-12-2018.txt\n",
      "\n",
      "Processing 45/75: Formation of GoM as Recommended by the GST Council...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/20.31st_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\045_22-12-2018.pdf\n",
      "Saved text: pdf_texts\\045_22-12-2018.txt\n",
      "\n",
      "Processing 46/75: Recommendations made during 31 Meeting of the GST ...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/3.31st_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\046_22-12-2018.pdf\n",
      "Saved text: pdf_texts\\046_22-12-2018.txt\n",
      "\n",
      "Processing 47/75: In-Principle approval given for Law Amendments dur...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/18.31st_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\047_22-12-2018.pdf\n",
      "Saved text: pdf_texts\\047_22-12-2018.txt\n",
      "\n",
      "Processing 48/75: Decisions taken by the GST Council in the 31st mee...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/6.31st_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\048_22-12-2018.pdf\n",
      "Saved text: pdf_texts\\048_22-12-2018.txt\n",
      "\n",
      "Processing 49/75: Constitution of Group of Ministers (GoM) to examin...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/30th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\049_22-09-2018.pdf\n",
      "Saved text: pdf_texts\\049_22-09-2018.txt\n",
      "\n",
      "Processing 50/75: GST COUNCIL RECOMMENDS GST RATES REDUCTION ON SEVE...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/28th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\050_21-07-2018.pdf\n",
      "Saved text: pdf_texts\\050_21-07-2018.txt\n",
      "\n",
      "Processing 51/75: Recommendations made during the 28thmeeting of the...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/5.28th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\051_21-07-2018.pdf\n",
      "Saved text: pdf_texts\\051_21-07-2018.txt\n",
      "\n",
      "Processing 52/75: GST council approves Simplified GST Return...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/19.28th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\052_21-07-2018.pdf\n",
      "Saved text: pdf_texts\\052_21-07-2018.txt\n",
      "\n",
      "Processing 53/75: GST rate on Services...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/16.28th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\053_21-07-2018.pdf\n",
      "Saved text: pdf_texts\\053_21-07-2018.txt\n",
      "\n",
      "Processing 54/75: GST Council approves principles for filing of new ...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/27th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\054_04-05-2018.pdf\n",
      "Saved text: pdf_texts\\054_04-05-2018.txt\n",
      "\n",
      "Processing 55/75: 27th GST council meeting discusses change in GST r...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/4.27th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\055_04-05-2018.pdf\n",
      "Saved text: pdf_texts\\055_04-05-2018.txt\n",
      "\n",
      "Processing 56/75: Recommendations made during the 26th meeting of th...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/26th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\056_10-03-2018.pdf\n",
      "Saved text: pdf_texts\\056_10-03-2018.txt\n",
      "\n",
      "Processing 57/75: Recommendations regarding E-way Bill made during m...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/22.26th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\057_10-03-2018.pdf\n",
      "Saved text: pdf_texts\\057_10-03-2018.txt\n",
      "\n",
      "Processing 58/75: 26th Meeting of the GST Council meets & decides Ex...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/18.26th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\058_10-03-2018.pdf\n",
      "Saved text: pdf_texts\\058_10-03-2018.txt\n",
      "\n",
      "Processing 59/75: Recommendations regarding Data Analytics made duri...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/15.26th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\059_10-03-2018.pdf\n",
      "Saved text: pdf_texts\\059_10-03-2018.txt\n",
      "\n",
      "Processing 60/75: Policy Changes recommended by the 25th GST Council...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/12.25th_gst_press_information_bureau_2.pdf\n",
      "Saved PDF: pdfs\\060_18-01-2018.pdf\n",
      "Saved text: pdf_texts\\060_18-01-2018.txt\n",
      "\n",
      "Processing 61/75: Recommendations for Changes In GST/IGST Rate and C...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/13.25th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\061_18-01-2018.pdf\n",
      "Saved text: pdf_texts\\061_18-01-2018.txt\n",
      "\n",
      "Processing 62/75: Recommendations made on GST Rate changes on servic...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/25th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\062_18-01-2018.pdf\n",
      "Saved text: pdf_texts\\062_18-01-2018.txt\n",
      "\n",
      "Processing 63/75: The 24th GST Council Meeting held today through vi...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/24th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\063_16-12-2017.pdf\n",
      "Saved text: pdf_texts\\063_16-12-2017.txt\n",
      "\n",
      "Processing 64/75: Recommendations made On GST Rate changes by the GS...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/2._23rd_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\064_10-11-2017.pdf\n",
      "Saved text: pdf_texts\\064_10-11-2017.txt\n",
      "\n",
      "Processing 65/75: Changes recommended in Composition Scheme...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/10.23rd_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\065_10-11-2017.pdf\n",
      "Saved text: pdf_texts\\065_10-11-2017.txt\n",
      "\n",
      "Processing 66/75: Recommendations made by the GST Council in the 23r...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/23rd_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\066_10-11-2017.pdf\n",
      "Saved text: pdf_texts\\066_10-11-2017.txt\n",
      "\n",
      "Processing 67/75: GST Rates on Services Decisions taken by the GST C...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/9.22nd_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\067_06-10-2017.pdf\n",
      "Saved text: pdf_texts\\067_06-10-2017.txt\n",
      "\n",
      "Processing 68/75: Recommendations made by the GST Council in its 22n...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/22nd_gst-press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\068_06-10-2017.pdf\n",
      "Saved text: pdf_texts\\068_06-10-2017.txt\n",
      "\n",
      "Processing 69/75: Changes in GST Rates for Goods and IGST Rates on I...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/1.22nd_gst_press_information_bureau_0.pdf\n",
      "Saved PDF: pdfs\\069_06-10-2017.pdf\n",
      "Saved text: pdf_texts\\069_06-10-2017.txt\n",
      "\n",
      "Processing 70/75: Recommendations made by the GST Council in the 21s...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/21st_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\070_09-09-2017.pdf\n",
      "Saved text: pdf_texts\\070_09-09-2017.txt\n",
      "\n",
      "Processing 71/75: Increase in the Compensation Cess rate on cigarett...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/19h_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\071_17-07-2017.pdf\n",
      "Saved text: pdf_texts\\071_17-07-2017.txt\n",
      "\n",
      "Processing 72/75: GST roll-out â€“ Complete transformation of the Indi...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/18h_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\072_30-06-2017.pdf\n",
      "Saved text: pdf_texts\\072_30-06-2017.txt\n",
      "\n",
      "Processing 73/75: Relaxation in return filing procedure for first tw...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/17_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\073_18-06-2017.pdf\n",
      "Saved text: pdf_texts\\073_18-06-2017.txt\n",
      "\n",
      "Processing 74/75: The 14th Goods and Services Tax (GST) Council meet...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/14_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\074_19-05-2017.pdf\n",
      "Saved text: pdf_texts\\074_19-05-2017.txt\n",
      "\n",
      "Processing 75/75: Goods and Services Tax GST) Council approves the C...\n",
      "Downloading: https://gstcouncil.gov.in/sites/default/files/2024-10/11th_gst_press_information_bureau.pdf\n",
      "Saved PDF: pdfs\\075_04-03-2017.pdf\n",
      "Saved text: pdf_texts\\075_04-03-2017.txt\n",
      "\n",
      "Metadata saved to pdf_metadata.json\n",
      "\n",
      "================================================================================\n",
      "Scraping complete!\n",
      "Total PDFs processed: 75\n",
      "PDFs saved in: ./pdfs/\n",
      "Text files saved in: ./pdf_texts/\n",
      "Metadata saved in: ./pdf_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "class GSTCouncilPDFScraper:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        })\n",
    "        self.pdf_data = []\n",
    "        \n",
    "    def get_page_content(self, page_num=0):\n",
    "        \"\"\"Fetch content from a specific page\"\"\"\n",
    "        url = f\"{self.base_url}?page={page_num}\"\n",
    "        print(f\"Fetching page {page_num + 1}...\")\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching page {page_num}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_pdf_links(self, html_content):\n",
    "        \"\"\"Extract all PDF links from the HTML content\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        pdf_links = []\n",
    "        \n",
    "        # Find all rows in the table\n",
    "        rows = soup.find_all('tr')\n",
    "        \n",
    "        for row in rows:\n",
    "            # Find PDF links in each row\n",
    "            link_tag = row.find('a', href=lambda x: x and x.endswith('.pdf'))\n",
    "            if link_tag:\n",
    "                href = link_tag.get('href')\n",
    "                title = link_tag.get_text(strip=True)\n",
    "                \n",
    "                # Get date from the row\n",
    "                date_cell = row.find('td', class_='views-field-field-date-of-uploading')\n",
    "                date = date_cell.get_text(strip=True) if date_cell else 'Unknown'\n",
    "                \n",
    "                pdf_links.append({\n",
    "                    'url': href,\n",
    "                    'title': title,\n",
    "                    'date': date\n",
    "                })\n",
    "        \n",
    "        return pdf_links\n",
    "    \n",
    "    def download_pdf(self, pdf_url):\n",
    "        \"\"\"Download PDF and return content as bytes\"\"\"\n",
    "        # Handle relative URLs\n",
    "        if pdf_url.startswith('/'):\n",
    "            # Extract base domain from base_url\n",
    "            from urllib.parse import urlparse\n",
    "            parsed = urlparse(self.base_url)\n",
    "            full_url = f\"{parsed.scheme}://{parsed.netloc}{pdf_url}\"\n",
    "        else:\n",
    "            full_url = pdf_url\n",
    "        \n",
    "        print(f\"Downloading: {full_url}\")\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(full_url, timeout=60)\n",
    "            response.raise_for_status()\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading PDF {full_url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_content):\n",
    "        \"\"\"Extract text from PDF bytes\"\"\"\n",
    "        try:\n",
    "            pdf_file = io.BytesIO(pdf_content)\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            \n",
    "            text = \"\"\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\\n\"\n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from PDF: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def scrape_all_pages(self, total_pages=9):\n",
    "        \"\"\"Scrape PDFs from all pages\"\"\"\n",
    "        all_pdf_links = []\n",
    "        \n",
    "        # Iterate through all pages\n",
    "        for page_num in range(total_pages):\n",
    "            html_content = self.get_page_content(page_num)\n",
    "            \n",
    "            if html_content:\n",
    "                pdf_links = self.extract_pdf_links(html_content)\n",
    "                all_pdf_links.extend(pdf_links)\n",
    "                print(f\"Found {len(pdf_links)} PDFs on page {page_num + 1}\")\n",
    "            \n",
    "            # Be respectful with requests\n",
    "            time.sleep(2)\n",
    "        \n",
    "        print(f\"\\nTotal PDFs found: {len(all_pdf_links)}\")\n",
    "        return all_pdf_links\n",
    "    \n",
    "    def process_pdfs(self, pdf_links, save_pdfs=True, save_text=True):\n",
    "        \"\"\"Download and extract content from all PDFs\"\"\"\n",
    "        \n",
    "        # Create directories\n",
    "        if save_pdfs:\n",
    "            os.makedirs('pdfs', exist_ok=True)\n",
    "        if save_text:\n",
    "            os.makedirs('pdf_texts', exist_ok=True)\n",
    "        \n",
    "        for idx, pdf_info in enumerate(pdf_links, 1):\n",
    "            print(f\"\\nProcessing {idx}/{len(pdf_links)}: {pdf_info['title'][:50]}...\")\n",
    "            \n",
    "            # Download PDF\n",
    "            pdf_content = self.download_pdf(pdf_info['url'])\n",
    "            \n",
    "            if pdf_content:\n",
    "                # Generate safe filename\n",
    "                safe_filename = f\"{idx:03d}_{pdf_info['date'].replace('/', '-')}\"\n",
    "                \n",
    "                # Save PDF file\n",
    "                if save_pdfs:\n",
    "                    pdf_path = os.path.join('pdfs', f\"{safe_filename}.pdf\")\n",
    "                    with open(pdf_path, 'wb') as f:\n",
    "                        f.write(pdf_content)\n",
    "                    print(f\"Saved PDF: {pdf_path}\")\n",
    "                \n",
    "                # Extract and save text\n",
    "                if save_text:\n",
    "                    text = self.extract_text_from_pdf(pdf_content)\n",
    "                    if text:\n",
    "                        text_path = os.path.join('pdf_texts', f\"{safe_filename}.txt\")\n",
    "                        with open(text_path, 'w', encoding='utf-8') as f:\n",
    "                            f.write(f\"Title: {pdf_info['title']}\\n\")\n",
    "                            f.write(f\"Date: {pdf_info['date']}\\n\")\n",
    "                            f.write(f\"URL: {pdf_info['url']}\\n\")\n",
    "                            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                            f.write(text)\n",
    "                        print(f\"Saved text: {text_path}\")\n",
    "                \n",
    "                # Store metadata\n",
    "                self.pdf_data.append({\n",
    "                    'index': idx,\n",
    "                    'title': pdf_info['title'],\n",
    "                    'date': pdf_info['date'],\n",
    "                    'url': pdf_info['url'],\n",
    "                    'text_length': len(text) if text else 0\n",
    "                })\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(1)\n",
    "    \n",
    "    def save_metadata(self, filename='pdf_metadata.json'):\n",
    "        \"\"\"Save metadata to JSON file\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.pdf_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nMetadata saved to {filename}\")\n",
    "    \n",
    "    def run(self, total_pages=9, save_pdfs=True, save_text=True):\n",
    "        \"\"\"Main execution method\"\"\"\n",
    "        print(\"Starting GST Council PDF Scraper...\\n\")\n",
    "        \n",
    "        # Step 1: Scrape all pages for PDF links\n",
    "        pdf_links = self.scrape_all_pages(total_pages)\n",
    "        \n",
    "        # Step 2: Process all PDFs\n",
    "        if pdf_links:\n",
    "            self.process_pdfs(pdf_links, save_pdfs, save_text)\n",
    "            \n",
    "            # Step 3: Save metadata\n",
    "            self.save_metadata()\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Scraping complete!\")\n",
    "            print(f\"Total PDFs processed: {len(self.pdf_data)}\")\n",
    "            print(f\"PDFs saved in: ./pdfs/\")\n",
    "            print(f\"Text files saved in: ./pdf_texts/\")\n",
    "            print(f\"Metadata saved in: ./pdf_metadata.json\")\n",
    "        else:\n",
    "            print(\"No PDFs found!\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with the actual base URL of the GST Council press release page\n",
    "    BASE_URL = \"https://gstcouncil.gov.in/press-release\"\n",
    "    \n",
    "    scraper = GSTCouncilPDFScraper(BASE_URL)\n",
    "    \n",
    "    # Run the scraper\n",
    "    # Parameters:\n",
    "    # - total_pages: number of pagination pages (9 based on your HTML)\n",
    "    # - save_pdfs: whether to save PDF files\n",
    "    # - save_text: whether to save extracted text\n",
    "    scraper.run(total_pages=9, save_pdfs=True, save_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ad8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9f509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201db65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a06782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: income_tax_pdfs\n",
      "================================================================================\n",
      "Income Tax India PDF Scraper - Complete All Pages\n",
      "================================================================================\n",
      "\n",
      "Loading website: https://incometaxindia.gov.in/Pages/tps/latest-updates.aspx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhim\\AppData\\Local\\Temp\\ipykernel_11980\\612707242.py:174: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  page_info = soup.find(text=re.compile(r'Page\\s*\\[\\s*\\d+\\s+of\\s+\\d+\\s*\\]'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Detected total pages: 41\n",
      "\n",
      "âœ“ Found 41 pages to scrape\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 1 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 9 PDFs on page 1\n",
      "\n",
      "[PDF 1/9 on Page 1] (Overall: 1)\n",
      "  Downloading: â€‹ Corrigendum- Board's letter dated 21.10.2025 on the subjec...\n",
      "  âœ“ Saved PDF: page1_pdf001_28_October_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf001_28_October_2025.txt\n",
      "\n",
      "[PDF 2/9 on Page 1] (Overall: 2)\n",
      "  Downloading: C&AG's performance Audit report No.1 of 2019 ON \"Assessment ...\n",
      "  âœ“ Saved PDF: page1_pdf002_21_October_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf002_21_October_2025.txt\n",
      "\n",
      "[PDF 3/9 on Page 1] (Overall: 3)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2025-26 as on 12.10.2025...\n",
      "  âœ“ Saved PDF: page1_pdf003_13_October_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf003_13_October_2025.txt\n",
      "\n",
      "[PDF 4/9 on Page 1] (Overall: 4)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2025-26 (as on 17.09.2025)...\n",
      "  âœ“ Saved PDF: page1_pdf004_18_September_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf004_18_September_2025.txt\n",
      "\n",
      "[PDF 5/9 on Page 1] (Overall: 5)\n",
      "  Downloading: â€‹ Gender  Composition in CBDT (Data as on Sept. 2025â€‹â€‹)...\n",
      "  âœ“ Saved PDF: page1_pdf005_18_September_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf005_18_September_2025.txt\n",
      "\n",
      "[PDF 6/9 on Page 1] (Overall: 6)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2025-26 as on 11.08.2025...\n",
      "  âœ“ Saved PDF: page1_pdf006_11_August_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf006_11_August_2025.txt\n",
      "\n",
      "[PDF 7/9 on Page 1] (Overall: 7)\n",
      "  Downloading: â€‹Direct Tax Collections for F.Y. 2025-26 (as on 10.07.2025)...\n",
      "  âœ“ Saved PDF: page1_pdf007_10_July_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf007_10_July_2025.txt\n",
      "\n",
      "[PDF 8/9 on Page 1] (Overall: 8)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2025-26 (as on 19.06.2025)...\n",
      "  âœ“ Saved PDF: page1_pdf008_19_June_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf008_19_June_2025.txt\n",
      "\n",
      "[PDF 9/9 on Page 1] (Overall: 9)\n",
      "  Downloading: Order under section 138(1)(a) of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page1_pdf009_17_June_2025.pdf\n",
      "  âœ“ Extracted text: page1_pdf009_17_June_2025.txt\n",
      "\n",
      "âœ“ Completed page 1\n",
      "Navigating to page 2...\n",
      "âœ“ Successfully navigated to page 2\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 2 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 9 PDFs on page 2\n",
      "\n",
      "[PDF 1/9 on Page 2] (Overall: 10)\n",
      "  Downloading: Order u/s 119(2)(a) of the Income-tax Act, 1961 regarding pr...\n",
      "  âœ“ Saved PDF: page2_pdf010_9_June_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf010_9_June_2025.txt\n",
      "\n",
      "[PDF 2/9 on Page 2] (Overall: 11)\n",
      "  Downloading: Order under section 138(1)(a) of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page2_pdf011_6_June_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf011_6_June_2025.txt\n",
      "\n",
      "[PDF 3/9 on Page 2] (Overall: 12)\n",
      "  Downloading: Allocation of Region to the Candidates Selected to the post ...\n",
      "  âœ“ Saved PDF: page2_pdf012_26_May_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf012_26_May_2025.txt\n",
      "\n",
      "[PDF 4/9 on Page 2] (Overall: 13)\n",
      "  Downloading: Allocation of Region to the Candidates Selected to the post ...\n",
      "  âœ“ Saved PDF: page2_pdf013_26_May_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf013_26_May_2025.txt\n",
      "\n",
      "[PDF 5/9 on Page 2] (Overall: 14)\n",
      "  Downloading: Notification - II for Departmental Examinations - 2025 for I...\n",
      "  âœ“ Saved PDF: page2_pdf014_14_May_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf014_14_May_2025.txt\n",
      "\n",
      "[PDF 6/9 on Page 2] (Overall: 15)\n",
      "  Downloading: Notification - I for Departmental Examinations - 2025 for Mi...\n",
      "  âœ“ Saved PDF: page2_pdf015_14_May_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf015_14_May_2025.txt\n",
      "\n",
      "[PDF 7/9 on Page 2] (Overall: 16)\n",
      "  Downloading: Draft for Amendment in Recruitment Rules, 2024 of Office Sup...\n",
      "  âœ“ Saved PDF: page2_pdf016_9_May_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf016_9_May_2025.txt\n",
      "\n",
      "[PDF 8/9 on Page 2] (Overall: 17)\n",
      "  Downloading: Permanent allocation of posts of Stenographer Grade-II (Pay ...\n",
      "  âœ“ Saved PDF: page2_pdf017_30_April_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf017_30_April_2025.txt\n",
      "\n",
      "[PDF 9/9 on Page 2] (Overall: 18)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2024-25 as on 31.03.2025...\n",
      "  âœ“ Saved PDF: page2_pdf018_25_April_2025.pdf\n",
      "  âœ“ Extracted text: page2_pdf018_25_April_2025.txt\n",
      "\n",
      "âœ“ Completed page 2\n",
      "Navigating to page 3...\n",
      "âœ“ Successfully navigated to page 3\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 3 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 10 PDFs on page 3\n",
      "\n",
      "[PDF 1/10 on Page 3] (Overall: 19)\n",
      "  Downloading: â€‹Key Highlights of Finance Act, 2025...\n",
      "  âœ“ Saved PDF: page3_pdf019_25_April_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf019_25_April_2025.txt\n",
      "\n",
      "[PDF 2/10 on Page 3] (Overall: 20)\n",
      "  Downloading: FAQs on Notification No. 38/2025 [F. No 370142/11/2025-TPL] ...\n",
      "  âœ“ Saved PDF: page3_pdf020_24_April_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf020_24_April_2025.txt\n",
      "\n",
      "[PDF 3/10 on Page 3] (Overall: 21)\n",
      "  Downloading: FAQs on Notification No. 36/2025 [F. No. 370142/11/2025-TPL]...\n",
      "  âœ“ Saved PDF: page3_pdf021_22_April_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf021_22_April_2025.txt\n",
      "\n",
      "[PDF 4/10 on Page 3] (Overall: 22)\n",
      "  Downloading: Allocation of Region to the Candidates Selected to the post ...\n",
      "  âœ“ Saved PDF: page3_pdf022_4_April_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf022_4_April_2025.txt\n",
      "\n",
      "[PDF 5/10 on Page 3] (Overall: 23)\n",
      "  Downloading: Allocation of Region to the Candidates Selected to the post ...\n",
      "  âœ“ Saved PDF: page3_pdf023_4_April_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf023_4_April_2025.txt\n",
      "\n",
      "[PDF 6/10 on Page 3] (Overall: 24)\n",
      "  Downloading: Order under section 119 of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page3_pdf024_26_March_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf024_26_March_2025.txt\n",
      "\n",
      "[PDF 7/10 on Page 3] (Overall: 25)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2024-25 as on 16.03.2025...\n",
      "  âœ“ Saved PDF: page3_pdf025_16_March_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf025_16_March_2025.txt\n",
      "\n",
      "[PDF 8/10 on Page 3] (Overall: 26)\n",
      "  Downloading: â€‹Notice for Engagement of Senior and Junior Standing Counsel...\n",
      "  âœ“ Saved PDF: page3_pdf026_6_March_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf026_6_March_2025.txt\n",
      "\n",
      "[PDF 9/10 on Page 3] (Overall: 27)\n",
      "  Downloading: Key Highlights of Finance Bill, 2025...\n",
      "  âœ“ Saved PDF: page3_pdf027_18_February_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf027_18_February_2025.txt\n",
      "\n",
      "[PDF 10/10 on Page 3] (Overall: 28)\n",
      "  Downloading: â€‹Direct Tax Collections for F.Y. 2024-25 as on 10.02.2025...\n",
      "  âœ“ Saved PDF: page3_pdf028_11_February_2025.pdf\n",
      "  âœ“ Extracted text: page3_pdf028_11_February_2025.txt\n",
      "\n",
      "âœ“ Completed page 3\n",
      "Navigating to page 4...\n",
      "âœ“ Successfully navigated to page 4\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 4 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 9 PDFs on page 4\n",
      "\n",
      "[PDF 1/9 on Page 4] (Overall: 29)\n",
      "  Downloading: Order under section 138(1)(a) of the Income-tax Act, 1961â€‹...\n",
      "  âœ“ Saved PDF: page4_pdf029_31_January_2025.pdf\n",
      "  âœ“ Extracted text: page4_pdf029_31_January_2025.txt\n",
      "\n",
      "[PDF 2/9 on Page 4] (Overall: 30)\n",
      "  Downloading: Direct Tax Collection for F.Y. 2024-25 as on 12.01.2025...\n",
      "  âœ“ Saved PDF: page4_pdf030_12_January_2025.pdf\n",
      "  âœ“ Extracted text: page4_pdf030_12_January_2025.txt\n",
      "\n",
      "[PDF 3/9 on Page 4] (Overall: 31)\n",
      "  Downloading: Annual APA report for FY 2023-2024...\n",
      "  âœ“ Saved PDF: page4_pdf031_10_January_2025.pdf\n",
      "  âœ“ Extracted text: page4_pdf031_10_January_2025.txt\n",
      "\n",
      "[PDF 4/9 on Page 4] (Overall: 32)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2024-25 as on 17.12.2024â€‹â€‹...\n",
      "  âœ“ Saved PDF: page4_pdf032_17_December_2024.pdf\n",
      "  âœ“ Extracted text: page4_pdf032_17_December_2024.txt\n",
      "\n",
      "[PDF 5/9 on Page 4] (Overall: 33)\n",
      "  Downloading: Approval of hospital for the purpose of sub clause (b) of cl...\n",
      "  âœ“ Saved PDF: page4_pdf033_17_December_2024.pdf\n",
      "  âœ“ Extracted text: page4_pdf033_17_December_2024.txt\n",
      "\n",
      "[PDF 6/9 on Page 4] (Overall: 34)\n",
      "  Downloading: â€‹Declaration of Result of Departmental Examination-2024 for ...\n",
      "  âœ“ Saved PDF: page4_pdf034_16_December_2024.pdf\n",
      "  âœ“ Extracted text: page4_pdf034_16_December_2024.txt\n",
      "\n",
      "[PDF 7/9 on Page 4] (Overall: 35)\n",
      "  Downloading: â€‹Declaration of Result of Departmental Examination-2024 for ...\n",
      "  âœ“ Saved PDF: page4_pdf035_16_December_2024.pdf\n",
      "  âœ“ Extracted text: page4_pdf035_16_December_2024.txt\n",
      "\n",
      "[PDF 8/9 on Page 4] (Overall: 36)\n",
      "  Downloading: Regarding publication of Sangam Se Samvad monthly newspaper ...\n",
      "  âœ“ Saved PDF: page4_pdf036_13_November_2024.pdf\n",
      "  âœ“ Extracted text: page4_pdf036_13_November_2024.txt\n",
      "\n",
      "[PDF 9/9 on Page 4] (Overall: 37)\n",
      "  Downloading: Direct Tax Collections for F.Y. 2024-25 as on 10.11.2024...\n",
      "  âœ“ Saved PDF: page4_pdf037_10_November_2024.pdf\n",
      "  âœ“ Extracted text: page4_pdf037_10_November_2024.txt\n",
      "\n",
      "âœ“ Completed page 4\n",
      "Navigating to page 5...\n",
      "âœ“ Successfully navigated to page 5\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 5 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 9 PDFs on page 5\n",
      "\n",
      "[PDF 1/9 on Page 5] (Overall: 38)\n",
      "  Downloading: Approval of hospital for the purpose of sub clause (b) of cl...\n",
      "  âœ“ Saved PDF: page5_pdf038_6_November_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf038_6_November_2024.txt\n",
      "\n",
      "[PDF 2/9 on Page 5] (Overall: 39)\n",
      "  Downloading: Guidelines for Compounding of Offences under Income Tax Act,...\n",
      "  âœ“ Saved PDF: page5_pdf039_17_October_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf039_17_October_2024.txt\n",
      "\n",
      "[PDF 3/9 on Page 5] (Overall: 40)\n",
      "  Downloading: Order under section 119 of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page5_pdf040_7_October_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf040_7_October_2024.txt\n",
      "\n",
      "[PDF 4/9 on Page 5] (Overall: 41)\n",
      "  Downloading: Notification of 'Designated Authority' under the Direct Tax ...\n",
      "  âœ“ Saved PDF: page5_pdf041_27_September_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf041_27_September_2024.txt\n",
      "\n",
      "[PDF 5/9 on Page 5] (Overall: 42)\n",
      "  Downloading: Standardization the process of filing application under sect...\n",
      "  âœ“ Saved PDF: page5_pdf042_20_August_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf042_20_August_2024.txt\n",
      "\n",
      "[PDF 6/9 on Page 5] (Overall: 43)\n",
      "  Downloading: Net Direct Tax collection (provisional) as on 11.08.2024 sta...\n",
      "  âœ“ Saved PDF: page5_pdf043_11_August_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf043_11_August_2024.txt\n",
      "\n",
      "[PDF 7/9 on Page 5] (Overall: 44)\n",
      "  Downloading: Notice for Empanelment of Junior Standing Counsel...\n",
      "  âœ“ Saved PDF: page5_pdf044_9_August_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf044_9_August_2024.txt\n",
      "\n",
      "[PDF 8/9 on Page 5] (Overall: 45)\n",
      "  Downloading: Order under proviso to sub-section (5) of section 144B of th...\n",
      "  âœ“ Saved PDF: page5_pdf045_1_August_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf045_1_August_2024.txt\n",
      "\n",
      "[PDF 9/9 on Page 5] (Overall: 46)\n",
      "  Downloading: FAQs â€“ New Capital gains Taxation regime...\n",
      "  âœ“ Saved PDF: page5_pdf046_24_July_2024.pdf\n",
      "  âœ“ Extracted text: page5_pdf046_24_July_2024.txt\n",
      "\n",
      "âœ“ Completed page 5\n",
      "Navigating to page 6...\n",
      "âœ“ Successfully navigated to page 6\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 6 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 8 PDFs on page 6\n",
      "\n",
      "[PDF 1/8 on Page 6] (Overall: 47)\n",
      "  Downloading: Key Highlights of Finance (No. 2) Bill, 2024...\n",
      "  âœ“ Saved PDF: page6_pdf047_23_July_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf047_23_July_2024.txt\n",
      "\n",
      "[PDF 2/8 on Page 6] (Overall: 48)\n",
      "  Downloading: Order under section 138(l)(a) of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page6_pdf048_9_July_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf048_9_July_2024.txt\n",
      "\n",
      "[PDF 3/8 on Page 6] (Overall: 49)\n",
      "  Downloading: Order under section 10 of the Direct Tax Vivad se Visbwas Ac...\n",
      "  âœ“ Saved PDF: page6_pdf049_27_June_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf049_27_June_2024.txt\n",
      "\n",
      "[PDF 4/8 on Page 6] (Overall: 50)\n",
      "  Downloading: Celebration of International Day of Yoga - 21st June 2024...\n",
      "  âœ“ Saved PDF: page6_pdf050_14_June_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf050_14_June_2024.txt\n",
      "\n",
      "[PDF 5/8 on Page 6] (Overall: 51)\n",
      "  Downloading: Suggestions from the Industry and Trade Associations for Bud...\n",
      "  âœ“ Saved PDF: page6_pdf051_12_June_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf051_12_June_2024.txt\n",
      "\n",
      "[PDF 6/8 on Page 6] (Overall: 52)\n",
      "  Downloading: Inviting nominations for 50th Advanced Professional Programm...\n",
      "  âœ“ Saved PDF: page6_pdf052_22_May_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf052_22_May_2024.txt\n",
      "\n",
      "[PDF 7/8 on Page 6] (Overall: 53)\n",
      "  Downloading: Allocation of Region to the Candidates Selected to the post ...\n",
      "  âœ“ Saved PDF: page6_pdf053_21_May_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf053_21_May_2024.txt\n",
      "\n",
      "[PDF 8/8 on Page 6] (Overall: 54)\n",
      "  Downloading: â€‹Notification - I for Departmental Examinations - 2024 for M...\n",
      "  âœ“ Saved PDF: page6_pdf054_13_May_2024.pdf\n",
      "  âœ“ Extracted text: page6_pdf054_13_May_2024.txt\n",
      "\n",
      "âœ“ Completed page 6\n",
      "Navigating to page 7...\n",
      "âœ“ Successfully navigated to page 7\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 7 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 9 PDFs on page 7\n",
      "\n",
      "[PDF 1/9 on Page 7] (Overall: 55)\n",
      "  Downloading: â€‹Notification - II for Departmental Examinations - 2024 for ...\n",
      "  âœ“ Saved PDF: page7_pdf055_13_May_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf055_13_May_2024.txt\n",
      "\n",
      "[PDF 2/9 on Page 7] (Overall: 56)\n",
      "  Downloading: Guidelines for compulsory selection of returns for Complete ...\n",
      "  âœ“ Saved PDF: page7_pdf056_3_May_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf056_3_May_2024.txt\n",
      "\n",
      "[PDF 3/9 on Page 7] (Overall: 57)\n",
      "  Downloading: â€‹Implementation of Hon'ble Supreme Court Judgement dated 3.7...\n",
      "  âœ“ Saved PDF: page7_pdf057_2_April_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf057_2_April_2024.txt\n",
      "\n",
      "[PDF 4/9 on Page 7] (Overall: 58)\n",
      "  Downloading: â€‹Order under section 138(1)(a) of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page7_pdf058_27_March_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf058_27_March_2024.txt\n",
      "\n",
      "[PDF 5/9 on Page 7] (Overall: 59)\n",
      "  Downloading: â€‹Order under section 119 of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page7_pdf059_18_March_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf059_18_March_2024.txt\n",
      "\n",
      "[PDF 6/9 on Page 7] (Overall: 60)\n",
      "  Downloading: â€‹Order under section 119 of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page7_pdf060_13_March_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf060_13_March_2024.txt\n",
      "\n",
      "[PDF 7/9 on Page 7] (Overall: 61)\n",
      "  Downloading: â€‹Processing of returns of income validly filed electronicall...\n",
      "  âœ“ Saved PDF: page7_pdf061_1_March_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf061_1_March_2024.txt\n",
      "\n",
      "[PDF 8/9 on Page 7] (Overall: 62)\n",
      "  Downloading: â€‹Calling for region preference of candidates nominated to th...\n",
      "  âœ“ Saved PDF: page7_pdf062_19_February_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf062_19_February_2024.txt\n",
      "\n",
      "[PDF 9/9 on Page 7] (Overall: 63)\n",
      "  Downloading: Highlights of Finance Act, 2024...\n",
      "  âœ“ Saved PDF: page7_pdf063_17_February_2024.pdf\n",
      "  âœ“ Extracted text: page7_pdf063_17_February_2024.txt\n",
      "\n",
      "âœ“ Completed page 7\n",
      "Navigating to page 8...\n",
      "âœ“ Successfully navigated to page 8\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 8 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 10 PDFs on page 8\n",
      "\n",
      "[PDF 1/10 on Page 8] (Overall: 64)\n",
      "  Downloading: Highlights of Finance Bill, 2024...\n",
      "  âœ“ Saved PDF: page8_pdf064_2_February_2024.pdf\n",
      "  âœ“ Extracted text: page8_pdf064_2_February_2024.txt\n",
      "\n",
      "[PDF 2/10 on Page 8] (Overall: 65)\n",
      "  Downloading: â€‹Processing of returns of income validly filed electronicall...\n",
      "  âœ“ Saved PDF: page8_pdf065_31_January_2024.pdf\n",
      "  âœ“ Extracted text: page8_pdf065_31_January_2024.txt\n",
      "\n",
      "[PDF 3/10 on Page 8] (Overall: 66)\n",
      "  Downloading: Permanent allocation of posts of Administrative Officer Grad...\n",
      "  âœ“ Saved PDF: page8_pdf066_25_January_2024.pdf\n",
      "  âœ“ Extracted text: page8_pdf066_25_January_2024.txt\n",
      "\n",
      "[PDF 4/10 on Page 8] (Overall: 67)\n",
      "  Downloading: â€‹Revised Allocation of Region to the Candidates Selected to ...\n",
      "  âœ“ Saved PDF: page8_pdf067_17_January_2024.pdf\n",
      "  âœ“ Extracted text: page8_pdf067_17_January_2024.txt\n",
      "\n",
      "[PDF 5/10 on Page 8] (Overall: 68)\n",
      "  Downloading: â€‹Revised Allocation of Region to the Candidates Selected to ...\n",
      "  âœ“ Saved PDF: page8_pdf068_17_January_2024.pdf\n",
      "  âœ“ Extracted text: page8_pdf068_17_January_2024.txt\n",
      "\n",
      "[PDF 6/10 on Page 8] (Overall: 69)\n",
      "  Downloading: â€‹Office Order pursuant to CBDT Order No. 331 of 2023 dated 3...\n",
      "  âœ“ Saved PDF: page8_pdf069_16_January_2024.pdf\n",
      "  âœ“ Extracted text: page8_pdf069_16_January_2024.txt\n",
      "\n",
      "[PDF 7/10 on Page 8] (Overall: 70)\n",
      "  Downloading: â€‹Permanent allocation of posts of Group B and Group C office...\n",
      "  âœ“ Saved PDF: page8_pdf070_2_January_2024.pdf\n",
      "  âœ“ Extracted text: page8_pdf070_2_January_2024.txt\n",
      "\n",
      "[PDF 8/10 on Page 8] (Overall: 71)\n",
      "  Downloading: Postponement of interview scheduled on 28.12.2023 for engage...\n",
      "  âœ“ Saved PDF: page8_pdf071_27_December_2023.pdf\n",
      "  âœ“ Extracted text: page8_pdf071_27_December_2023.txt\n",
      "\n",
      "[PDF 9/10 on Page 8] (Overall: 72)\n",
      "  Downloading: â€‹Interview for engagement of retired government officials on...\n",
      "  âœ“ Saved PDF: page8_pdf072_20_December_2023.pdf\n",
      "  âœ“ Extracted text: page8_pdf072_20_December_2023.txt\n",
      "\n",
      "[PDF 10/10 on Page 8] (Overall: 73)\n",
      "  Downloading: Calling for region preference of candidates nominated to the...\n",
      "  âœ“ Saved PDF: page8_pdf073_15_December_2023.pdf\n",
      "  âœ“ Extracted text: page8_pdf073_15_December_2023.txt\n",
      "\n",
      "âœ“ Completed page 8\n",
      "Navigating to page 9...\n",
      "âœ“ Successfully navigated to page 9\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 9 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 9 PDFs on page 9\n",
      "\n",
      "[PDF 1/9 on Page 9] (Overall: 74)\n",
      "  Downloading: Calling for region preference of candidates nominated to the...\n",
      "  âœ“ Saved PDF: page9_pdf074_15_December_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf074_15_December_2023.txt\n",
      "\n",
      "[PDF 2/9 on Page 9] (Overall: 75)\n",
      "  Downloading: Processing of returns of income validly filed electronically...\n",
      "  âœ“ Saved PDF: page9_pdf075_1_December_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf075_1_December_2023.txt\n",
      "\n",
      "[PDF 3/9 on Page 9] (Overall: 76)\n",
      "  Downloading: â€‹Final Selection of Young Professional under Young Professio...\n",
      "  âœ“ Saved PDF: page9_pdf076_27_October_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf076_27_October_2023.txt\n",
      "\n",
      "[PDF 4/9 on Page 9] (Overall: 77)\n",
      "  Downloading: â€‹Names of Candidates appeared in interview and recommended f...\n",
      "  âœ“ Saved PDF: page9_pdf077_27_October_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf077_27_October_2023.txt\n",
      "\n",
      "[PDF 5/9 on Page 9] (Overall: 78)\n",
      "  Downloading: â€‹Introduction of Young Professional Scheme in the U.P. (West...\n",
      "  âœ“ Saved PDF: page9_pdf078_26_October_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf078_26_October_2023.txt\n",
      "\n",
      "[PDF 6/9 on Page 9] (Overall: 79)\n",
      "  Downloading: â€‹Order under section 119 of the Income-tax Act, 1961 (the Ac...\n",
      "  âœ“ Saved PDF: page9_pdf079_25_October_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf079_25_October_2023.txt\n",
      "\n",
      "[PDF 7/9 on Page 9] (Overall: 80)\n",
      "  Downloading: â€‹Allocation of Region to the Candidates Selected to the post...\n",
      "  âœ“ Saved PDF: page9_pdf080_20_October_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf080_20_October_2023.txt\n",
      "\n",
      "[PDF 8/9 on Page 9] (Overall: 81)\n",
      "  Downloading: â€‹Income-Tax Department, North-West Region, Chandigarh-Young ...\n",
      "  âœ“ Saved PDF: page9_pdf081_19_October_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf081_19_October_2023.txt\n",
      "\n",
      "[PDF 9/9 on Page 9] (Overall: 82)\n",
      "  Downloading: Processing of returns with refund claims under section 143(1...\n",
      "  âœ“ Saved PDF: page9_pdf082_16_October_2023.pdf\n",
      "  âœ“ Extracted text: page9_pdf082_16_October_2023.txt\n",
      "\n",
      "âœ“ Completed page 9\n",
      "Navigating to page 10...\n",
      "âœ“ Successfully navigated to page 10\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 10 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 8 PDFs on page 10\n",
      "\n",
      "[PDF 1/8 on Page 10] (Overall: 83)\n",
      "  Downloading: â€‹Candidates shortlisted for Young Professionals Scheme 2023,...\n",
      "  âœ“ Saved PDF: page10_pdf083_16_October_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf083_16_October_2023.txt\n",
      "\n",
      "[PDF 2/8 on Page 10] (Overall: 84)\n",
      "  Downloading: â€‹Young Professional Scheme, 2023â€‹...\n",
      "  âœ“ Saved PDF: page10_pdf084_10_October_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf084_10_October_2023.txt\n",
      "\n",
      "[PDF 3/8 on Page 10] (Overall: 85)\n",
      "  Downloading: Introduction of Young Professional Scheme in the Income Tax ...\n",
      "  âœ“ Saved PDF: page10_pdf085_20_September_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf085_20_September_2023.txt\n",
      "\n",
      "[PDF 4/8 on Page 10] (Overall: 86)\n",
      "  Downloading: â€‹Memorandum - Calling for region preference of candidates no...\n",
      "  âœ“ Saved PDF: page10_pdf086_13_September_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf086_13_September_2023.txt\n",
      "\n",
      "[PDF 5/8 on Page 10] (Overall: 87)\n",
      "  Downloading: APA report (for FY 2022-23)â€‹â€‹...\n",
      "  âœ“ Saved PDF: page10_pdf087_1_September_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf087_1_September_2023.txt\n",
      "\n",
      "[PDF 6/8 on Page 10] (Overall: 88)\n",
      "  Downloading: Notification - I for Departmental Examination - 2023 for Min...\n",
      "  âœ“ Saved PDF: page10_pdf088_24_August_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf088_24_August_2023.txt\n",
      "\n",
      "[PDF 7/8 on Page 10] (Overall: 89)\n",
      "  Downloading: â€‹Inviting comments on draft Form no. 6C for implementing the...\n",
      "  âœ“ Saved PDF: page10_pdf089_16_August_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf089_16_August_2023.txt\n",
      "\n",
      "[PDF 8/8 on Page 10] (Overall: 90)\n",
      "  Downloading: Notification â€“ II for Departmental Examination 2023 for Inco...\n",
      "  âœ“ Saved PDF: page10_pdf090_18_July_2023.pdf\n",
      "  âœ“ Extracted text: page10_pdf090_18_July_2023.txt\n",
      "\n",
      "âœ“ Completed page 10\n",
      "Navigating to page 11...\n",
      "âœ“ Successfully navigated to page 11\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 11 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 10 PDFs on page 11\n",
      "\n",
      "[PDF 1/10 on Page 11] (Overall: 91)\n",
      "  Downloading: â€‹Allocation of Region to candidates selected for the post of...\n",
      "  âœ“ Saved PDF: page11_pdf091_12_July_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf091_12_July_2023.txt\n",
      "\n",
      "[PDF 2/10 on Page 11] (Overall: 92)\n",
      "  Downloading: â€‹Order under sub-section (6) of section 246 of the Income-ta...\n",
      "  âœ“ Saved PDF: page11_pdf092_16_June_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf092_16_June_2023.txt\n",
      "\n",
      "[PDF 3/10 on Page 11] (Overall: 93)\n",
      "  Downloading: â€‹Inviting comments on the draft rule 11UA for implementing t...\n",
      "  âœ“ Saved PDF: page11_pdf093_26_May_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf093_26_May_2023.txt\n",
      "\n",
      "[PDF 4/10 on Page 11] (Overall: 94)\n",
      "  Downloading: Guidelines for compulsory selection of returns for Complete ...\n",
      "  âœ“ Saved PDF: page11_pdf094_24_May_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf094_24_May_2023.txt\n",
      "\n",
      "[PDF 5/10 on Page 11] (Overall: 95)\n",
      "  Downloading: â€‹Allocation of Regions to candidates selected to the post of...\n",
      "  âœ“ Saved PDF: page11_pdf095_3_May_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf095_3_May_2023.txt\n",
      "\n",
      "[PDF 6/10 on Page 11] (Overall: 96)\n",
      "  Downloading: â€‹Allocation of Regions to candidates selected to the post of...\n",
      "  âœ“ Saved PDF: page11_pdf096_3_May_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf096_3_May_2023.txt\n",
      "\n",
      "[PDF 7/10 on Page 11] (Overall: 97)\n",
      "  Downloading: Specified date for the purposes of sub-rule (4) to rule 114A...\n",
      "  âœ“ Saved PDF: page11_pdf097_1_April_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf097_1_April_2023.txt\n",
      "\n",
      "[PDF 8/10 on Page 11] (Overall: 98)\n",
      "  Downloading: Highlights of Finance Act, 2023...\n",
      "  âœ“ Saved PDF: page11_pdf098_1_April_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf098_1_April_2023.txt\n",
      "\n",
      "[PDF 9/10 on Page 11] (Overall: 99)\n",
      "  Downloading: â€‹Calling for region preference of candidates nominated to th...\n",
      "  âœ“ Saved PDF: page11_pdf099_21_March_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf099_21_March_2023.txt\n",
      "\n",
      "[PDF 10/10 on Page 11] (Overall: 100)\n",
      "  Downloading: â€‹Calling for region preference of candidates nominated to th...\n",
      "  âœ“ Saved PDF: page11_pdf100_21_March_2023.pdf\n",
      "  âœ“ Extracted text: page11_pdf100_21_March_2023.txt\n",
      "\n",
      "âœ“ Completed page 11\n",
      "Navigating to page 12...\n",
      "âœ“ Successfully navigated to page 12\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 12 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 6 PDFs on page 12\n",
      "\n",
      "[PDF 1/6 on Page 12] (Overall: 101)\n",
      "  Downloading: â€‹Setting up of Units under sub-section (3) of section 144B o...\n",
      "  âœ“ Saved PDF: page12_pdf101_1_March_2023.pdf\n",
      "  âœ“ Extracted text: page12_pdf101_1_March_2023.txt\n",
      "\n",
      "[PDF 2/6 on Page 12] (Overall: 102)\n",
      "  Downloading: â€‹Order under section 138(1)(a) of the Income-tax Act, 1961...\n",
      "  âœ“ Saved PDF: page12_pdf102_16_February_2023.pdf\n",
      "  âœ“ Extracted text: page12_pdf102_16_February_2023.txt\n",
      "\n",
      "[PDF 3/6 on Page 12] (Overall: 103)\n",
      "  Downloading: E-Calendar 2023...\n",
      "  âœ“ Saved PDF: page12_pdf103_6_January_2023.pdf\n",
      "  âœ“ Extracted text: page12_pdf103_6_January_2023.txt\n",
      "\n",
      "[PDF 4/6 on Page 12] (Overall: 104)\n",
      "  Downloading: â€‹Allocation of Region to candidates selected to the post of ...\n",
      "  âœ“ Saved PDF: page12_pdf104_20_December_2022.pdf\n",
      "  âœ“ Extracted text: page12_pdf104_20_December_2022.txt\n",
      "\n",
      "[PDF 5/6 on Page 12] (Overall: 105)\n",
      "  Downloading: Allocation of Region to Candidates selected to the post of I...\n",
      "  âœ“ Saved PDF: page12_pdf105_2_December_2022.pdf\n",
      "  âœ“ Extracted text: page12_pdf105_2_December_2022.txt\n",
      "\n",
      "[PDF 6/6 on Page 12] (Overall: 106)\n",
      "  Downloading: Allocation of Region to Candidates selected to the post of S...\n",
      "  âœ“ Saved PDF: page12_pdf106_2_December_2022.pdf\n",
      "  âœ“ Extracted text: page12_pdf106_2_December_2022.txt\n",
      "\n",
      "âœ“ Completed page 12\n",
      "Navigating to page 13...\n",
      "âœ“ Successfully navigated to page 13\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 13 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 8 PDFs on page 13\n",
      "\n",
      "[PDF 1/8 on Page 13] (Overall: 107)\n",
      "  Downloading: â€‹Setting up of Units under sub-section (3) of section 144B o...\n",
      "  âœ“ Saved PDF: page13_pdf107_14_November_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf107_14_November_2022.txt\n",
      "\n",
      "[PDF 2/8 on Page 13] (Overall: 108)\n",
      "  Downloading: â€‹Calling for region preference of candidates nominated to th...\n",
      "  âœ“ Saved PDF: page13_pdf108_3_November_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf108_3_November_2022.txt\n",
      "\n",
      "[PDF 3/8 on Page 13] (Overall: 109)\n",
      "  Downloading: â€‹Calling for region preference of candidates nominated to th...\n",
      "  âœ“ Saved PDF: page13_pdf109_3_November_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf109_3_November_2022.txt\n",
      "\n",
      "[PDF 4/8 on Page 13] (Overall: 110)\n",
      "  Downloading: â€‹Calling for region preference of candidates nominated to th...\n",
      "  âœ“ Saved PDF: page13_pdf110_3_November_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf110_3_November_2022.txt\n",
      "\n",
      "[PDF 5/8 on Page 13] (Overall: 111)\n",
      "  Downloading: â€‹Computer Based Test Related Instructions for Departmental E...\n",
      "  âœ“ Saved PDF: page13_pdf111_2_November_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf111_2_November_2022.txt\n",
      "\n",
      "[PDF 6/8 on Page 13] (Overall: 112)\n",
      "  Downloading: â€‹Corrigendum on order u/s 119 of the IT Act,1961...\n",
      "  âœ“ Saved PDF: page13_pdf112_27_September_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf112_27_September_2022.txt\n",
      "\n",
      "[PDF 7/8 on Page 13] (Overall: 113)\n",
      "  Downloading: â€‹Order u/s 119 of the Income-tax Act, 1961â€‹...\n",
      "  âœ“ Saved PDF: page13_pdf113_26_September_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf113_26_September_2022.txt\n",
      "\n",
      "[PDF 8/8 on Page 13] (Overall: 114)\n",
      "  Downloading: Guidelines for Compounding of Offences under the Income-Tax ...\n",
      "  âœ“ Saved PDF: page13_pdf114_16_September_2022.pdf\n",
      "  âœ“ Extracted text: page13_pdf114_16_September_2022.txt\n",
      "\n",
      "âœ“ Completed page 13\n",
      "Navigating to page 14...\n",
      "âœ“ Successfully navigated to page 14\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 14 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 6 PDFs on page 14\n",
      "\n",
      "[PDF 1/6 on Page 14] (Overall: 115)\n",
      "  Downloading: Allocation of Region to Candidates selected to the post of S...\n",
      "  âœ“ Saved PDF: page14_pdf115_16_September_2022.pdf\n",
      "  âœ“ Extracted text: page14_pdf115_16_September_2022.txt\n",
      "\n",
      "[PDF 2/6 on Page 14] (Overall: 116)\n",
      "  Downloading: Notification for Departmental Examination 2022 of Income-tax...\n",
      "  âœ“ Saved PDF: page14_pdf116_13_September_2022.pdf\n",
      "  âœ“ Extracted text: page14_pdf116_13_September_2022.txt\n",
      "\n",
      "[PDF 3/6 on Page 14] (Overall: 117)\n",
      "  Downloading: â€‹Allocation of Region to Candidates selected to the post of ...\n",
      "  âœ“ Saved PDF: page14_pdf117_8_September_2022.pdf\n",
      "  âœ“ Extracted text: page14_pdf117_8_September_2022.txt\n",
      "\n",
      "[PDF 4/6 on Page 14] (Overall: 118)\n",
      "  Downloading: â€‹CORRIGENDUM - Allocation of Region to Candidates selected t...\n",
      "  âœ“ Saved PDF: page14_pdf118_5_September_2022.pdf\n",
      "  âœ“ Extracted text: page14_pdf118_5_September_2022.txt\n",
      "\n",
      "[PDF 5/6 on Page 14] (Overall: 119)\n",
      "  Downloading: Allocation of Region to Candidates selected to the post of I...\n",
      "  âœ“ Saved PDF: page14_pdf119_25_August_2022.pdf\n",
      "  âœ“ Extracted text: page14_pdf119_25_August_2022.txt\n",
      "\n",
      "[PDF 6/6 on Page 14] (Overall: 120)\n",
      "  Downloading: Order under Section 119(1) of the Income Tax Act, 1961...\n",
      "  âœ“ Saved PDF: page14_pdf120_30_July_2022.pdf\n",
      "  âœ“ Extracted text: page14_pdf120_30_July_2022.txt\n",
      "\n",
      "âœ“ Completed page 14\n",
      "Navigating to page 15...\n",
      "âœ“ Successfully navigated to page 15\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 15 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 10 PDFs on page 15\n",
      "\n",
      "[PDF 1/10 on Page 15] (Overall: 121)\n",
      "  Downloading: Reminder - Calling for region preference of candidates nomin...\n",
      "  âœ“ Saved PDF: page15_pdf121_22_July_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf121_22_July_2022.txt\n",
      "\n",
      "[PDF 2/10 on Page 15] (Overall: 122)\n",
      "  Downloading: Order authorizing 'Prescribed Authority' for the purpose of ...\n",
      "  âœ“ Saved PDF: page15_pdf122_20_July_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf122_20_July_2022.txt\n",
      "\n",
      "[PDF 3/10 on Page 15] (Overall: 123)\n",
      "  Downloading: â€‹Notification for Departmental Examinations - 2022 for Minis...\n",
      "  âœ“ Saved PDF: page15_pdf123_19_July_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf123_19_July_2022.txt\n",
      "\n",
      "[PDF 4/10 on Page 15] (Overall: 124)\n",
      "  Downloading: Standardizing the process of filing application for approval...\n",
      "  âœ“ Saved PDF: page15_pdf124_11_July_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf124_11_July_2022.txt\n",
      "\n",
      "[PDF 5/10 on Page 15] (Overall: 125)\n",
      "  Downloading: Calling for region preference of candidates nominated to the...\n",
      "  âœ“ Saved PDF: page15_pdf125_28_June_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf125_28_June_2022.txt\n",
      "\n",
      "[PDF 6/10 on Page 15] (Overall: 126)\n",
      "  Downloading: â€‹Calling for region preference of candidates nominated to th...\n",
      "  âœ“ Saved PDF: page15_pdf126_23_June_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf126_23_June_2022.txt\n",
      "\n",
      "[PDF 7/10 on Page 15] (Overall: 127)\n",
      "  Downloading: Inspector of Income Tax in CBDT on the basis of Combined Gra...\n",
      "  âœ“ Saved PDF: page15_pdf127_7_June_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf127_7_June_2022.txt\n",
      "\n",
      "[PDF 8/10 on Page 15] (Overall: 128)\n",
      "  Downloading: â€‹Guidelines for compulsory selection of returns for Complete...\n",
      "  âœ“ Saved PDF: page15_pdf128_3_June_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf128_3_June_2022.txt\n",
      "\n",
      "[PDF 9/10 on Page 15] (Overall: 129)\n",
      "  Downloading: Guidelines for compulsory selection of returns for Complete ...\n",
      "  âœ“ Saved PDF: page15_pdf129_11_May_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf129_11_May_2022.txt\n",
      "\n",
      "[PDF 10/10 on Page 15] (Overall: 130)\n",
      "  Downloading: â€‹Revised Instruction for constitution and functioning of 'Lo...\n",
      "  âœ“ Saved PDF: page15_pdf130_23_April_2022.pdf\n",
      "  âœ“ Extracted text: page15_pdf130_23_April_2022.txt\n",
      "\n",
      "âœ“ Completed page 15\n",
      "Navigating to page 16...\n",
      "âœ“ Successfully navigated to page 16\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 16 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 7 PDFs on page 16\n",
      "\n",
      "[PDF 1/7 on Page 16] (Overall: 131)\n",
      "  Downloading: Specified date for the purposes of proviso to sub-rule (2) t...\n",
      "  âœ“ Saved PDF: page16_pdf131_30_March_2022.pdf\n",
      "  âœ“ Extracted text: page16_pdf131_30_March_2022.txt\n",
      "\n",
      "[PDF 2/7 on Page 16] (Overall: 132)\n",
      "  Downloading: Order under section 119 of the Income-tax Act, 1961 (the Act...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x7a6b9 for key /Info\n",
      "Multiple definitions in dictionary at byte 0x7a6c6 for key /Info\n",
      "Multiple definitions in dictionary at byte 0x7a6d3 for key /Info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Saved PDF: page16_pdf132_17_March_2022.pdf\n",
      "  âœ“ Extracted text: page16_pdf132_17_March_2022.txt\n",
      "\n",
      "[PDF 3/7 on Page 16] (Overall: 133)\n",
      "  Downloading: Order under sub-section (2) of Section 144B of the Income-ta...\n",
      "  âœ“ Saved PDF: page16_pdf133_17_March_2022.pdf\n",
      "  âœ“ Extracted text: page16_pdf133_17_March_2022.txt\n",
      "\n",
      "[PDF 4/7 on Page 16] (Overall: 134)\n",
      "  Downloading: Condonation of delay under section 119(2)(b) of the Income-t...\n",
      "  âœ“ Saved PDF: page16_pdf134_17_March_2022.pdf\n",
      "  âœ“ Extracted text: page16_pdf134_17_March_2022.txt\n",
      "\n",
      "[PDF 5/7 on Page 16] (Overall: 135)\n",
      "  Downloading: Setting up of office for operationalising Interim Boards for...\n",
      "  âœ“ Saved PDF: page16_pdf135_31_January_2022.pdf\n",
      "  âœ“ Extracted text: page16_pdf135_31_January_2022.txt\n",
      "\n",
      "[PDF 6/7 on Page 16] (Overall: 136)\n",
      "  Downloading: Corrigendum to Order dated 20.01.2022 issued in pursuant to ...\n",
      "  âœ“ Saved PDF: page16_pdf136_28_January_2022.pdf\n",
      "  âœ“ Extracted text: page16_pdf136_28_January_2022.txt\n",
      "\n",
      "[PDF 7/7 on Page 16] (Overall: 137)\n",
      "  Downloading: Office Order pursuant to CBDT Order No. 304 of 2021 dated 08...\n",
      "  âœ“ Saved PDF: page16_pdf137_24_January_2022.pdf\n",
      "  âœ“ Extracted text: page16_pdf137_24_January_2022.txt\n",
      "\n",
      "âœ“ Completed page 16\n",
      "Navigating to page 17...\n",
      "âœ“ Successfully navigated to page 17\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 17 of 41\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 6 PDFs on page 17\n",
      "\n",
      "[PDF 1/6 on Page 17] (Overall: 138)\n",
      "  Downloading: Office Order pursuant to CBDT Order No. 352 of 2021 dated 30...\n",
      "  âœ“ Saved PDF: page17_pdf138_20_January_2022.pdf\n",
      "  âœ“ Extracted text: page17_pdf138_20_January_2022.txt\n",
      "\n",
      "[PDF 2/6 on Page 17] (Overall: 139)\n",
      "  Downloading: Order under section 119 of the Income-tax Act, 1961 for exer...\n",
      "  âœ“ Saved PDF: page17_pdf139_31_December_2021.pdf\n",
      "  âœ“ Extracted text: page17_pdf139_31_December_2021.txt\n",
      "\n",
      "[PDF 3/6 on Page 17] (Overall: 140)\n",
      "  Downloading: â€‹Order under section 119 of the Income-tax Act, 1961 (the Ac...\n",
      "  âœ“ Saved PDF: page17_pdf140_16_December_2021.pdf\n",
      "  âœ“ Extracted text: page17_pdf140_16_December_2021.txt\n",
      "\n",
      "[PDF 4/6 on Page 17] (Overall: 141)\n",
      "  Downloading: â€‹Order under sub-section (2) of Section 144B of the Income-t...\n",
      "  âœ“ Saved PDF: page17_pdf141_16_December_2021.pdf\n",
      "  âœ“ Extracted text: page17_pdf141_16_December_2021.txt\n",
      "\n",
      "Closing browser...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 351\u001b[39m\n\u001b[32m    347\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 324\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    321\u001b[39m scraper = IncomeTaxPDFScraperComplete()\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# Run the scraper\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m results = \u001b[43mscraper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscrape_all_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Print detailed summary\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m results:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 282\u001b[39m, in \u001b[36mIncomeTaxPDFScraperComplete.scrape_all_pages\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[PDF \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdf_info_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on Page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] (Overall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    281\u001b[39m     \u001b[38;5;28mself\u001b[39m.download_and_extract_pdf(pdf_info, page_num, pdf_counter)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ“ Completed page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# Navigate to next page (if not the last page)\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "class IncomeTaxPDFScraperComplete:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://incometaxindia.gov.in/Pages/tps/latest-updates.aspx\"\n",
    "        self.output_dir = \"income_tax_pdfs\"\n",
    "        \n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            print(f\"Created directory: {self.output_dir}\")\n",
    "        \n",
    "        self.chrome_options = webdriver.ChromeOptions()\n",
    "        self.chrome_options.add_argument('--headless')\n",
    "        self.chrome_options.add_argument('--no-sandbox')\n",
    "        self.chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        self.chrome_options.add_argument('--disable-gpu')\n",
    "        self.chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "        \n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        })\n",
    "        \n",
    "        self.pdf_data = []\n",
    "        \n",
    "    def init_driver(self):\n",
    "        \"\"\"Initialize Selenium WebDriver\"\"\"\n",
    "        try:\n",
    "            self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "            self.driver.maximize_window()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing driver: {e}\")\n",
    "            print(\"Make sure ChromeDriver is installed and in PATH\")\n",
    "            return False\n",
    "    \n",
    "    def extract_pdf_urls_from_html(self, html_content):\n",
    "        \"\"\"Extract all PDF URLs from the HTML content\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        pdf_info = []\n",
    "        \n",
    "        news_rows = soup.find_all('div', class_='news-rows')\n",
    "        \n",
    "        for row in news_rows:\n",
    "            try:\n",
    "                title_elem = row.find('h1')\n",
    "                if not title_elem:\n",
    "                    continue\n",
    "                \n",
    "                title_link = title_elem.find('a')\n",
    "                if not title_link:\n",
    "                    continue\n",
    "                    \n",
    "                title = title_link.get_text(strip=True)\n",
    "                \n",
    "                date_elem = row.find('span', id=re.compile('publishDt'))\n",
    "                date = date_elem.get_text(strip=True) if date_elem else \"Unknown Date\"\n",
    "                \n",
    "                onclick = title_link.get('onclick', '')\n",
    "                url_match = re.search(r\"'(https://[^']+\\.pdf)\", onclick)\n",
    "                \n",
    "                if url_match:\n",
    "                    pdf_url = url_match.group(1)\n",
    "                    pdf_info.append({\n",
    "                        'title': title,\n",
    "                        'date': date,\n",
    "                        'url': pdf_url\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting PDF info from row: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return pdf_info\n",
    "    \n",
    "    def download_and_extract_pdf(self, pdf_info, page_num, pdf_index):\n",
    "        \"\"\"Download PDF and extract text content\"\"\"\n",
    "        try:\n",
    "            print(f\"  Downloading: {pdf_info['title'][:60]}...\")\n",
    "            \n",
    "            max_retries = 3\n",
    "            pdf_content = None\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = self.session.get(pdf_info['url'], timeout=60)\n",
    "                    response.raise_for_status()\n",
    "                    pdf_content = response.content\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"  Retry {attempt + 1}/{max_retries}...\")\n",
    "                        time.sleep(2)\n",
    "                    else:\n",
    "                        raise e\n",
    "            \n",
    "            if not pdf_content:\n",
    "                print(f\"  âœ— Failed to download PDF\")\n",
    "                return False\n",
    "            \n",
    "            safe_date = pdf_info['date'].replace('/', '-').replace(' ', '_')\n",
    "            safe_filename = f\"page{page_num}_pdf{pdf_index:03d}_{safe_date}\"\n",
    "            \n",
    "            pdf_path = os.path.join(self.output_dir, f\"{safe_filename}.pdf\")\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(pdf_content)\n",
    "            print(f\"  âœ“ Saved PDF: {safe_filename}.pdf\")\n",
    "            \n",
    "            text = \"\"\n",
    "            try:\n",
    "                pdf_file = io.BytesIO(pdf_content)\n",
    "                pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "                \n",
    "                text_content = []\n",
    "                for page_idx in range(len(pdf_reader.pages)):\n",
    "                    page = pdf_reader.pages[page_idx]\n",
    "                    page_text = page.extract_text()\n",
    "                    text_content.append(f\"--- Page {page_idx + 1} ---\\n{page_text}\\n\")\n",
    "                \n",
    "                text = \"\\n\".join(text_content)\n",
    "                \n",
    "                text_path = os.path.join(self.output_dir, f\"{safe_filename}.txt\")\n",
    "                with open(text_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(f\"Source Page: {page_num}\\n\")\n",
    "                    f.write(f\"PDF Index: {pdf_index}\\n\")\n",
    "                    f.write(f\"Title: {pdf_info['title']}\\n\")\n",
    "                    f.write(f\"Date: {pdf_info['date']}\\n\")\n",
    "                    f.write(f\"URL: {pdf_info['url']}\\n\")\n",
    "                    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "                    f.write(text)\n",
    "                \n",
    "                print(f\"  âœ“ Extracted text: {safe_filename}.txt\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âš  Warning: Could not extract text: {e}\")\n",
    "                text = \"[Text extraction failed]\"\n",
    "            \n",
    "            self.pdf_data.append({\n",
    "                'page': page_num,\n",
    "                'index': pdf_index,\n",
    "                'title': pdf_info['title'],\n",
    "                'date': pdf_info['date'],\n",
    "                'url': pdf_info['url'],\n",
    "                'filename': safe_filename,\n",
    "                'text_length': len(text)\n",
    "            })\n",
    "            \n",
    "            return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error processing PDF: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_total_pages(self):\n",
    "        \"\"\"Extract total number of pages from the page info text\"\"\"\n",
    "        try:\n",
    "            # Look for text like \"410 Record(s) | Page [6 of 41]\"\n",
    "            page_source = self.driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            # Try to find the page info text\n",
    "            page_info = soup.find(text=re.compile(r'Page\\s*\\[\\s*\\d+\\s+of\\s+\\d+\\s*\\]'))\n",
    "            \n",
    "            if page_info:\n",
    "                match = re.search(r'of\\s+(\\d+)', page_info)\n",
    "                if match:\n",
    "                    total = int(match.group(1))\n",
    "                    print(f\"âœ“ Detected total pages: {total}\")\n",
    "                    return total\n",
    "            \n",
    "            # Fallback: look in any element\n",
    "            all_text = soup.get_text()\n",
    "            match = re.search(r'Page\\s*\\[\\s*\\d+\\s+of\\s+(\\d+)\\s*\\]', all_text)\n",
    "            if match:\n",
    "                total = int(match.group(1))\n",
    "                print(f\"âœ“ Detected total pages: {total}\")\n",
    "                return total\n",
    "            \n",
    "            print(\"âš  Could not detect total pages, defaulting to 1\")\n",
    "            return 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting total pages: {e}\")\n",
    "            return 1\n",
    "    \n",
    "    def click_next_page(self):\n",
    "        \"\"\"Click the Next button to go to the next page\"\"\"\n",
    "        try:\n",
    "            # Find the Next button\n",
    "            next_button = self.driver.find_element(\n",
    "                By.CSS_SELECTOR,\n",
    "                \"input[id*='imgbtnNext']\"\n",
    "            )\n",
    "            \n",
    "            # Check if Next button is enabled\n",
    "            if next_button.is_enabled():\n",
    "                # Scroll to the button\n",
    "                self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                time.sleep(1)\n",
    "                \n",
    "                # Click the Next button\n",
    "                next_button.click()\n",
    "                \n",
    "                # Wait for page to load\n",
    "                time.sleep(3)\n",
    "                \n",
    "                # Wait for news rows to be present\n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"news-rows\"))\n",
    "                )\n",
    "                \n",
    "                return True\n",
    "            else:\n",
    "                print(\"Next button is disabled (last page reached)\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error clicking Next button: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def save_metadata(self):\n",
    "        \"\"\"Save metadata to JSON file\"\"\"\n",
    "        metadata_path = os.path.join(self.output_dir, 'metadata.json')\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.pdf_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nMetadata saved to: {metadata_path}\")\n",
    "    \n",
    "    def scrape_all_pages(self):\n",
    "        \"\"\"Main method to scrape all pages\"\"\"\n",
    "        print(\"=\"*80)\n",
    "        print(\"Income Tax India PDF Scraper - Complete All Pages\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if not self.init_driver():\n",
    "            print(\"Failed to initialize browser driver. Exiting.\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Load the main page\n",
    "            print(f\"\\nLoading website: {self.base_url}\")\n",
    "            self.driver.get(self.base_url)\n",
    "            time.sleep(5)\n",
    "            \n",
    "            # Get total number of pages\n",
    "            total_pages = self.get_total_pages()\n",
    "            \n",
    "            print(f\"\\nâœ“ Found {total_pages} pages to scrape\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            pdf_counter = 0\n",
    "            \n",
    "            # Process each page\n",
    "            for page_num in range(1, total_pages + 1):\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"PROCESSING PAGE {page_num} of {total_pages}\")\n",
    "                print(f\"{'='*80}\")\n",
    "                \n",
    "                # Get current page HTML\n",
    "                page_html = self.driver.page_source\n",
    "                \n",
    "                # Extract PDF information\n",
    "                pdf_info_list = self.extract_pdf_urls_from_html(page_html)\n",
    "                print(f\"\\nâœ“ Found {len(pdf_info_list)} PDFs on page {page_num}\")\n",
    "                \n",
    "                # Download and extract each PDF\n",
    "                for i, pdf_info in enumerate(pdf_info_list, 1):\n",
    "                    pdf_counter += 1\n",
    "                    print(f\"\\n[PDF {i}/{len(pdf_info_list)} on Page {page_num}] (Overall: {pdf_counter})\")\n",
    "                    self.download_and_extract_pdf(pdf_info, page_num, pdf_counter)\n",
    "                    time.sleep(1)\n",
    "                \n",
    "                print(f\"\\nâœ“ Completed page {page_num}\")\n",
    "                \n",
    "                # Navigate to next page (if not the last page)\n",
    "                if page_num < total_pages:\n",
    "                    print(f\"Navigating to page {page_num + 1}...\")\n",
    "                    if not self.click_next_page():\n",
    "                        print(f\"Failed to navigate to next page. Stopping at page {page_num}.\")\n",
    "                        break\n",
    "                    print(f\"âœ“ Successfully navigated to page {page_num + 1}\")\n",
    "                \n",
    "                time.sleep(2)\n",
    "            \n",
    "            # Save metadata\n",
    "            self.save_metadata()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError during scraping: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        finally:\n",
    "            # Close the browser\n",
    "            print(\"\\nClosing browser...\")\n",
    "            self.driver.quit()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SCRAPING COMPLETED!\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Total PDFs processed: {len(self.pdf_data)}\")\n",
    "        print(f\"Output directory: {os.path.abspath(self.output_dir)}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self.pdf_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    scraper = IncomeTaxPDFScraperComplete()\n",
    "    \n",
    "    # Run the scraper\n",
    "    results = scraper.scrape_all_pages()\n",
    "    \n",
    "    # Print detailed summary\n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DETAILED SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Group by page\n",
    "        pages = {}\n",
    "        for pdf in results:\n",
    "            page = pdf.get('page', 1)\n",
    "            if page not in pages:\n",
    "                pages[page] = []\n",
    "            pages[page].append(pdf)\n",
    "        \n",
    "        for page_num in sorted(pages.keys()):\n",
    "            print(f\"\\n--- Page {page_num} ({len(pages[page_num])} PDFs) ---\")\n",
    "            for pdf in pages[page_num]:\n",
    "                print(f\"  {pdf['index']:03d}. {pdf['title'][:65]}... ({pdf['date']})\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"All files saved in: {os.path.abspath(scraper.output_dir)}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92eb1808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RBI PDF SCRAPER\n",
      "================================================================================\n",
      "\n",
      "Required packages:\n",
      "  pip install selenium beautifulsoup4 PyPDF2 pdfplumber requests\n",
      "\n",
      "Note: pdfplumber is used as a fallback when PyPDF2 fails\n",
      "================================================================================\n",
      "\n",
      "Created directory: rbi_pdfs\n",
      "================================================================================\n",
      "RBI Press Release PDF Scraper - All Pages\n",
      "================================================================================\n",
      "\n",
      "Loading website: https://rbi.org.in/Scripts/BS_PressreleaseDisplay.aspx\n",
      "âš  No pagination found, assuming single page\n",
      "\n",
      "âœ“ Will scrape 1 page(s)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PROCESSING PAGE 1 of 1\n",
      "================================================================================\n",
      "\n",
      "âœ“ Found 55 PDFs on page 1\n",
      "\n",
      "[PDF 1/55 on Page 1] (Overall: 1)\n",
      "  Downloading: Treasury Bills: Full Auction Result...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1456CB0AABB86A474281B8AF568E7E58A7AD.PDF\n",
      "  âœ“ Saved PDF: page1_pdf001_Nov_06_2025_Treasury_Bills_Full_Auction_Result.pdf (284 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 2/55 on Page 1] (Overall: 2)\n",
      "  Downloading: 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR145593F4EF78749D4FB298774F46094AC63B.PDF\n",
      "  âœ“ Saved PDF: page1_pdf002_Nov_06_2025_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_C.pdf (240 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 3/55 on Page 1] (Overall: 3)\n",
      "  Downloading: Underwriting Auction for sale of Government Security for â‚¹32...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14544EE127CF73E44543AB068F237CB069D0.PDF\n",
      "  âœ“ Saved PDF: page1_pdf003_Nov_06_2025_Underwriting_Auction_for_sale_of_Government_Securi.pdf (295 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 4/55 on Page 1] (Overall: 4)\n",
      "  Downloading: Money Market Operations as on November 05, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1453MMO2C919431676C448AB02AD0D9E36B667B.PDF\n",
      "  âœ“ Saved PDF: page1_pdf004_Nov_06_2025_Money_Market_Operations_as_on_November_05_2025.pdf (317 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 5/55 on Page 1] (Overall: 5)\n",
      "  Downloading: Money Market Operations as on November 04, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1452MMO4457F193A111451B8757CDFA0A3A6631.PDF\n",
      "  âœ“ Saved PDF: page1_pdf005_Nov_06_2025_Money_Market_Operations_as_on_November_04_2025.pdf (322 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 6/55 on Page 1] (Overall: 6)\n",
      "  Downloading: Final redemption under Sovereign Gold Bond (SGB) Scheme - Re...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1451E57A27AB72064813908CF985E082B62B.PDF\n",
      "  âœ“ Saved PDF: page1_pdf006_Nov_04_2025_Final_redemption_under_Sovereign_Gold_Bond_SGB_Sch.pdf (154 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 7/55 on Page 1] (Overall: 7)\n",
      "  Downloading: RBI imposes monetary penalty on Latur District Central Co-op...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1450E08CF403893F49A5B6CBCDC9F52E9DAE.PDF\n",
      "  âœ“ Saved PDF: page1_pdf007_Nov_04_2025_RBI_imposes_monetary_penalty_on_Latur_District_Cen.pdf (306 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 8/55 on Page 1] (Overall: 8)\n",
      "  Downloading: RBI imposes monetary penalty on Parbhani District Central Co...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR144981783187906E4BDEB1717F18413D5C88.PDF\n",
      "  âœ“ Saved PDF: page1_pdf008_Nov_04_2025_RBI_imposes_monetary_penalty_on_Parbhani_District_.pdf (374 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 9/55 on Page 1] (Overall: 9)\n",
      "  Downloading: RBI imposes monetary penalty on Viva Home Finance Limited, P...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1448F3140F5BFA24453081C4339AEEA7F30A.PDF\n",
      "  âœ“ Saved PDF: page1_pdf009_Nov_04_2025_RBI_imposes_monetary_penalty_on_Viva_Home_Finance_.pdf (337 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 10/55 on Page 1] (Overall: 10)\n",
      "  Downloading: RBI imposes monetary penalty on The Satara Sahakari Bank Ltd...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1447E1CF12A578CD4DD293C1EE27942E6301.PDF\n",
      "  âœ“ Saved PDF: page1_pdf010_Nov_04_2025_RBI_imposes_monetary_penalty_on_The_Satara_Sahakar.pdf (329 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 11/55 on Page 1] (Overall: 11)\n",
      "  Downloading: Survey on Computer Software and Information Technology Enabl...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14466DF1C349F44F4CF788D653D8EBCB2565.PDF\n",
      "  âœ“ Saved PDF: page1_pdf011_Nov_04_2025_Survey_on_Computer_Software_and_Information_Techno.pdf (531 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 12/55 on Page 1] (Overall: 12)\n",
      "  Downloading: State Government Securities - Full Auction Result...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1445DDBBAEADF6C44A40985A6E284B5C190E.PDF\n",
      "  âœ“ Saved PDF: page1_pdf012_Nov_04_2025_State_Government_Securities_-_Full_Auction_Result.pdf (432 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 13/55 on Page 1] (Overall: 13)\n",
      "  Downloading: Result of Yield/Price Based Auction of State Government Secu...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14447584B590519C401D8E5A0586E585C317.PDF\n",
      "  âœ“ Saved PDF: page1_pdf013_Nov_04_2025_Result_of_YieldPrice_Based_Auction_of_State_Govern.pdf (298 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 14/55 on Page 1] (Overall: 14)\n",
      "  Downloading: Financial Action Task Force (FATF) High risk and other monit...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR144349E7A53CFFCD413AB74621339F09E37D.PDF\n",
      "  âœ“ Saved PDF: page1_pdf014_Nov_04_2025_Financial_Action_Task_Force_FATF_High_risk_and_oth.pdf (388 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 15/55 on Page 1] (Overall: 15)\n",
      "  Downloading: Money Market Operations as on November 03, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1442MMO47EFDC90ECD9460FBC148CA180BD39F4.PDF\n",
      "  âœ“ Saved PDF: page1_pdf015_Nov_04_2025_Money_Market_Operations_as_on_November_03_2025.pdf (346 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 16/55 on Page 1] (Overall: 16)\n",
      "  Downloading: Auction of Government of India Dated Security...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR144102559B86747F405C9EFE7687FF0E72E7.PDF\n",
      "  âœ“ Saved PDF: page1_pdf016_Nov_03_2025_Auction_of_Government_of_India_Dated_Security.pdf (450 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 17/55 on Page 1] (Overall: 17)\n",
      "  Downloading: Premature redemption under Sovereign Gold Bond (SGB) Scheme ...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1440CA18BF23AFDA4530AF4D0347BC637239.PDF\n",
      "  âœ“ Saved PDF: page1_pdf017_Nov_03_2025_Premature_redemption_under_Sovereign_Gold_Bond_SGB.pdf (280 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 18/55 on Page 1] (Overall: 18)\n",
      "  Downloading: Money Market Operations as on November 02, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1439243EBA20F6404DB8829BD3BBD83A3625.PDF\n",
      "  âœ“ Saved PDF: page1_pdf018_Nov_03_2025_Money_Market_Operations_as_on_November_02_2025.pdf (323 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 19/55 on Page 1] (Overall: 19)\n",
      "  Downloading: Money Market Operations as on November 01, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1438MMO5969E19CAC1F4C02A21C221114CA4C35.PDF\n",
      "  âœ“ Saved PDF: page1_pdf019_Nov_03_2025_Money_Market_Operations_as_on_November_01_2025.pdf (319 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 20/55 on Page 1] (Overall: 20)\n",
      "  Downloading: Money Market Operations as on October 31, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1437MMO313A0B6573CC45AD8A46BB5A55F8900F.PDF\n",
      "  âœ“ Saved PDF: page1_pdf020_Nov_03_2025_Money_Market_Operations_as_on_October_31_2025.pdf (349 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 21/55 on Page 1] (Overall: 21)\n",
      "  Downloading: Processing of Applications Received Under the Citizenâ€™s Char...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14363C2F339563EA49009C139D59DF243852.PDF\n",
      "  âœ“ Saved PDF: page1_pdf021_Nov_01_2025_Processing_of_Applications_Received_Under_the_Citi.pdf (318 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 22/55 on Page 1] (Overall: 22)\n",
      "  Downloading: Withdrawal of â‚¹2000 Denomination Banknotes â€“ Status...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR143593E579758E2940A2853C7F17F0EBAA67.PDF\n",
      "  âœ“ Saved PDF: page1_pdf022_Nov_01_2025_Withdrawal_of_2000_Denomination_Banknotes_Status.pdf (341 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 23/55 on Page 1] (Overall: 23)\n",
      "  Downloading: 619thMeeting of Central Board of the Reserve Bank of India...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1434FE631D8D01C94A2D92B845D2D9BAB3C7.PDF\n",
      "  âœ“ Saved PDF: page1_pdf023_Oct_31_2025_619thMeeting_of_Central_Board_of_the_Reserve_Bank_.pdf (291 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 24/55 on Page 1] (Overall: 24)\n",
      "  Downloading: RBI launches the November 2025 round of Urban Consumer Confi...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14331BB43FAD13804C6485ECB1A916EE2227.PDF\n",
      "  âœ“ Saved PDF: page1_pdf024_Oct_31_2025_RBI_launches_the_November_2025_round_of_Urban_Cons.pdf (369 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 25/55 on Page 1] (Overall: 25)\n",
      "  Downloading: RBI launches the November 2025 round of the Rural Consumer C...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR143232EF1D55D93E4754BD89D14ABCE9CF2C.PDF\n",
      "  âœ“ Saved PDF: page1_pdf025_Oct_31_2025_RBI_launches_the_November_2025_round_of_the_Rural_.pdf (284 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 26/55 on Page 1] (Overall: 26)\n",
      "  Downloading: RBI launches the November 2025 round of the Inflation Expect...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1431F427E147B4764AB69A6E8B7F243EE9B8.PDF\n",
      "  âœ“ Saved PDF: page1_pdf026_Oct_31_2025_RBI_launches_the_November_2025_round_of_the_Inflat.pdf (264 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 27/55 on Page 1] (Overall: 27)\n",
      "  Downloading: Auction of State Government Securities...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR143042C42BF708C140D1B3B74AB689A710EB.PDF\n",
      "  âœ“ Saved PDF: page1_pdf027_Oct_31_2025_Auction_of_State_Government_Securities.pdf (412 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 28/55 on Page 1] (Overall: 28)\n",
      "  Downloading: Lending and Deposit Rates of Scheduled Commercial Banks â€“ Oc...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14292B4B8F7D5C6F4AC794A46B3DACF3C393.PDF\n",
      "  âœ“ Saved PDF: page1_pdf028_Oct_31_2025_Lending_and_Deposit_Rates_of_Scheduled_Commercial_.pdf (288 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 29/55 on Page 1] (Overall: 29)\n",
      "  Downloading: Monthly Data on Indiaâ€™s International Trade in Services  for...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14286754E6C89EA04E6FBCE6626CE3CDF389.PDF\n",
      "  âœ“ Saved PDF: page1_pdf029_Oct_31_2025_Monthly_Data_on_Indias_International_Trade_in_Serv.pdf (271 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 30/55 on Page 1] (Overall: 30)\n",
      "  Downloading: Auction of 91-Day, 182-Day and 364-Day Treasury Bills...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1427F854D8F4EC9B4DEA8398687503ECEECA.PDF\n",
      "  âœ“ Saved PDF: page1_pdf030_Oct_31_2025_Auction_of_91-Day_182-Day_and_364-Day_Treasury_Bil.pdf (376 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 31/55 on Page 1] (Overall: 31)\n",
      "  Downloading: Money Supply for the fortnight ended October 17, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14269C6FED3E7DE84080A907349302E58A03.PDF\n",
      "  âœ“ Saved PDF: page1_pdf031_Oct_31_2025_Money_Supply_for_the_fortnight_ended_October_17_20.pdf (285 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 32/55 on Page 1] (Overall: 32)\n",
      "  Downloading: Reserve Bank of India â€“ Bulletin Weekly Statistical Suppleme...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1425WSSC2604712EE344740A6AA88FCB66F4DF9.PDF\n",
      "  âœ“ Saved PDF: page1_pdf032_Oct_31_2025_Reserve_Bank_of_India_Bulletin_Weekly_Statistical.pdf (377 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 33/55 on Page 1] (Overall: 33)\n",
      "  Downloading: Government Stock - Full Auction Results...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14249B673518E0334641BBC32942C998533E.PDF\n",
      "  âœ“ Saved PDF: page1_pdf033_Oct_31_2025_Government_Stock_-_Full_Auction_Results.pdf (300 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 34/55 on Page 1] (Overall: 34)\n",
      "  Downloading: Sectoral Deployment of Bank Credit â€“ September 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1423BC58B5E54AC54B8793D56D5B6B53B12D.PDF\n",
      "  âœ“ Saved PDF: page1_pdf034_Oct_31_2025_Sectoral_Deployment_of_Bank_Credit_September_2025.pdf (396 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 35/55 on Page 1] (Overall: 35)\n",
      "  Downloading: Government Stock - Auction Results: Cut-off...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1422AEBB7C77D95747549CD4538A7B1DDE91.PDF\n",
      "  âœ“ Saved PDF: page1_pdf035_Oct_31_2025_Government_Stock_-_Auction_Results_Cut-off.pdf (370 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 36/55 on Page 1] (Overall: 36)\n",
      "  Downloading: Result of Underwriting Auction conducted on October 31, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1421D047F45514BB41AF9D560586FA61A6C0.PDF\n",
      "  âœ“ Saved PDF: page1_pdf036_Oct_31_2025_Result_of_Underwriting_Auction_conducted_on_Octobe.pdf (247 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 37/55 on Page 1] (Overall: 37)\n",
      "  Downloading: Money Market Operations as on October 30, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR142096447D2005B44EDCA6D9728F56DF383F.PDF\n",
      "  âœ“ Saved PDF: page1_pdf037_Oct_31_2025_Money_Market_Operations_as_on_October_30_2025.pdf (322 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 38/55 on Page 1] (Overall: 38)\n",
      "  Downloading: RBI imposes monetary penalty on Parner Taluka Sainik Sahakar...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1419D9C1E4FF97BB447997AFB4AA8E228FF1.PDF\n",
      "  âœ“ Saved PDF: page1_pdf038_Oct_30_2025_RBI_imposes_monetary_penalty_on_Parner_Taluka_Sain.pdf (321 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 39/55 on Page 1] (Overall: 39)\n",
      "  Downloading: RBI imposes monetary penalty on The Mehsana Urban Co-operati...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1418A17768F843FE45788EF5CE87BFA59410.PDF\n",
      "  âœ“ Saved PDF: page1_pdf039_Oct_30_2025_RBI_imposes_monetary_penalty_on_The_Mehsana_Urban_.pdf (307 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 40/55 on Page 1] (Overall: 40)\n",
      "  Downloading: Scheduled Banksâ€™ Statement of Position in India as on Friday...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1417B749B2133B82483F8CAD2B0BA4B6AB13.PDF\n",
      "  âœ“ Saved PDF: page1_pdf040_Oct_30_2025_Scheduled_Banks_Statement_of_Position_in_India_as_.pdf (346 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 41/55 on Page 1] (Overall: 41)\n",
      "  Downloading: Underwriting Auction for sale of Government Securities for â‚¹...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14165D8A61199E0C404C8465D7E7A31BA0CA.PDF\n",
      "  âœ“ Saved PDF: page1_pdf041_Oct_30_2025_Underwriting_Auction_for_sale_of_Government_Securi.pdf (387 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 42/55 on Page 1] (Overall: 42)\n",
      "  Downloading: Result of the Overnight Variable Rate Repo (VRR) auction hel...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1415DF0248AE87B14F99A9F5DC278A1D9D0E.PDF\n",
      "  âœ“ Saved PDF: page1_pdf042_Oct_30_2025_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auc.pdf (312 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 43/55 on Page 1] (Overall: 43)\n",
      "  Downloading: Money Market Operations as on October 29, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR141497347531DD374D87BA3B18648382F63C.PDF\n",
      "  âœ“ Saved PDF: page1_pdf043_Oct_30_2025_Money_Market_Operations_as_on_October_29_2025.pdf (322 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 44/55 on Page 1] (Overall: 44)\n",
      "  Downloading: RBI to conduct Overnight Variable Rate Repo (VRR) auction un...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14130E151BA1EB2A47E4BBFA21D1440A6EA0.PDF\n",
      "  âœ“ Saved PDF: page1_pdf044_Oct_29_2025_RBI_to_conduct_Overnight_Variable_Rate_Repo_VRR_au.pdf (161 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 45/55 on Page 1] (Overall: 45)\n",
      "  Downloading: Premature redemption under Sovereign Gold Bond (SGB) Scheme ...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR141205375279CC5C4858A135C458B5BB3FEF.PDF\n",
      "  âœ“ Saved PDF: page1_pdf045_Oct_29_2025_Premature_redemption_under_Sovereign_Gold_Bond_SGB.pdf (285 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 46/55 on Page 1] (Overall: 46)\n",
      "  Downloading: Final redemption under Sovereign Gold Bond (SGB) Scheme - Re...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1411EBE5EFE58D514157BBB9729FD6557061.PDF\n",
      "  âœ“ Saved PDF: page1_pdf046_Oct_29_2025_Final_redemption_under_Sovereign_Gold_Bond_SGB_Sch.pdf (285 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 47/55 on Page 1] (Overall: 47)\n",
      "  Downloading: RBI releases Draft circular on Guidelines to facilitate fast...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1410B0EEEF3CC00D4183B125227C9B57F09C.PDF\n",
      "  âœ“ Saved PDF: page1_pdf047_Oct_29_2025_RBI_releases_Draft_circular_on_Guidelines_to_facil.pdf (291 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 48/55 on Page 1] (Overall: 48)\n",
      "  Downloading: Rate of Interest on Government of India Floating Rate Bond 2...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1409BDDB26B5139D40E7A6E5CF6F32C56C41.PDF\n",
      "  âœ“ Saved PDF: page1_pdf048_Oct_29_2025_Rate_of_Interest_on_Government_of_India_Floating_R.pdf (263 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 49/55 on Page 1] (Overall: 49)\n",
      "  Downloading: Census on Foreign Liabilities and Assets of Indian Direct In...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14087365654471CD402C903E3FA859DF5CBC.PDF\n",
      "  âœ“ Saved PDF: page1_pdf049_Oct_29_2025_Census_on_Foreign_Liabilities_and_Assets_of_Indian.pdf (644 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 50/55 on Page 1] (Overall: 50)\n",
      "  Downloading: Reserve Money for the fortnight ended October 24, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1407EAAD781B45984B8F807763279834584F.PDF\n",
      "  âœ“ Saved PDF: page1_pdf050_Oct_29_2025_Reserve_Money_for_the_fortnight_ended_October_24_2.pdf (286 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 51/55 on Page 1] (Overall: 51)\n",
      "  Downloading: Treasury Bills: Full Auction Result...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR140606E7E9F81CA044B68AEF56259AF1F660.PDF\n",
      "  âœ“ Saved PDF: page1_pdf051_Oct_29_2025_Treasury_Bills_Full_Auction_Result.pdf (323 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 52/55 on Page 1] (Overall: 52)\n",
      "  Downloading: 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1405C094DE94AC8249238905BA018EB8F26A.PDF\n",
      "  âœ“ Saved PDF: page1_pdf052_Oct_29_2025_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_C.pdf (279 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 53/55 on Page 1] (Overall: 53)\n",
      "  Downloading: Scheme for writing books originally in Hindi on Economics/Ba...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR14047E42F99835414418A533D71BC160F3F8.PDF\n",
      "  âœ“ Saved PDF: page1_pdf053_Oct_29_2025_Scheme_for_writing_books_originally_in_Hindi_on_Ec.pdf (329 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 54/55 on Page 1] (Overall: 54)\n",
      "  Downloading: Result of the Overnight Variable Rate Repo (VRR) auction hel...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR1403B9051471501B41AD97C71AE7D9B654D7.PDF\n",
      "  âœ“ Saved PDF: page1_pdf054_Oct_29_2025_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auc.pdf (312 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "[PDF 55/55 on Page 1] (Overall: 55)\n",
      "  Downloading: Money Market Operations as on October 28, 2025...\n",
      "  URL: https://rbidocs.rbi.org.in/rdocs/PressRelease/PDFs/PR140245515131C83F4129BEA8C529616A0C84.PDF\n",
      "  âœ“ Saved PDF: page1_pdf055_Oct_29_2025_Money_Market_Operations_as_on_October_28_2025.pdf (352 kb)\n",
      "  âš  pdfplumber extraction failed: pdfplumber failed: No /Root object! - Is this really a PDF?\n",
      "  âš  PyPDF2 extraction failed: PyPDF2 failed: EOF marker not found\n",
      "  âš  Text extraction failed - PDF saved but text not extracted\n",
      "\n",
      "âœ“ Completed page 1\n",
      "\n",
      "Metadata saved to: rbi_pdfs\\metadata.json\n",
      "Summary CSV saved to: rbi_pdfs\\summary.csv\n",
      "\n",
      "Closing browser...\n",
      "\n",
      "================================================================================\n",
      "SCRAPING COMPLETED!\n",
      "================================================================================\n",
      "Total PDFs processed: 55\n",
      "Text extracted successfully: 0\n",
      "Text extraction failed: 55\n",
      "Output directory: c:\\Users\\abhim\\OneDrive\\Desktop\\news-scapper1\\backend\\venv\\rbi_pdfs\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DETAILED SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total Pages Scraped: 1\n",
      "Total Dates: 7\n",
      "Total PDFs: 55\n",
      "\n",
      "--- Extraction Methods ---\n",
      "  Failed: 55 PDFs\n",
      "\n",
      "--- By Page ---\n",
      "\n",
      "Page 1 (55 PDFs):\n",
      "  âœ— 001. [Nov 06, 2025] Treasury Bills: Full Auction Result...\n",
      "  âœ— 002. [Nov 06, 2025] 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-...\n",
      "  âœ— 003. [Nov 06, 2025] Underwriting Auction for sale of Government Security fo...\n",
      "  ... and 52 more\n",
      "\n",
      "--- By Date ---\n",
      "\n",
      "Oct 31, 2025 (15 PDFs):\n",
      "  â€¢ 619thMeeting of Central Board of the Reserve Bank of India...\n",
      "  â€¢ RBI launches the November 2025 round of Urban Consumer Confidence...\n",
      "  â€¢ RBI launches the November 2025 round of the Rural Consumer Confid...\n",
      "  ... and 12 more\n",
      "\n",
      "Oct 30, 2025 (6 PDFs):\n",
      "  â€¢ RBI imposes monetary penalty on Parner Taluka Sainik Sahakari Ban...\n",
      "  â€¢ RBI imposes monetary penalty on The Mehsana Urban Co-operative Ba...\n",
      "  â€¢ Scheduled Banksâ€™ Statement of Position in India as on Friday, Oct...\n",
      "  ... and 3 more\n",
      "\n",
      "Oct 29, 2025 (12 PDFs):\n",
      "  â€¢ RBI to conduct Overnight Variable Rate Repo (VRR) auction under L...\n",
      "  â€¢ Premature redemption under Sovereign Gold Bond (SGB) Scheme - Red...\n",
      "  â€¢ Final redemption under Sovereign Gold Bond (SGB) Scheme - Redempt...\n",
      "  ... and 9 more\n",
      "\n",
      "Nov 06, 2025 (5 PDFs):\n",
      "  â€¢ Treasury Bills: Full Auction Result...\n",
      "  â€¢ 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off...\n",
      "  â€¢ Underwriting Auction for sale of Government Security for â‚¹32,000 ...\n",
      "  ... and 2 more\n",
      "\n",
      "Nov 04, 2025 (10 PDFs):\n",
      "  â€¢ Final redemption under Sovereign Gold Bond (SGB) Scheme - Redempt...\n",
      "  â€¢ RBI imposes monetary penalty on Latur District Central Co-operati...\n",
      "  â€¢ RBI imposes monetary penalty on Parbhani District Central Coopera...\n",
      "  ... and 7 more\n",
      "\n",
      "================================================================================\n",
      "All files saved in: c:\\Users\\abhim\\OneDrive\\Desktop\\news-scapper1\\backend\\venv\\rbi_pdfs\n",
      "Files created:\n",
      "  â€¢ 55 PDF files\n",
      "  â€¢ 55 TXT files (extracted text)\n",
      "  â€¢ 1 metadata.json file\n",
      "  â€¢ 1 summary.csv file\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import pdfplumber\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "class RBIPDFScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://rbi.org.in/Scripts/BS_PressreleaseDisplay.aspx\"\n",
    "        self.output_dir = \"rbi_pdfs\"\n",
    "        \n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            print(f\"Created directory: {self.output_dir}\")\n",
    "        \n",
    "        # Setup Chrome options\n",
    "        self.chrome_options = webdriver.ChromeOptions()\n",
    "        self.chrome_options.add_argument('--headless')\n",
    "        self.chrome_options.add_argument('--no-sandbox')\n",
    "        self.chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        self.chrome_options.add_argument('--disable-gpu')\n",
    "        self.chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "        \n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        })\n",
    "        \n",
    "        self.pdf_data = []\n",
    "        \n",
    "    def init_driver(self):\n",
    "        \"\"\"Initialize Selenium WebDriver\"\"\"\n",
    "        try:\n",
    "            self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "            self.driver.maximize_window()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing driver: {e}\")\n",
    "            print(\"Make sure ChromeDriver is installed and in PATH\")\n",
    "            return False\n",
    "    \n",
    "    def extract_pdf_info_from_html(self, html_content):\n",
    "        \"\"\"Extract all PDF information from the HTML content\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        pdf_info_list = []\n",
    "        \n",
    "        # Find all table rows\n",
    "        table = soup.find('table', class_='tablebg')\n",
    "        if not table:\n",
    "            print(\"Warning: Could not find table with class 'tablebg'\")\n",
    "            return pdf_info_list\n",
    "        \n",
    "        rows = table.find_all('tr')\n",
    "        current_date = \"Unknown Date\"\n",
    "        \n",
    "        for row in rows:\n",
    "            try:\n",
    "                # Check if this row is a date header\n",
    "                date_header = row.find('h2', class_='dop_header')\n",
    "                if date_header:\n",
    "                    current_date = date_header.get_text(strip=True)\n",
    "                    continue\n",
    "                \n",
    "                # Extract title and PDF link\n",
    "                title_link = row.find('a', class_='link2')\n",
    "                if not title_link:\n",
    "                    continue\n",
    "                \n",
    "                title = title_link.get_text(strip=True)\n",
    "                \n",
    "                # Find PDF link\n",
    "                pdf_link = row.find('a', href=re.compile(r'\\.PDF$', re.IGNORECASE))\n",
    "                if not pdf_link:\n",
    "                    continue\n",
    "                \n",
    "                pdf_url = pdf_link.get('href')\n",
    "                \n",
    "                # Make sure URL is absolute\n",
    "                if not pdf_url.startswith('http'):\n",
    "                    pdf_url = 'https://rbidocs.rbi.org.in' + pdf_url if pdf_url.startswith('/') else 'https://rbidocs.rbi.org.in/' + pdf_url\n",
    "                \n",
    "                # Extract file size\n",
    "                size_span = pdf_link.find_next_sibling('span')\n",
    "                file_size = size_span.get_text(strip=True) if size_span else \"Unknown size\"\n",
    "                \n",
    "                pdf_info_list.append({\n",
    "                    'title': title,\n",
    "                    'date': current_date,\n",
    "                    'url': pdf_url,\n",
    "                    'size': file_size\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting PDF info from row: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return pdf_info_list\n",
    "    \n",
    "    def extract_text_with_pypdf2(self, pdf_content):\n",
    "        \"\"\"Extract text using PyPDF2\"\"\"\n",
    "        try:\n",
    "            pdf_file = io.BytesIO(pdf_content)\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            \n",
    "            text_content = []\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            \n",
    "            for page_idx in range(num_pages):\n",
    "                page = pdf_reader.pages[page_idx]\n",
    "                page_text = page.extract_text()\n",
    "                if page_text.strip():\n",
    "                    text_content.append(f\"--- Page {page_idx + 1} of {num_pages} ---\\n{page_text}\\n\")\n",
    "            \n",
    "            text = \"\\n\".join(text_content)\n",
    "            return text, num_pages, \"PyPDF2\"\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"PyPDF2 failed: {e}\")\n",
    "    \n",
    "    def extract_text_with_pdfplumber(self, pdf_content):\n",
    "        \"\"\"Extract text using pdfplumber (more robust)\"\"\"\n",
    "        try:\n",
    "            pdf_file = io.BytesIO(pdf_content)\n",
    "            text_content = []\n",
    "            \n",
    "            with pdfplumber.open(pdf_file) as pdf:\n",
    "                num_pages = len(pdf.pages)\n",
    "                \n",
    "                for page_idx, page in enumerate(pdf.pages):\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text and page_text.strip():\n",
    "                        text_content.append(f\"--- Page {page_idx + 1} of {num_pages} ---\\n{page_text}\\n\")\n",
    "            \n",
    "            text = \"\\n\".join(text_content)\n",
    "            return text, num_pages, \"pdfplumber\"\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"pdfplumber failed: {e}\")\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_content):\n",
    "        \"\"\"Try multiple methods to extract text from PDF\"\"\"\n",
    "        extraction_methods = [\n",
    "            (\"pdfplumber\", self.extract_text_with_pdfplumber),\n",
    "            (\"PyPDF2\", self.extract_text_with_pypdf2)\n",
    "        ]\n",
    "        \n",
    "        for method_name, method_func in extraction_methods:\n",
    "            try:\n",
    "                text, num_pages, used_method = method_func(pdf_content)\n",
    "                if text and text.strip():\n",
    "                    return text, num_pages, used_method\n",
    "            except Exception as e:\n",
    "                print(f\"  âš  {method_name} extraction failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # If all methods fail, return failure indicator\n",
    "        return \"[Text extraction failed - PDF may be image-based or corrupted]\", 0, \"Failed\"\n",
    "    \n",
    "    def download_and_extract_pdf(self, pdf_info, page_num, pdf_index):\n",
    "        \"\"\"Download PDF and extract text content\"\"\"\n",
    "        try:\n",
    "            print(f\"  Downloading: {pdf_info['title'][:60]}...\")\n",
    "            print(f\"  URL: {pdf_info['url']}\")\n",
    "            \n",
    "            # Download PDF with timeout and retries\n",
    "            max_retries = 3\n",
    "            pdf_content = None\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = self.session.get(pdf_info['url'], timeout=60)\n",
    "                    response.raise_for_status()\n",
    "                    pdf_content = response.content\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"  Retry {attempt + 1}/{max_retries}...\")\n",
    "                        time.sleep(2)\n",
    "                    else:\n",
    "                        raise e\n",
    "            \n",
    "            if not pdf_content:\n",
    "                print(f\"  âœ— Failed to download PDF\")\n",
    "                return False\n",
    "            \n",
    "            # Create safe filename\n",
    "            safe_date = pdf_info['date'].replace('/', '-').replace(' ', '_').replace(',', '')\n",
    "            safe_title = re.sub(r'[^\\w\\s-]', '', pdf_info['title'])[:50]\n",
    "            safe_title = re.sub(r'\\s+', '_', safe_title)\n",
    "            safe_filename = f\"page{page_num}_pdf{pdf_index:03d}_{safe_date}_{safe_title}\"\n",
    "            \n",
    "            # Save PDF file\n",
    "            pdf_path = os.path.join(self.output_dir, f\"{safe_filename}.pdf\")\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(pdf_content)\n",
    "            print(f\"  âœ“ Saved PDF: {safe_filename}.pdf ({pdf_info['size']})\")\n",
    "            \n",
    "            # Extract text from PDF using multiple methods\n",
    "            text, num_pages, extraction_method = self.extract_text_from_pdf(pdf_content)\n",
    "            \n",
    "            if extraction_method != \"Failed\":\n",
    "                print(f\"  âœ“ Extracted text using {extraction_method}: {safe_filename}.txt ({num_pages} pages)\")\n",
    "            else:\n",
    "                print(f\"  âš  Text extraction failed - PDF saved but text not extracted\")\n",
    "            \n",
    "            # Save extracted text\n",
    "            text_path = os.path.join(self.output_dir, f\"{safe_filename}.txt\")\n",
    "            with open(text_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Source: RBI Press Release\\n\")\n",
    "                f.write(f\"Webpage Page Number: {page_num}\\n\")\n",
    "                f.write(f\"PDF Index: {pdf_index}\\n\")\n",
    "                f.write(f\"Title: {pdf_info['title']}\\n\")\n",
    "                f.write(f\"Date: {pdf_info['date']}\\n\")\n",
    "                f.write(f\"File Size: {pdf_info['size']}\\n\")\n",
    "                f.write(f\"URL: {pdf_info['url']}\\n\")\n",
    "                f.write(f\"PDF Pages: {num_pages}\\n\")\n",
    "                f.write(f\"Extraction Method: {extraction_method}\\n\")\n",
    "                f.write(\"=\"*80 + \"\\n\\n\")\n",
    "                f.write(text)\n",
    "            \n",
    "            # Store metadata\n",
    "            self.pdf_data.append({\n",
    "                'page': page_num,\n",
    "                'index': pdf_index,\n",
    "                'title': pdf_info['title'],\n",
    "                'date': pdf_info['date'],\n",
    "                'url': pdf_info['url'],\n",
    "                'size': pdf_info['size'],\n",
    "                'filename': safe_filename,\n",
    "                'text_length': len(text),\n",
    "                'pdf_pages': num_pages,\n",
    "                'extraction_method': extraction_method\n",
    "            })\n",
    "            \n",
    "            return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error processing PDF: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_total_pages(self):\n",
    "        \"\"\"Extract total number of pages from pagination\"\"\"\n",
    "        try:\n",
    "            # Wait for pagination to load\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Look for pagination links\n",
    "            pagination_links = self.driver.find_elements(By.CSS_SELECTOR, \"a[href*='javascript:__doPostBack']\")\n",
    "            \n",
    "            page_numbers = []\n",
    "            for link in pagination_links:\n",
    "                try:\n",
    "                    text = link.text.strip()\n",
    "                    if text.isdigit():\n",
    "                        page_numbers.append(int(text))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if page_numbers:\n",
    "                total = max(page_numbers)\n",
    "                print(f\"âœ“ Detected {total} pages from pagination links\")\n",
    "                return total\n",
    "            \n",
    "            # If no pagination links found, assume single page\n",
    "            print(\"âš  No pagination found, assuming single page\")\n",
    "            return 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting total pages: {e}\")\n",
    "            return 1\n",
    "    \n",
    "    def click_next_page(self):\n",
    "        \"\"\"Click the next page button\"\"\"\n",
    "        try:\n",
    "            # Try to find and click \"Next\" or \">\" button\n",
    "            # Different possible selectors for next button\n",
    "            next_selectors = [\n",
    "                \"a[title='Next Page']\",\n",
    "                \"input[title='Next Page']\",\n",
    "                \"a:contains('Next')\",\n",
    "                \"img[alt='Next']\"\n",
    "            ]\n",
    "            \n",
    "            for selector in next_selectors:\n",
    "                try:\n",
    "                    next_button = self.driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                    \n",
    "                    if next_button.is_displayed() and next_button.is_enabled():\n",
    "                        # Scroll to button\n",
    "                        self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                        # Click\n",
    "                        next_button.click()\n",
    "                        time.sleep(3)\n",
    "                        \n",
    "                        return True\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            print(\"Could not find Next button\")\n",
    "            return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error clicking next page: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def click_page_number(self, page_num):\n",
    "        \"\"\"Click on a specific page number link\"\"\"\n",
    "        try:\n",
    "            # Find all links that might be page numbers\n",
    "            page_links = self.driver.find_elements(By.CSS_SELECTOR, \"a[href*='javascript:__doPostBack']\")\n",
    "            \n",
    "            for link in page_links:\n",
    "                if link.text.strip() == str(page_num):\n",
    "                    # Scroll to element\n",
    "                    self.driver.execute_script(\"arguments[0].scrollIntoView(true);\", link)\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Click the link\n",
    "                    link.click()\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "                    return True\n",
    "            \n",
    "            return False\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error clicking page {page_num}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def save_metadata(self):\n",
    "        \"\"\"Save metadata to JSON file\"\"\"\n",
    "        metadata_path = os.path.join(self.output_dir, 'metadata.json')\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.pdf_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nMetadata saved to: {metadata_path}\")\n",
    "        \n",
    "        # Also save a summary CSV\n",
    "        csv_path = os.path.join(self.output_dir, 'summary.csv')\n",
    "        with open(csv_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Page,Index,Date,Title,Size,PDF_Pages,Extraction_Method,Filename\\n\")\n",
    "            for pdf in self.pdf_data:\n",
    "                f.write(f\"{pdf['page']},{pdf['index']},\\\"{pdf['date']}\\\",\\\"{pdf['title']}\\\",\\\"{pdf['size']}\\\",{pdf.get('pdf_pages', 0)},\\\"{pdf.get('extraction_method', 'Unknown')}\\\",\\\"{pdf['filename']}\\\"\\n\")\n",
    "        print(f\"Summary CSV saved to: {csv_path}\")\n",
    "    \n",
    "    def scrape_all_pages(self, max_pages=None):\n",
    "        \"\"\"Main method to scrape all pages\n",
    "        \n",
    "        Args:\n",
    "            max_pages: Maximum number of pages to scrape (None = all pages)\n",
    "        \"\"\"\n",
    "        print(\"=\"*80)\n",
    "        print(\"RBI Press Release PDF Scraper - All Pages\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if not self.init_driver():\n",
    "            print(\"Failed to initialize browser driver. Exiting.\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Load the main page\n",
    "            print(f\"\\nLoading website: {self.base_url}\")\n",
    "            self.driver.get(self.base_url)\n",
    "            time.sleep(5)\n",
    "            \n",
    "            # Get total number of pages\n",
    "            total_pages = self.get_total_pages()\n",
    "            \n",
    "            if max_pages and max_pages < total_pages:\n",
    "                total_pages = max_pages\n",
    "                print(f\"Limiting scrape to {max_pages} pages\")\n",
    "            \n",
    "            print(f\"\\nâœ“ Will scrape {total_pages} page(s)\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            pdf_counter = 0\n",
    "            \n",
    "            # Process each page\n",
    "            for page_num in range(1, total_pages + 1):\n",
    "                print(f\"\\n{'='*80}\")\n",
    "                print(f\"PROCESSING PAGE {page_num} of {total_pages}\")\n",
    "                print(f\"{'='*80}\")\n",
    "                \n",
    "                # Get current page HTML\n",
    "                page_html = self.driver.page_source\n",
    "                \n",
    "                # Extract PDF information\n",
    "                pdf_info_list = self.extract_pdf_info_from_html(page_html)\n",
    "                print(f\"\\nâœ“ Found {len(pdf_info_list)} PDFs on page {page_num}\")\n",
    "                \n",
    "                # Download and extract each PDF\n",
    "                for i, pdf_info in enumerate(pdf_info_list, 1):\n",
    "                    pdf_counter += 1\n",
    "                    print(f\"\\n[PDF {i}/{len(pdf_info_list)} on Page {page_num}] (Overall: {pdf_counter})\")\n",
    "                    self.download_and_extract_pdf(pdf_info, page_num, pdf_counter)\n",
    "                    time.sleep(1)  # Be polite to the server\n",
    "                \n",
    "                print(f\"\\nâœ“ Completed page {page_num}\")\n",
    "                \n",
    "                # Navigate to next page (if not the last page)\n",
    "                if page_num < total_pages:\n",
    "                    print(f\"\\nNavigating to page {page_num + 1}...\")\n",
    "                    \n",
    "                    # Try clicking specific page number first\n",
    "                    if not self.click_page_number(page_num + 1):\n",
    "                        # If that fails, try clicking Next button\n",
    "                        if not self.click_next_page():\n",
    "                            print(f\"Failed to navigate to page {page_num + 1}. Stopping.\")\n",
    "                            break\n",
    "                    \n",
    "                    print(f\"âœ“ Successfully navigated to page {page_num + 1}\")\n",
    "                \n",
    "                time.sleep(2)\n",
    "            \n",
    "            # Save metadata\n",
    "            self.save_metadata()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError during scraping: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        finally:\n",
    "            # Close the browser\n",
    "            print(\"\\nClosing browser...\")\n",
    "            self.driver.quit()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SCRAPING COMPLETED!\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Total PDFs processed: {len(self.pdf_data)}\")\n",
    "        \n",
    "        # Count successful extractions\n",
    "        successful = sum(1 for pdf in self.pdf_data if pdf.get('extraction_method') != 'Failed')\n",
    "        failed = len(self.pdf_data) - successful\n",
    "        print(f\"Text extracted successfully: {successful}\")\n",
    "        print(f\"Text extraction failed: {failed}\")\n",
    "        print(f\"Output directory: {os.path.abspath(self.output_dir)}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self.pdf_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RBI PDF SCRAPER\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nRequired packages:\")\n",
    "    print(\"  pip install selenium beautifulsoup4 PyPDF2 pdfplumber requests\")\n",
    "    print(\"\\nNote: pdfplumber is used as a fallback when PyPDF2 fails\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    scraper = RBIPDFScraper()\n",
    "    \n",
    "    # Run the scraper\n",
    "    # Set max_pages=None to scrape all pages, or set a number to limit (e.g., max_pages=5)\n",
    "    results = scraper.scrape_all_pages(max_pages=None)\n",
    "    \n",
    "    # Print detailed summary\n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"DETAILED SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Group by page\n",
    "        pages = {}\n",
    "        for pdf in results:\n",
    "            page = pdf.get('page', 1)\n",
    "            if page not in pages:\n",
    "                pages[page] = []\n",
    "            pages[page].append(pdf)\n",
    "        \n",
    "        # Group by date\n",
    "        dates = {}\n",
    "        for pdf in results:\n",
    "            date = pdf.get('date', 'Unknown')\n",
    "            if date not in dates:\n",
    "                dates[date] = []\n",
    "            dates[date].append(pdf)\n",
    "        \n",
    "        # Group by extraction method\n",
    "        methods = {}\n",
    "        for pdf in results:\n",
    "            method = pdf.get('extraction_method', 'Unknown')\n",
    "            if method not in methods:\n",
    "                methods[method] = []\n",
    "            methods[method].append(pdf)\n",
    "        \n",
    "        print(f\"\\nTotal Pages Scraped: {len(pages)}\")\n",
    "        print(f\"Total Dates: {len(dates)}\")\n",
    "        print(f\"Total PDFs: {len(results)}\")\n",
    "        \n",
    "        print(\"\\n--- Extraction Methods ---\")\n",
    "        for method, pdfs in methods.items():\n",
    "            print(f\"  {method}: {len(pdfs)} PDFs\")\n",
    "        \n",
    "        print(\"\\n--- By Page ---\")\n",
    "        for page_num in sorted(pages.keys()):\n",
    "            print(f\"\\nPage {page_num} ({len(pages[page_num])} PDFs):\")\n",
    "            for pdf in pages[page_num][:3]:  # Show first 3 from each page\n",
    "                method_icon = \"âœ“\" if pdf.get('extraction_method') != 'Failed' else \"âœ—\"\n",
    "                print(f\"  {method_icon} {pdf['index']:03d}. [{pdf['date']}] {pdf['title'][:55]}...\")\n",
    "            if len(pages[page_num]) > 3:\n",
    "                print(f\"  ... and {len(pages[page_num]) - 3} more\")\n",
    "        \n",
    "        print(\"\\n--- By Date ---\")\n",
    "        for date in sorted(dates.keys(), reverse=True)[:5]:  # Show 5 most recent dates\n",
    "            print(f\"\\n{date} ({len(dates[date])} PDFs):\")\n",
    "            for pdf in dates[date][:3]:\n",
    "                print(f\"  â€¢ {pdf['title'][:65]}...\")\n",
    "            if len(dates[date]) > 3:\n",
    "                print(f\"  ... and {len(dates[date]) - 3} more\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"All files saved in: {os.path.abspath(scraper.output_dir)}\")\n",
    "        print(\"Files created:\")\n",
    "        print(f\"  â€¢ {len(results)} PDF files\")\n",
    "        print(f\"  â€¢ {len(results)} TXT files (extracted text)\")\n",
    "        print(f\"  â€¢ 1 metadata.json file\")\n",
    "        print(f\"  â€¢ 1 summary.csv file\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be18652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching press releases...\n",
      "Found 55 press releases\n",
      "\n",
      "Processing: Treasury Bills: Full Auction Result\n",
      "\n",
      "Processing: 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off\n",
      "\n",
      "Processing: Underwriting Auction for sale of Government Security for â‚¹32,000 crore on November 07, 2025\n",
      "\n",
      "Processing: Money Market Operations as on November 05, 2025\n",
      "\n",
      "Processing: Money Market Operations as on November 04, 2025\n",
      "\n",
      "\n",
      "Total records scraped: 22\n",
      "Data saved to rbi_treasury_bills.csv\n",
      "Data saved to rbi_treasury_bills.xlsx\n",
      "Data saved to rbi_press_releases_list.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import re\n",
    "\n",
    "class RBIScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://rbi.org.in/Scripts/\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        })\n",
    "    \n",
    "    def get_press_releases(self, url):\n",
    "        \"\"\"Fetch all press releases from the main page\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            releases = []\n",
    "            # Find all press release links\n",
    "            for row in soup.find_all('tr'):\n",
    "                link = row.find('a', class_='link2')\n",
    "                if link and 'href' in link.attrs:\n",
    "                    releases.append({\n",
    "                        'title': link.get_text(strip=True),\n",
    "                        'url': urljoin(self.base_url, link['href']),\n",
    "                        'date': self._extract_date(row)\n",
    "                    })\n",
    "            \n",
    "            return releases\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching press releases: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_date(self, row):\n",
    "        \"\"\"Extract date from the row or previous header\"\"\"\n",
    "        # Look for date header in previous rows\n",
    "        prev = row.find_previous('td', class_='tableheader')\n",
    "        if prev:\n",
    "            h2 = prev.find('h2', class_='dop_header')\n",
    "            if h2:\n",
    "                return h2.get_text(strip=True)\n",
    "        return None\n",
    "    \n",
    "    def scrape_table_from_page(self, url):\n",
    "        \"\"\"Scrape table data from detail page\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find all tables in the page\n",
    "            tables = soup.find_all('table', class_='tablebg')\n",
    "            \n",
    "            all_data = []\n",
    "            for table in tables:\n",
    "                # Try to extract structured data\n",
    "                data = self._parse_table(table)\n",
    "                if data:\n",
    "                    all_data.extend(data)\n",
    "            \n",
    "            return all_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping table from {url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _parse_table(self, table):\n",
    "        \"\"\"Parse table into structured data\"\"\"\n",
    "        rows = []\n",
    "        \n",
    "        # Get all table rows\n",
    "        for tr in table.find_all('tr'):\n",
    "            cells = tr.find_all(['td', 'th'])\n",
    "            if cells:\n",
    "                row_data = [cell.get_text(strip=True) for cell in cells]\n",
    "                # Skip empty rows\n",
    "                if any(row_data):\n",
    "                    rows.append(row_data)\n",
    "        \n",
    "        return rows\n",
    "    \n",
    "    def scrape_treasury_bills(self, url):\n",
    "        \"\"\"Specific scraper for Treasury Bills data\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find the main content table\n",
    "            content_table = soup.find('table', class_='td')\n",
    "            if not content_table:\n",
    "                return None\n",
    "            \n",
    "            # Extract title and date\n",
    "            title_elem = soup.find('h2', class_='dop_header')\n",
    "            title = title_elem.get_text(strip=True) if title_elem else \"Unknown\"\n",
    "            \n",
    "            # Find the data table\n",
    "            data_table = content_table.find('table', class_='tablebg')\n",
    "            if not data_table:\n",
    "                return None\n",
    "            \n",
    "            # Parse the Treasury Bills table\n",
    "            data = []\n",
    "            headers = ['Description', '91-Day', '182-Day', '364-Day']\n",
    "            \n",
    "            for tr in data_table.find_all('tr'):\n",
    "                cells = tr.find_all('td')\n",
    "                if len(cells) >= 2:\n",
    "                    # Skip header rows\n",
    "                    if cells[0].get('class') and 'head' in cells[0].get('class'):\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract row data\n",
    "                    row_data = {}\n",
    "                    \n",
    "                    # Handle different row structures\n",
    "                    if len(cells) == 5:  # Row with Roman numeral, description, and 3 values\n",
    "                        row_data['Section'] = cells[0].get_text(strip=True)\n",
    "                        row_data['Description'] = cells[1].get_text(strip=True)\n",
    "                        row_data['91-Day'] = cells[2].get_text(strip=True)\n",
    "                        row_data['182-Day'] = cells[3].get_text(strip=True)\n",
    "                        row_data['364-Day'] = cells[4].get_text(strip=True)\n",
    "                    elif len(cells) == 4:  # Row without section number\n",
    "                        row_data['Section'] = ''\n",
    "                        row_data['Description'] = cells[0].get_text(strip=True)\n",
    "                        row_data['91-Day'] = cells[1].get_text(strip=True)\n",
    "                        row_data['182-Day'] = cells[2].get_text(strip=True)\n",
    "                        row_data['364-Day'] = cells[3].get_text(strip=True)\n",
    "                    \n",
    "                    if row_data and row_data['Description']:\n",
    "                        data.append(row_data)\n",
    "            \n",
    "            return {\n",
    "                'title': title,\n",
    "                'data': data\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping treasury bills: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_to_csv(self, data, filename):\n",
    "        \"\"\"Save data to CSV file\"\"\"\n",
    "        try:\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Data saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to CSV: {e}\")\n",
    "    \n",
    "    def save_to_excel(self, data, filename):\n",
    "        \"\"\"Save data to Excel file\"\"\"\n",
    "        try:\n",
    "            df = pd.DataFrame(data)\n",
    "            df.to_excel(filename, index=False, engine='openpyxl')\n",
    "            print(f\"Data saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to Excel: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize scraper\n",
    "    scraper = RBIScraper()\n",
    "    \n",
    "    # Main press release page\n",
    "    main_url = \"https://rbi.org.in/Scripts/BS_PressreleaseDisplay.aspx\"\n",
    "    \n",
    "    print(\"Fetching press releases...\")\n",
    "    releases = scraper.get_press_releases(main_url)\n",
    "    print(f\"Found {len(releases)} press releases\")\n",
    "    \n",
    "    # Scrape Treasury Bills specifically\n",
    "    treasury_bills_data = []\n",
    "    \n",
    "    for release in releases[:5]:  # Limit to first 5 for testing\n",
    "        print(f\"\\nProcessing: {release['title']}\")\n",
    "        \n",
    "        if 'Treasury Bills' in release['title'] or 'T-Bill' in release['title']:\n",
    "            time.sleep(1)  # Be polite to the server\n",
    "            \n",
    "            result = scraper.scrape_treasury_bills(release['url'])\n",
    "            if result:\n",
    "                # Add metadata\n",
    "                for row in result['data']:\n",
    "                    row['Release_Title'] = release['title']\n",
    "                    row['Release_Date'] = release['date']\n",
    "                    row['Release_URL'] = release['url']\n",
    "                    treasury_bills_data.append(row)\n",
    "    \n",
    "    # Save results\n",
    "    if treasury_bills_data:\n",
    "        print(f\"\\n\\nTotal records scraped: {len(treasury_bills_data)}\")\n",
    "        scraper.save_to_csv(treasury_bills_data, 'rbi_treasury_bills.csv')\n",
    "        scraper.save_to_excel(treasury_bills_data, 'rbi_treasury_bills.xlsx')\n",
    "    else:\n",
    "        print(\"\\nNo Treasury Bills data found\")\n",
    "    \n",
    "    # Save all press releases list\n",
    "    if releases:\n",
    "        scraper.save_to_csv(releases, 'rbi_press_releases_list.csv')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff2f42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RBI Press Release Scraper\n",
      "================================================================================\n",
      "Fetching main page: https://rbi.org.in/Scripts/BS_PressreleaseDisplay.aspx\n",
      "Found 55 press releases\n",
      "\n",
      "Starting to scrape 55 press releases...\n",
      "================================================================================\n",
      "\n",
      "[1/55] Treasury Bills: Full Auction Result\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61572\n",
      "\n",
      "  Fetching detail page: Treasury Bills: Full Auction Result...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/001_Treasury_Bills_Full_Auction_Result_table_1.csv\n",
      "    Saved: rbi_scraped_data/001_Treasury_Bills_Full_Auction_Result_table_2.csv\n",
      "    Saved: rbi_scraped_data/001_Treasury_Bills_Full_Auction_Result_table_3.csv\n",
      "    Saved: rbi_scraped_data/001_Treasury_Bills_Full_Auction_Result_table_4.csv\n",
      "\n",
      "[2/55] 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61571\n",
      "\n",
      "  Fetching detail page: 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/002_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_1.csv\n",
      "    Saved: rbi_scraped_data/002_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_2.csv\n",
      "    Saved: rbi_scraped_data/002_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_3.csv\n",
      "    Saved: rbi_scraped_data/002_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_4.csv\n",
      "\n",
      "[3/55] Underwriting Auction for sale of Government Security for â‚¹32,000 crore\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61570\n",
      "\n",
      "  Fetching detail page: Underwriting Auction for sale of Government Security for â‚¹32...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/003_Underwriting_Auction_for_sale_of_Government_Security_for_32000_crore_on_November_07_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/003_Underwriting_Auction_for_sale_of_Government_Security_for_32000_crore_on_November_07_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/003_Underwriting_Auction_for_sale_of_Government_Security_for_32000_crore_on_November_07_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/003_Underwriting_Auction_for_sale_of_Government_Security_for_32000_crore_on_November_07_2025_table_4.csv\n",
      "\n",
      "[4/55] Money Market Operations as on November 05, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61569\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on November 05, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/004_Money_Market_Operations_as_on_November_05_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/004_Money_Market_Operations_as_on_November_05_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/004_Money_Market_Operations_as_on_November_05_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/004_Money_Market_Operations_as_on_November_05_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/004_Money_Market_Operations_as_on_November_05_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/004_Money_Market_Operations_as_on_November_05_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/004_Money_Market_Operations_as_on_November_05_2025_table_7.csv\n",
      "\n",
      "[5/55] Money Market Operations as on November 04, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61568\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on November 04, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/005_Money_Market_Operations_as_on_November_04_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/005_Money_Market_Operations_as_on_November_04_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/005_Money_Market_Operations_as_on_November_04_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/005_Money_Market_Operations_as_on_November_04_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/005_Money_Market_Operations_as_on_November_04_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/005_Money_Market_Operations_as_on_November_04_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/005_Money_Market_Operations_as_on_November_04_2025_table_7.csv\n",
      "\n",
      "[6/55] Final redemption under Sovereign Gold Bond (SGB) Scheme - Redemption P\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61567\n",
      "\n",
      "  Fetching detail page: Final redemption under Sovereign Gold Bond (SGB) Scheme - Re...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/006_Final_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_final_redemption_of_201_table_1.csv\n",
      "    Saved: rbi_scraped_data/006_Final_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_final_redemption_of_201_table_2.csv\n",
      "    Saved: rbi_scraped_data/006_Final_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_final_redemption_of_201_table_3.csv\n",
      "\n",
      "[7/55] RBI imposes monetary penalty on Latur District Central Co-operative Ba\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61566\n",
      "\n",
      "  Fetching detail page: RBI imposes monetary penalty on Latur District Central Co-op...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/007_RBI_imposes_monetary_penalty_on_Latur_District_Central_Co-operative_Bank_Ltd_Maharashtra_table_1.csv\n",
      "    Saved: rbi_scraped_data/007_RBI_imposes_monetary_penalty_on_Latur_District_Central_Co-operative_Bank_Ltd_Maharashtra_table_2.csv\n",
      "    Saved: rbi_scraped_data/007_RBI_imposes_monetary_penalty_on_Latur_District_Central_Co-operative_Bank_Ltd_Maharashtra_table_3.csv\n",
      "\n",
      "[8/55] RBI imposes monetary penalty on Parbhani District Central Cooperative \n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61565\n",
      "\n",
      "  Fetching detail page: RBI imposes monetary penalty on Parbhani District Central Co...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/008_RBI_imposes_monetary_penalty_on_Parbhani_District_Central_Cooperative_Bank_Ltd_Maharashtra_table_1.csv\n",
      "    Saved: rbi_scraped_data/008_RBI_imposes_monetary_penalty_on_Parbhani_District_Central_Cooperative_Bank_Ltd_Maharashtra_table_2.csv\n",
      "    Saved: rbi_scraped_data/008_RBI_imposes_monetary_penalty_on_Parbhani_District_Central_Cooperative_Bank_Ltd_Maharashtra_table_3.csv\n",
      "\n",
      "[9/55] RBI imposes monetary penalty on Viva Home Finance Limited, Palghar, Ma\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61564\n",
      "\n",
      "  Fetching detail page: RBI imposes monetary penalty on Viva Home Finance Limited, P...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/009_RBI_imposes_monetary_penalty_on_Viva_Home_Finance_Limited_Palghar_Maharashtra_table_1.csv\n",
      "    Saved: rbi_scraped_data/009_RBI_imposes_monetary_penalty_on_Viva_Home_Finance_Limited_Palghar_Maharashtra_table_2.csv\n",
      "    Saved: rbi_scraped_data/009_RBI_imposes_monetary_penalty_on_Viva_Home_Finance_Limited_Palghar_Maharashtra_table_3.csv\n",
      "\n",
      "[10/55] RBI imposes monetary penalty on The Satara Sahakari Bank Ltd., Mumbai,\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61563\n",
      "\n",
      "  Fetching detail page: RBI imposes monetary penalty on The Satara Sahakari Bank Ltd...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/010_RBI_imposes_monetary_penalty_on_The_Satara_Sahakari_Bank_Ltd_Mumbai_Maharashtra_table_1.csv\n",
      "    Saved: rbi_scraped_data/010_RBI_imposes_monetary_penalty_on_The_Satara_Sahakari_Bank_Ltd_Mumbai_Maharashtra_table_2.csv\n",
      "    Saved: rbi_scraped_data/010_RBI_imposes_monetary_penalty_on_The_Satara_Sahakari_Bank_Ltd_Mumbai_Maharashtra_table_3.csv\n",
      "\n",
      "[11/55] Survey on Computer Software and Information Technology Enabled Service\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61562\n",
      "\n",
      "  Fetching detail page: Survey on Computer Software and Information Technology Enabl...\n",
      "    Found 13 table(s)\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_1.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_2.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_3.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_4.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_5.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_6.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_7.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_8.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_9.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_10.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_11.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_12.csv\n",
      "    Saved: rbi_scraped_data/011_Survey_on_Computer_Software_and_Information_Technology_Enabled_Services_Exports_2024-25_table_13.csv\n",
      "\n",
      "[12/55] State Government Securities - Full Auction Result\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61561\n",
      "\n",
      "  Fetching detail page: State Government Securities - Full Auction Result...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/012_State_Government_Securities_-_Full_Auction_Result_table_1.csv\n",
      "    Saved: rbi_scraped_data/012_State_Government_Securities_-_Full_Auction_Result_table_2.csv\n",
      "    Saved: rbi_scraped_data/012_State_Government_Securities_-_Full_Auction_Result_table_3.csv\n",
      "    Saved: rbi_scraped_data/012_State_Government_Securities_-_Full_Auction_Result_table_4.csv\n",
      "    Saved: rbi_scraped_data/012_State_Government_Securities_-_Full_Auction_Result_table_5.csv\n",
      "    Saved: rbi_scraped_data/012_State_Government_Securities_-_Full_Auction_Result_table_6.csv\n",
      "    Saved: rbi_scraped_data/012_State_Government_Securities_-_Full_Auction_Result_table_7.csv\n",
      "\n",
      "[13/55] Result of Yield/Price Based Auction of State Government Securities\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61560\n",
      "\n",
      "  Fetching detail page: Result of Yield/Price Based Auction of State Government Secu...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/013_Result_of_YieldPrice_Based_Auction_of_State_Government_Securities_table_1.csv\n",
      "    Saved: rbi_scraped_data/013_Result_of_YieldPrice_Based_Auction_of_State_Government_Securities_table_2.csv\n",
      "    Saved: rbi_scraped_data/013_Result_of_YieldPrice_Based_Auction_of_State_Government_Securities_table_3.csv\n",
      "    Saved: rbi_scraped_data/013_Result_of_YieldPrice_Based_Auction_of_State_Government_Securities_table_4.csv\n",
      "\n",
      "[14/55] Financial Action Task Force (FATF) High risk and other monitored juris\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61559\n",
      "\n",
      "  Fetching detail page: Financial Action Task Force (FATF) High risk and other monit...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/014_Financial_Action_Task_Force_FATF_High_risk_and_other_monitored_jurisdictions_October_22-24_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/014_Financial_Action_Task_Force_FATF_High_risk_and_other_monitored_jurisdictions_October_22-24_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/014_Financial_Action_Task_Force_FATF_High_risk_and_other_monitored_jurisdictions_October_22-24_2025_table_3.csv\n",
      "\n",
      "[15/55] Money Market Operations as on November 03, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61558\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on November 03, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/015_Money_Market_Operations_as_on_November_03_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/015_Money_Market_Operations_as_on_November_03_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/015_Money_Market_Operations_as_on_November_03_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/015_Money_Market_Operations_as_on_November_03_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/015_Money_Market_Operations_as_on_November_03_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/015_Money_Market_Operations_as_on_November_03_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/015_Money_Market_Operations_as_on_November_03_2025_table_7.csv\n",
      "\n",
      "[16/55] Auction of Government of India Dated Security\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61557\n",
      "\n",
      "  Fetching detail page: Auction of Government of India Dated Security...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/016_Auction_of_Government_of_India_Dated_Security_table_1.csv\n",
      "    Saved: rbi_scraped_data/016_Auction_of_Government_of_India_Dated_Security_table_2.csv\n",
      "    Saved: rbi_scraped_data/016_Auction_of_Government_of_India_Dated_Security_table_3.csv\n",
      "    Saved: rbi_scraped_data/016_Auction_of_Government_of_India_Dated_Security_table_4.csv\n",
      "\n",
      "[17/55] Premature redemption under Sovereign Gold Bond (SGB) Scheme - Redempti\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61556\n",
      "\n",
      "  Fetching detail page: Premature redemption under Sovereign Gold Bond (SGB) Scheme ...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/017_Premature_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_premature_redemptio_table_1.csv\n",
      "    Saved: rbi_scraped_data/017_Premature_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_premature_redemptio_table_2.csv\n",
      "    Saved: rbi_scraped_data/017_Premature_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_premature_redemptio_table_3.csv\n",
      "\n",
      "[18/55] Money Market Operations as on November 02, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61555\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on November 02, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/018_Money_Market_Operations_as_on_November_02_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/018_Money_Market_Operations_as_on_November_02_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/018_Money_Market_Operations_as_on_November_02_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/018_Money_Market_Operations_as_on_November_02_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/018_Money_Market_Operations_as_on_November_02_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/018_Money_Market_Operations_as_on_November_02_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/018_Money_Market_Operations_as_on_November_02_2025_table_7.csv\n",
      "\n",
      "[19/55] Money Market Operations as on November 01, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61554\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on November 01, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/019_Money_Market_Operations_as_on_November_01_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/019_Money_Market_Operations_as_on_November_01_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/019_Money_Market_Operations_as_on_November_01_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/019_Money_Market_Operations_as_on_November_01_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/019_Money_Market_Operations_as_on_November_01_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/019_Money_Market_Operations_as_on_November_01_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/019_Money_Market_Operations_as_on_November_01_2025_table_7.csv\n",
      "\n",
      "[20/55] Money Market Operations as on October 31, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61553\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on October 31, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/020_Money_Market_Operations_as_on_October_31_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/020_Money_Market_Operations_as_on_October_31_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/020_Money_Market_Operations_as_on_October_31_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/020_Money_Market_Operations_as_on_October_31_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/020_Money_Market_Operations_as_on_October_31_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/020_Money_Market_Operations_as_on_October_31_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/020_Money_Market_Operations_as_on_October_31_2025_table_7.csv\n",
      "\n",
      "[21/55] Processing of Applications Received Under the Citizenâ€™s Charter â€“ Stat\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61552\n",
      "\n",
      "  Fetching detail page: Processing of Applications Received Under the Citizenâ€™s Char...\n",
      "    Found 5 table(s)\n",
      "    Saved: rbi_scraped_data/021_Processing_of_Applications_Received_Under_the_Citizens_Charter_Status_as_on_October_31_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/021_Processing_of_Applications_Received_Under_the_Citizens_Charter_Status_as_on_October_31_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/021_Processing_of_Applications_Received_Under_the_Citizens_Charter_Status_as_on_October_31_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/021_Processing_of_Applications_Received_Under_the_Citizens_Charter_Status_as_on_October_31_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/021_Processing_of_Applications_Received_Under_the_Citizens_Charter_Status_as_on_October_31_2025_table_5.csv\n",
      "\n",
      "[22/55] Withdrawal of â‚¹2000 Denomination Banknotes â€“ Status\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61551\n",
      "\n",
      "  Fetching detail page: Withdrawal of â‚¹2000 Denomination Banknotes â€“ Status...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/022_Withdrawal_of_2000_Denomination_Banknotes_Status_table_1.csv\n",
      "    Saved: rbi_scraped_data/022_Withdrawal_of_2000_Denomination_Banknotes_Status_table_2.csv\n",
      "    Saved: rbi_scraped_data/022_Withdrawal_of_2000_Denomination_Banknotes_Status_table_3.csv\n",
      "\n",
      "[23/55] 619thMeeting of Central Board of the Reserve Bank of India\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61550\n",
      "\n",
      "  Fetching detail page: 619thMeeting of Central Board of the Reserve Bank of India...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/023_619thMeeting_of_Central_Board_of_the_Reserve_Bank_of_India_table_1.csv\n",
      "    Saved: rbi_scraped_data/023_619thMeeting_of_Central_Board_of_the_Reserve_Bank_of_India_table_2.csv\n",
      "    Saved: rbi_scraped_data/023_619thMeeting_of_Central_Board_of_the_Reserve_Bank_of_India_table_3.csv\n",
      "\n",
      "[24/55] RBI launches the November 2025 round of Urban Consumer Confidence Surv\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61547\n",
      "\n",
      "  Fetching detail page: RBI launches the November 2025 round of Urban Consumer Confi...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/024_RBI_launches_the_November_2025_round_of_Urban_Consumer_Confidence_Survey_table_1.csv\n",
      "    Saved: rbi_scraped_data/024_RBI_launches_the_November_2025_round_of_Urban_Consumer_Confidence_Survey_table_2.csv\n",
      "    Saved: rbi_scraped_data/024_RBI_launches_the_November_2025_round_of_Urban_Consumer_Confidence_Survey_table_3.csv\n",
      "\n",
      "[25/55] RBI launches the November 2025 round of the Rural Consumer Confidence \n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61548\n",
      "\n",
      "  Fetching detail page: RBI launches the November 2025 round of the Rural Consumer C...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/025_RBI_launches_the_November_2025_round_of_the_Rural_Consumer_Confidence_Survey_table_1.csv\n",
      "    Saved: rbi_scraped_data/025_RBI_launches_the_November_2025_round_of_the_Rural_Consumer_Confidence_Survey_table_2.csv\n",
      "    Saved: rbi_scraped_data/025_RBI_launches_the_November_2025_round_of_the_Rural_Consumer_Confidence_Survey_table_3.csv\n",
      "\n",
      "[26/55] RBI launches the November 2025 round of the Inflation Expectations  Su\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61549\n",
      "\n",
      "  Fetching detail page: RBI launches the November 2025 round of the Inflation Expect...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/026_RBI_launches_the_November_2025_round_of_the_Inflation_Expectations_Survey_of_Households_table_1.csv\n",
      "    Saved: rbi_scraped_data/026_RBI_launches_the_November_2025_round_of_the_Inflation_Expectations_Survey_of_Households_table_2.csv\n",
      "    Saved: rbi_scraped_data/026_RBI_launches_the_November_2025_round_of_the_Inflation_Expectations_Survey_of_Households_table_3.csv\n",
      "\n",
      "[27/55] Auction of State Government Securities\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61546\n",
      "\n",
      "  Fetching detail page: Auction of State Government Securities...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/027_Auction_of_State_Government_Securities_table_1.csv\n",
      "    Saved: rbi_scraped_data/027_Auction_of_State_Government_Securities_table_2.csv\n",
      "    Saved: rbi_scraped_data/027_Auction_of_State_Government_Securities_table_3.csv\n",
      "    Saved: rbi_scraped_data/027_Auction_of_State_Government_Securities_table_4.csv\n",
      "\n",
      "[28/55] Lending and Deposit Rates of Scheduled Commercial Banks â€“ October 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61545\n",
      "\n",
      "  Fetching detail page: Lending and Deposit Rates of Scheduled Commercial Banks â€“ Oc...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/028_Lending_and_Deposit_Rates_of_Scheduled_Commercial_Banks_October_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/028_Lending_and_Deposit_Rates_of_Scheduled_Commercial_Banks_October_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/028_Lending_and_Deposit_Rates_of_Scheduled_Commercial_Banks_October_2025_table_3.csv\n",
      "\n",
      "[29/55] Monthly Data on Indiaâ€™s International Trade in Services  for the Month\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61544\n",
      "\n",
      "  Fetching detail page: Monthly Data on Indiaâ€™s International Trade in Services  for...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/029_Monthly_Data_on_Indias_International_Trade_in_Services_for_the_Month_of_September_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/029_Monthly_Data_on_Indias_International_Trade_in_Services_for_the_Month_of_September_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/029_Monthly_Data_on_Indias_International_Trade_in_Services_for_the_Month_of_September_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/029_Monthly_Data_on_Indias_International_Trade_in_Services_for_the_Month_of_September_2025_table_4.csv\n",
      "\n",
      "[30/55] Auction of 91-Day, 182-Day and 364-Day Treasury Bills\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61543\n",
      "\n",
      "  Fetching detail page: Auction of 91-Day, 182-Day and 364-Day Treasury Bills...\n",
      "    Found 5 table(s)\n",
      "    Saved: rbi_scraped_data/030_Auction_of_91-Day_182-Day_and_364-Day_Treasury_Bills_table_1.csv\n",
      "    Saved: rbi_scraped_data/030_Auction_of_91-Day_182-Day_and_364-Day_Treasury_Bills_table_2.csv\n",
      "    Saved: rbi_scraped_data/030_Auction_of_91-Day_182-Day_and_364-Day_Treasury_Bills_table_3.csv\n",
      "    Saved: rbi_scraped_data/030_Auction_of_91-Day_182-Day_and_364-Day_Treasury_Bills_table_4.csv\n",
      "    Saved: rbi_scraped_data/030_Auction_of_91-Day_182-Day_and_364-Day_Treasury_Bills_table_5.csv\n",
      "\n",
      "[31/55] Money Supply for the fortnight ended October 17, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61542\n",
      "\n",
      "  Fetching detail page: Money Supply for the fortnight ended October 17, 2025...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/031_Money_Supply_for_the_fortnight_ended_October_17_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/031_Money_Supply_for_the_fortnight_ended_October_17_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/031_Money_Supply_for_the_fortnight_ended_October_17_2025_table_3.csv\n",
      "\n",
      "[32/55] Reserve Bank of India â€“ Bulletin Weekly Statistical Supplement â€“ Extra\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61541\n",
      "\n",
      "  Fetching detail page: Reserve Bank of India â€“ Bulletin Weekly Statistical Suppleme...\n",
      "    Found 8 table(s)\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_1.csv\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_2.csv\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_3.csv\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_4.csv\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_5.csv\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_6.csv\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_7.csv\n",
      "    Saved: rbi_scraped_data/032_Reserve_Bank_of_India_Bulletin_Weekly_Statistical_Supplement_Extract_table_8.csv\n",
      "\n",
      "[33/55] Government Stock - Full Auction Results\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61540\n",
      "\n",
      "  Fetching detail page: Government Stock - Full Auction Results...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/033_Government_Stock_-_Full_Auction_Results_table_1.csv\n",
      "    Saved: rbi_scraped_data/033_Government_Stock_-_Full_Auction_Results_table_2.csv\n",
      "    Saved: rbi_scraped_data/033_Government_Stock_-_Full_Auction_Results_table_3.csv\n",
      "    Saved: rbi_scraped_data/033_Government_Stock_-_Full_Auction_Results_table_4.csv\n",
      "\n",
      "[34/55] Sectoral Deployment of Bank Credit â€“ September 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61539\n",
      "\n",
      "  Fetching detail page: Sectoral Deployment of Bank Credit â€“ September 2025...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/034_Sectoral_Deployment_of_Bank_Credit_September_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/034_Sectoral_Deployment_of_Bank_Credit_September_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/034_Sectoral_Deployment_of_Bank_Credit_September_2025_table_3.csv\n",
      "\n",
      "[35/55] Government Stock - Auction Results: Cut-off\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61538\n",
      "\n",
      "  Fetching detail page: Government Stock - Auction Results: Cut-off...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/035_Government_Stock_-_Auction_Results_Cut-off_table_1.csv\n",
      "    Saved: rbi_scraped_data/035_Government_Stock_-_Auction_Results_Cut-off_table_2.csv\n",
      "    Saved: rbi_scraped_data/035_Government_Stock_-_Auction_Results_Cut-off_table_3.csv\n",
      "    Saved: rbi_scraped_data/035_Government_Stock_-_Auction_Results_Cut-off_table_4.csv\n",
      "\n",
      "[36/55] Result of Underwriting Auction conducted on October 31, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61537\n",
      "\n",
      "  Fetching detail page: Result of Underwriting Auction conducted on October 31, 2025...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/036_Result_of_Underwriting_Auction_conducted_on_October_31_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/036_Result_of_Underwriting_Auction_conducted_on_October_31_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/036_Result_of_Underwriting_Auction_conducted_on_October_31_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/036_Result_of_Underwriting_Auction_conducted_on_October_31_2025_table_4.csv\n",
      "\n",
      "[37/55] Money Market Operations as on October 30, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61536\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on October 30, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/037_Money_Market_Operations_as_on_October_30_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/037_Money_Market_Operations_as_on_October_30_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/037_Money_Market_Operations_as_on_October_30_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/037_Money_Market_Operations_as_on_October_30_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/037_Money_Market_Operations_as_on_October_30_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/037_Money_Market_Operations_as_on_October_30_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/037_Money_Market_Operations_as_on_October_30_2025_table_7.csv\n",
      "\n",
      "[38/55] RBI imposes monetary penalty on Parner Taluka Sainik Sahakari Bank Ltd\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61535\n",
      "\n",
      "  Fetching detail page: RBI imposes monetary penalty on Parner Taluka Sainik Sahakar...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/038_RBI_imposes_monetary_penalty_on_Parner_Taluka_Sainik_Sahakari_Bank_Ltd_Parner_Maharashtra_table_1.csv\n",
      "    Saved: rbi_scraped_data/038_RBI_imposes_monetary_penalty_on_Parner_Taluka_Sainik_Sahakari_Bank_Ltd_Parner_Maharashtra_table_2.csv\n",
      "    Saved: rbi_scraped_data/038_RBI_imposes_monetary_penalty_on_Parner_Taluka_Sainik_Sahakari_Bank_Ltd_Parner_Maharashtra_table_3.csv\n",
      "\n",
      "[39/55] RBI imposes monetary penalty on The Mehsana Urban Co-operative Bank Li\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61534\n",
      "\n",
      "  Fetching detail page: RBI imposes monetary penalty on The Mehsana Urban Co-operati...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/039_RBI_imposes_monetary_penalty_on_The_Mehsana_Urban_Co-operative_Bank_Limited_Gujarat_table_1.csv\n",
      "    Saved: rbi_scraped_data/039_RBI_imposes_monetary_penalty_on_The_Mehsana_Urban_Co-operative_Bank_Limited_Gujarat_table_2.csv\n",
      "    Saved: rbi_scraped_data/039_RBI_imposes_monetary_penalty_on_The_Mehsana_Urban_Co-operative_Bank_Limited_Gujarat_table_3.csv\n",
      "\n",
      "[40/55] Scheduled Banksâ€™ Statement of Position in India as on Friday, October \n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61533\n",
      "\n",
      "  Fetching detail page: Scheduled Banksâ€™ Statement of Position in India as on Friday...\n",
      "    Found 6 table(s)\n",
      "    Saved: rbi_scraped_data/040_Scheduled_Banks_Statement_of_Position_in_India_as_on_Friday_October_17_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/040_Scheduled_Banks_Statement_of_Position_in_India_as_on_Friday_October_17_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/040_Scheduled_Banks_Statement_of_Position_in_India_as_on_Friday_October_17_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/040_Scheduled_Banks_Statement_of_Position_in_India_as_on_Friday_October_17_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/040_Scheduled_Banks_Statement_of_Position_in_India_as_on_Friday_October_17_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/040_Scheduled_Banks_Statement_of_Position_in_India_as_on_Friday_October_17_2025_table_6.csv\n",
      "\n",
      "[41/55] Underwriting Auction for sale of Government Securities for â‚¹32,000 cro\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61532\n",
      "\n",
      "  Fetching detail page: Underwriting Auction for sale of Government Securities for â‚¹...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/041_Underwriting_Auction_for_sale_of_Government_Securities_for_32000_crore_on_October_31_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/041_Underwriting_Auction_for_sale_of_Government_Securities_for_32000_crore_on_October_31_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/041_Underwriting_Auction_for_sale_of_Government_Securities_for_32000_crore_on_October_31_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/041_Underwriting_Auction_for_sale_of_Government_Securities_for_32000_crore_on_October_31_2025_table_4.csv\n",
      "\n",
      "[42/55] Result of the Overnight Variable Rate Repo (VRR) auction held on Octob\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61531\n",
      "\n",
      "  Fetching detail page: Result of the Overnight Variable Rate Repo (VRR) auction hel...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/042_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_30_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/042_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_30_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/042_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_30_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/042_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_30_2025_table_4.csv\n",
      "\n",
      "[43/55] Money Market Operations as on October 29, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61530\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on October 29, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/043_Money_Market_Operations_as_on_October_29_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/043_Money_Market_Operations_as_on_October_29_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/043_Money_Market_Operations_as_on_October_29_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/043_Money_Market_Operations_as_on_October_29_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/043_Money_Market_Operations_as_on_October_29_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/043_Money_Market_Operations_as_on_October_29_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/043_Money_Market_Operations_as_on_October_29_2025_table_7.csv\n",
      "\n",
      "[44/55] RBI to conduct Overnight Variable Rate Repo (VRR) auction under LAF on\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61529\n",
      "\n",
      "  Fetching detail page: RBI to conduct Overnight Variable Rate Repo (VRR) auction un...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/044_RBI_to_conduct_Overnight_Variable_Rate_Repo_VRR_auction_under_LAF_on_October_30_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/044_RBI_to_conduct_Overnight_Variable_Rate_Repo_VRR_auction_under_LAF_on_October_30_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/044_RBI_to_conduct_Overnight_Variable_Rate_Repo_VRR_auction_under_LAF_on_October_30_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/044_RBI_to_conduct_Overnight_Variable_Rate_Repo_VRR_auction_under_LAF_on_October_30_2025_table_4.csv\n",
      "\n",
      "[45/55] Premature redemption under Sovereign Gold Bond (SGB) Scheme - Redempti\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61528\n",
      "\n",
      "  Fetching detail page: Premature redemption under Sovereign Gold Bond (SGB) Scheme ...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/045_Premature_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_premature_redemptio_table_1.csv\n",
      "    Saved: rbi_scraped_data/045_Premature_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_premature_redemptio_table_2.csv\n",
      "    Saved: rbi_scraped_data/045_Premature_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_premature_redemptio_table_3.csv\n",
      "\n",
      "[46/55] Final redemption under Sovereign Gold Bond (SGB) Scheme - Redemption P\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61527\n",
      "\n",
      "  Fetching detail page: Final redemption under Sovereign Gold Bond (SGB) Scheme - Re...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/046_Final_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_final_redemption_of_201_table_1.csv\n",
      "    Saved: rbi_scraped_data/046_Final_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_final_redemption_of_201_table_2.csv\n",
      "    Saved: rbi_scraped_data/046_Final_redemption_under_Sovereign_Gold_Bond_SGB_Scheme_-_Redemption_Price_for_final_redemption_of_201_table_3.csv\n",
      "\n",
      "[47/55] RBI releases Draft circular on Guidelines to facilitate faster cross-b\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61526\n",
      "\n",
      "  Fetching detail page: RBI releases Draft circular on Guidelines to facilitate fast...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/047_RBI_releases_Draft_circular_on_Guidelines_to_facilitate_faster_cross-border_inward_payments_table_1.csv\n",
      "    Saved: rbi_scraped_data/047_RBI_releases_Draft_circular_on_Guidelines_to_facilitate_faster_cross-border_inward_payments_table_2.csv\n",
      "    Saved: rbi_scraped_data/047_RBI_releases_Draft_circular_on_Guidelines_to_facilitate_faster_cross-border_inward_payments_table_3.csv\n",
      "\n",
      "[48/55] Rate of Interest on Government of India Floating Rate Bond 2034\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61525\n",
      "\n",
      "  Fetching detail page: Rate of Interest on Government of India Floating Rate Bond 2...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/048_Rate_of_Interest_on_Government_of_India_Floating_Rate_Bond_2034_table_1.csv\n",
      "    Saved: rbi_scraped_data/048_Rate_of_Interest_on_Government_of_India_Floating_Rate_Bond_2034_table_2.csv\n",
      "    Saved: rbi_scraped_data/048_Rate_of_Interest_on_Government_of_India_Floating_Rate_Bond_2034_table_3.csv\n",
      "\n",
      "[49/55] Census on Foreign Liabilities and Assets of Indian Direct Investment E\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61524\n",
      "\n",
      "  Fetching detail page: Census on Foreign Liabilities and Assets of Indian Direct In...\n",
      "    Found 21 table(s)\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_1.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_2.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_3.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_4.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_5.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_6.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_7.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_8.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_9.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_10.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_11.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_12.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_13.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_14.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_15.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_16.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_17.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_18.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_19.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_20.csv\n",
      "    Saved: rbi_scraped_data/049_Census_on_Foreign_Liabilities_and_Assets_of_Indian_Direct_Investment_Entities_for_2024-25_table_21.csv\n",
      "\n",
      "[50/55] Reserve Money for the fortnight ended October 24, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61523\n",
      "\n",
      "  Fetching detail page: Reserve Money for the fortnight ended October 24, 2025...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/050_Reserve_Money_for_the_fortnight_ended_October_24_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/050_Reserve_Money_for_the_fortnight_ended_October_24_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/050_Reserve_Money_for_the_fortnight_ended_October_24_2025_table_3.csv\n",
      "\n",
      "[51/55] Treasury Bills: Full Auction Result\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61522\n",
      "\n",
      "  Fetching detail page: Treasury Bills: Full Auction Result...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/051_Treasury_Bills_Full_Auction_Result_table_1.csv\n",
      "    Saved: rbi_scraped_data/051_Treasury_Bills_Full_Auction_Result_table_2.csv\n",
      "    Saved: rbi_scraped_data/051_Treasury_Bills_Full_Auction_Result_table_3.csv\n",
      "    Saved: rbi_scraped_data/051_Treasury_Bills_Full_Auction_Result_table_4.csv\n",
      "\n",
      "[52/55] 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61521\n",
      "\n",
      "  Fetching detail page: 91-Day, 182-Day and 364-Day T-Bill Auction Result: Cut-off...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/052_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_1.csv\n",
      "    Saved: rbi_scraped_data/052_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_2.csv\n",
      "    Saved: rbi_scraped_data/052_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_3.csv\n",
      "    Saved: rbi_scraped_data/052_91-Day_182-Day_and_364-Day_T-Bill_Auction_Result_Cut-off_table_4.csv\n",
      "\n",
      "[53/55] Scheme for writing books originally in Hindi on Economics/Banking/Fina\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61520\n",
      "\n",
      "  Fetching detail page: Scheme for writing books originally in Hindi on Economics/Ba...\n",
      "    Found 3 table(s)\n",
      "    Saved: rbi_scraped_data/053_Scheme_for_writing_books_originally_in_Hindi_on_EconomicsBankingFinancial_subjects_Declaration_of_Re_table_1.csv\n",
      "    Saved: rbi_scraped_data/053_Scheme_for_writing_books_originally_in_Hindi_on_EconomicsBankingFinancial_subjects_Declaration_of_Re_table_2.csv\n",
      "    Saved: rbi_scraped_data/053_Scheme_for_writing_books_originally_in_Hindi_on_EconomicsBankingFinancial_subjects_Declaration_of_Re_table_3.csv\n",
      "\n",
      "[54/55] Result of the Overnight Variable Rate Repo (VRR) auction held on Octob\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61519\n",
      "\n",
      "  Fetching detail page: Result of the Overnight Variable Rate Repo (VRR) auction hel...\n",
      "    Found 4 table(s)\n",
      "    Saved: rbi_scraped_data/054_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_29_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/054_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_29_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/054_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_29_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/054_Result_of_the_Overnight_Variable_Rate_Repo_VRR_auction_held_on_October_29_2025_table_4.csv\n",
      "\n",
      "[55/55] Money Market Operations as on October 28, 2025\n",
      "  Date: None\n",
      "  URL: https://rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx?prid=61518\n",
      "\n",
      "  Fetching detail page: Money Market Operations as on October 28, 2025...\n",
      "    Found 7 table(s)\n",
      "    Saved: rbi_scraped_data/055_Money_Market_Operations_as_on_October_28_2025_table_1.csv\n",
      "    Saved: rbi_scraped_data/055_Money_Market_Operations_as_on_October_28_2025_table_2.csv\n",
      "    Saved: rbi_scraped_data/055_Money_Market_Operations_as_on_October_28_2025_table_3.csv\n",
      "    Saved: rbi_scraped_data/055_Money_Market_Operations_as_on_October_28_2025_table_4.csv\n",
      "    Saved: rbi_scraped_data/055_Money_Market_Operations_as_on_October_28_2025_table_5.csv\n",
      "    Saved: rbi_scraped_data/055_Money_Market_Operations_as_on_October_28_2025_table_6.csv\n",
      "    Saved: rbi_scraped_data/055_Money_Market_Operations_as_on_October_28_2025_table_7.csv\n",
      "\n",
      "================================================================================\n",
      "SCRAPING COMPLETE\n",
      "================================================================================\n",
      "Total press releases processed: 55\n",
      "Successful scrapes: 261\n",
      "Failed scrapes: 0\n",
      "\n",
      "All CSV files saved in: rbi_scraped_data/\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "class RBIScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://rbi.org.in/Scripts/\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "    \n",
    "    def get_press_release_links(self, main_url):\n",
    "        \"\"\"Extract all press release links from the main page\"\"\"\n",
    "        try:\n",
    "            print(f\"Fetching main page: {main_url}\")\n",
    "            response = self.session.get(main_url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            releases = []\n",
    "            current_date = None\n",
    "            \n",
    "            # Find all rows in the table\n",
    "            for row in soup.find_all('tr'):\n",
    "                # Check if this row is a date header\n",
    "                date_header = row.find('td', class_='tableheader')\n",
    "                if date_header:\n",
    "                    h2 = date_header.find('h2', class_='dop_header')\n",
    "                    if h2:\n",
    "                        current_date = h2.get_text(strip=True)\n",
    "                        continue\n",
    "                \n",
    "                # Find press release link\n",
    "                link_td = row.find('a', class_='link2')\n",
    "                if link_td and 'href' in link_td.attrs:\n",
    "                    title = link_td.get_text(strip=True)\n",
    "                    relative_url = link_td['href']\n",
    "                    full_url = urljoin(self.base_url, relative_url)\n",
    "                    \n",
    "                    releases.append({\n",
    "                        'title': title,\n",
    "                        'date': current_date,\n",
    "                        'url': full_url,\n",
    "                        'relative_url': relative_url\n",
    "                    })\n",
    "            \n",
    "            print(f\"Found {len(releases)} press releases\")\n",
    "            return releases\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching press releases: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def scrape_detail_page_tables(self, url, title):\n",
    "        \"\"\"Scrape all tables from a detail page\"\"\"\n",
    "        try:\n",
    "            print(f\"\\n  Fetching detail page: {title[:60]}...\")\n",
    "            response = self.session.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            # Find all tables\n",
    "            tables = soup.find_all('table')\n",
    "            \n",
    "            if not tables:\n",
    "                print(f\"    No tables found\")\n",
    "                return None\n",
    "            \n",
    "            # Extract data from all tables\n",
    "            all_tables_data = []\n",
    "            \n",
    "            for idx, table in enumerate(tables):\n",
    "                table_data = self._extract_table_data(table)\n",
    "                if table_data and len(table_data) > 0:\n",
    "                    all_tables_data.append({\n",
    "                        'table_index': idx,\n",
    "                        'data': table_data\n",
    "                    })\n",
    "            \n",
    "            if all_tables_data:\n",
    "                print(f\"    Found {len(all_tables_data)} table(s)\")\n",
    "                return all_tables_data\n",
    "            else:\n",
    "                print(f\"    No valid table data extracted\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    Error scraping detail page: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _extract_table_data(self, table):\n",
    "        \"\"\"Extract data from a single table\"\"\"\n",
    "        rows = []\n",
    "        \n",
    "        # Get all rows\n",
    "        for tr in table.find_all('tr'):\n",
    "            cells = tr.find_all(['td', 'th'])\n",
    "            if cells:\n",
    "                # Extract text from each cell\n",
    "                row_data = []\n",
    "                for cell in cells:\n",
    "                    # Get text and clean it\n",
    "                    text = cell.get_text(strip=True)\n",
    "                    # Handle line breaks\n",
    "                    text = ' '.join(text.split())\n",
    "                    row_data.append(text)\n",
    "                \n",
    "                # Only add non-empty rows\n",
    "                if any(row_data):\n",
    "                    rows.append(row_data)\n",
    "        \n",
    "        return rows\n",
    "    \n",
    "    def save_table_to_csv(self, table_data, filename):\n",
    "        \"\"\"Save table data to CSV\"\"\"\n",
    "        try:\n",
    "            if not table_data or len(table_data) == 0:\n",
    "                return False\n",
    "            \n",
    "            # Find the maximum number of columns\n",
    "            max_cols = max(len(row) for row in table_data)\n",
    "            \n",
    "            # Pad rows to have equal columns\n",
    "            padded_data = []\n",
    "            for row in table_data:\n",
    "                padded_row = row + [''] * (max_cols - len(row))\n",
    "                padded_data.append(padded_row)\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(padded_data)\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(filename, index=False, header=False, encoding='utf-8-sig')\n",
    "            print(f\"    Saved: {filename}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error saving CSV: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def clean_filename(self, title):\n",
    "        \"\"\"Create a clean filename from title\"\"\"\n",
    "        # Remove special characters\n",
    "        clean = re.sub(r'[^\\w\\s-]', '', title)\n",
    "        # Replace spaces with underscores\n",
    "        clean = re.sub(r'\\s+', '_', clean)\n",
    "        # Limit length\n",
    "        clean = clean[:100]\n",
    "        return clean\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create output directory\n",
    "    output_dir = \"rbi_scraped_data\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Initialize scraper\n",
    "    scraper = RBIScraper()\n",
    "    \n",
    "    # Main press release page URL\n",
    "    main_url = \"https://rbi.org.in/Scripts/BS_PressreleaseDisplay.aspx\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"RBI Press Release Scraper\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Step 1: Get all press release links\n",
    "    releases = scraper.get_press_release_links(main_url)\n",
    "    \n",
    "    if not releases:\n",
    "        print(\"\\nNo press releases found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nStarting to scrape {len(releases)} press releases...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Step 2: Visit each link and scrape tables\n",
    "    successful_scrapes = 0\n",
    "    failed_scrapes = 0\n",
    "    \n",
    "    for i, release in enumerate(releases, 1):\n",
    "        print(f\"\\n[{i}/{len(releases)}] {release['title'][:70]}\")\n",
    "        print(f\"  Date: {release['date']}\")\n",
    "        print(f\"  URL: {release['url']}\")\n",
    "        \n",
    "        # Scrape tables from detail page\n",
    "        tables = scraper.scrape_detail_page_tables(release['url'], release['title'])\n",
    "        \n",
    "        if tables:\n",
    "            # Save each table as a separate CSV\n",
    "            clean_title = scraper.clean_filename(release['title'])\n",
    "            \n",
    "            for table_info in tables:\n",
    "                table_idx = table_info['table_index']\n",
    "                table_data = table_info['data']\n",
    "                \n",
    "                # Create filename\n",
    "                if len(tables) > 1:\n",
    "                    filename = f\"{output_dir}/{i:03d}_{clean_title}_table_{table_idx+1}.csv\"\n",
    "                else:\n",
    "                    filename = f\"{output_dir}/{i:03d}_{clean_title}.csv\"\n",
    "                \n",
    "                # Save table\n",
    "                if scraper.save_table_to_csv(table_data, filename):\n",
    "                    successful_scrapes += 1\n",
    "        else:\n",
    "            failed_scrapes += 1\n",
    "        \n",
    "        # Be polite to the server\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SCRAPING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total press releases processed: {len(releases)}\")\n",
    "    print(f\"Successful scrapes: {successful_scrapes}\")\n",
    "    print(f\"Failed scrapes: {failed_scrapes}\")\n",
    "    print(f\"\\nAll CSV files saved in: {output_dir}/\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0461bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
